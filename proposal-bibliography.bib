@misc{brian_mcfee_2018_1252297,
author = {McFee, Brian and McVicar, Matt and Balke, Stefan and Thom{\'{e}}, Carl and Raffel, Colin and Lee, Dana and Nieto, Oriol and Battenberg, Eric and Ellis, Dan and Yamamoto, Ryuichi and Moore, Josh and Bittner, Rachel and Choi, Keunwoo and Friesch, Pius and St{\"{o}}ter, Fabian-Robert and Lostanlen, Vincent and Kumar, Siddhartha and Waloschek, Simon and Kranzler, Seth and Naktinis, Rimvydas and Repetto, Douglas and Hawthorne, Curtis ``Fjord'' and Carr, C J and Pimenta, Waldir and Viktorin, Petr and Brossier, Paul and Santos, Jo{\~{a}}o Felipe and Wu, Jackie and Peterson, Erik and Holovaty, Adrian},
doi = {10.5281/zenodo.1252297},
month = {may},
title = {librosa/librosa: 0.6.1},
url = {https://doi.org/10.5281/zenodo.1252297},
year = {2018}
}
@misc{chollet2015keras,
author = {Chollet, Fran{\c{c}}ois and Others},
howpublished = {$\backslash$url{\{}https://keras.io{\}}},
title = {{Keras}},
year = {2015}
}
@article{Wingfield2016,
abstract = {The goal of this article is to trace the evolution of models of working memory and cognitive resources from the early 20th century to today. Linear flow models of information processing common in the 1960s and 1970s centered on the transfer of verbal information from a limited-capacity short-term memory store to long-term memory through rehearsal. Current conceptions see working memory as a dynamic system that includes both maintaining and manipulating information through a series of interactive components that include executive control and attentional resources. These models also reflect the evolution from an almost exclusive concentration on working memory for verbal materials to inclusion of a visual working memory component. Although differing in postulated mechanisms and emphasis, these evolving viewpoints all share the recognition that human information processing is a limited-capacity system with limits on the amount of information that can be attended to, remain activated in memory, and utilized at one time. These limitations take on special importance in spoken language comprehension, especially when the stimuli have complex linguistic structures or listening effort is increased by poor acoustic quality or reduced hearing acuity.},
author = {Wingfield, Arthur},
doi = {10.1097/AUD.0000000000000310},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wingfield - 2016 - Evolution of Models of Working Memory and Cognitive Resources.pdf:pdf},
isbn = {0000000000000},
issn = {0196-0202},
journal = {Ear and Hearing},
keywords = {Cocktail party,Resources,Short term memory,Subvocal rehersal,Working memory},
pages = {35S--43S},
pmid = {27355768},
title = {{Evolution of Models of Working Memory and Cognitive Resources}},
url = {http://insights.ovid.com/crossref?an=00003446-201607001-00004},
volume = {37},
year = {2016}
}
@book{Plack2018,
address = {Third edition. | Abingdon, Oxon; New York, NY: Routledge, 2018.},
author = {Plack, Christopher J.},
doi = {10.4324/9781315208145},
isbn = {9781315208145},
month = {jun},
publisher = {Routledge},
title = {{The Sense of Hearing}},
url = {https://www.taylorfrancis.com/books/9781315208145},
year = {2018}
}
@techreport{bishop1994mixture,
author = {Bishop, Christopher M},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bishop - 2013 - Mixture Density Networks.pdf:pdf},
institution = {Citeseer},
title = {{Mixture density networks}},
year = {1994}
}
@article{slaney1993importance,
author = {Slaney, Malcolm and Lyon, Richard F},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Slaney et al. - 1993 - No Title.pdf:pdf},
journal = {Visual representations of speech signals},
publisher = {Chichester: Wiley},
title = {{On the importance of time-a temporal representation of sound}},
volume = {95116},
year = {1993}
}
@article{Piazza2013,
abstract = {In vision, humans use summary statistics (e.g., the average facial expression of a crowd) to efficiently perceive the gist of groups of features. Here, we present direct evidence that ensemble coding is also important for auditory processing. We found that listeners could accurately estimate the mean frequency of a set of logarithmically spaced pure tones presented in a temporal sequence (Experiment 1). Their performance was severely reduced when only a subset of tones from a given sequence was presented (Experiment 2), which demonstrates that ensemble coding is based on a substantial number of the tones in a sequence. This precise ensemble coding occurred despite very limited representation of individual tones from the sequence: Listeners were poor at identifying specific individual member tones (Experiment 3) and at determining their positions in the sequence (Experiment 4). Together, these results indicate that summary statistical coding is not limited to visual processing and is an important auditory mechanism for extracting ensemble frequency information from sequences of sounds.},
author = {Piazza, Elise A. and Sweeny, Timothy D. and Wessel, David and Silver, Michael A. and Whitney, David},
doi = {10.1177/0956797612473759},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Piazza et al. - 2013 - Humans Use Summary Statistics to Perceive Auditory Sequences.pdf:pdf},
isbn = {1467-9280 (Electronic)$\backslash$n0956-7976 (Linking)},
issn = {0956-7976},
journal = {Psychological Science},
keywords = {auditory perception,ensemble coding,frequency,perception,statistical summary,visual perception},
month = {aug},
number = {8},
pages = {1389--1397},
pmid = {23761928},
title = {{Humans Use Summary Statistics to Perceive Auditory Sequences}},
url = {http://journals.sagepub.com/doi/10.1177/0956797612473759},
volume = {24},
year = {2013}
}
@article{Hickok2007,
abstract = {Despite decades of research, the functional neuroanatomy of speech processing has been difficult to characterize. A major impediment to progress may have been the failure to consider task effects when mapping speech-related processing systems. We outline a dual-stream model of speech processing that remedies this situation. In this model, a ventral stream processes speech signals for comprehension, and a dorsal stream maps acoustic speech signals to frontal lobe articulatory networks. The model assumes that the ventral stream is largely bilaterally organized — although there are important computational differences between the left- and right-hemisphere systems — and that the dorsal stream is strongly left-hemisphere dominant.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Hickok, Gregory and Poeppel, David},
doi = {10.1038/nrn2113},
eprint = {NIHMS150003},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hickok, Poeppel - 2007 - The cortical organization of speech processing.pdf:pdf},
isbn = {1471-003X (Print)},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
month = {may},
number = {5},
pages = {393--402},
pmid = {17431404},
title = {{The cortical organization of speech processing}},
url = {http://www.nature.com/articles/nrn2113},
volume = {8},
year = {2007}
}
@article{Eggermont2001,
abstract = {This review investigates the roles of representation, transformation and coding as part of a hierarchical process between sound and perception. This is followed by a survey of how speech sounds and elements thereof are represented in the activity patterns along the auditory pathway. Then the evidence for a place representation of texture features of sound, comprising frequency, periodicity pitch, harmonicity in vowels, and direction and speed of frequency modulation, and for a temporal and synchrony representation of sound contours, comprising onsets, offsets, voice onset time, and low rate amplitude modulation, in auditory cortex is reviewed. Contours mark changes and transitions in sound and auditory cortex appears particularly sensitive to these dynamic aspects of sound. Texture determines which neurons, both cortical and subcortical, are activated by the sound whereas the contours modulate the activity of those neurons. Because contours are temporally represented in the majority of neurons activated by the texture aspects of sound, each of these neurons is part of an ensemble formed by the combination of contour and texture sensitivity. A multiplexed coding of complex sound is proposed whereby the contours set up widespread synchrony across those neurons in all auditory cortical areas that are activated by the texture of sound. Copyright {\textcopyright} 2001 Elsevier Science B.V.},
author = {Eggermont, Jos J.},
doi = {10.1016/S0378-5955(01)00259-3},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Eggermont - 2001 - Between sound and perception Reviewing the search for a neural code.pdf:pdf},
isbn = {0378-5955},
issn = {03785955},
journal = {Hearing Research},
keywords = {Amplitude and frequency modulation,Auditory system,Neural coding,Neural representation,Neural synchrony,Neural transformation,Speech,Vocalization,Voice onset time},
number = {1-2},
pages = {1--42},
pmid = {11470183},
title = {{Between sound and perception: Reviewing the search for a neural code}},
volume = {157},
year = {2001}
}
@article{Choudhury2008,
abstract = {The Mobile Sensing Platform (MSP) is a small-form-factor wearable device designed for embedded activity recognition. The MSP aims broadly to support context-aware ubiquitous computing applications. It incorporates multimodal sensing, data processing and inference, storage, all-day battery life, and wireless connectivity into a single 4 oz (115 g) wearable unit. Several design iterations and real-world deployments over the last four years have identified a set of core hardware and software requirements for a mobile inference system. This article presents findings and lessons learned in the course of designing, improving and using this system. This article is part of a special issue on activity-based computing.},
author = {Choudhury, Tanzeem and Borriello, Gaetano and Consolvo, Sunny and Haehnel, Dirk and Harrison, Beverly and Hemingway, Bruce and Hightower, Jeffrey and Klasnja, Predrag "Pedja" and Koscher, Karl and LaMarca, Anthony and Landay, James A. and LeGrand, Louis and Lester, Jonathan and Rahimi, Ali and Rea, Adam and Wyatt, Danny},
doi = {10.1109/MPRV.2008.39},
issn = {1536-1268},
journal = {IEEE Pervasive Computing},
keywords = {activity recognition,embedded systems,machine learning,wearable computers},
month = {apr},
number = {2},
pages = {32--41},
publisher = {IEEE Computer Society},
title = {{The Mobile Sensing Platform: An Embedded Activity Recognition System}},
url = {http://ieeexplore.ieee.org/document/4487086/},
volume = {7},
year = {2008}
}
@article{Meyer2017,
abstract = {Identifying acoustic events from a continuously streaming audio source is of interest for many applications including environmental monitoring for basic research. In this scenario neither different event classes are known nor what distinguishes one class from another. Therefore, an unsupervised feature learning method for exploration of audio data is presented in this paper. It incorporates the two following novel contributions: First, an audio frame predictor based on a Convolutional LSTM autoencoder is demonstrated, which is used for unsupervised feature extraction. Second, a training method for autoencoders is presented, which leads to distinct features by amplifying event similarities. In comparison to standard approaches, the features extracted from the audio frame predictor trained with the novel approach show 13 {\%} better results when used with a classifier and 36 {\%} better results when used for clustering.},
archivePrefix = {arXiv},
arxivId = {1712.03835},
author = {Meyer, Matthias and Beutel, Jan and Thiele, Lothar},
eprint = {1712.03835},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Meyer, Beutel, Thiele - 2017 - Unsupervised Feature Learning for Audio Analysis.pdf:pdf},
month = {dec},
title = {{Unsupervised Feature Learning for Audio Analysis}},
url = {http://arxiv.org/abs/1712.03835},
year = {2017}
}
@article{Boyd2010,
archivePrefix = {arXiv},
arxivId = {cond-mat/0307085},
author = {Boyd, Stephen},
doi = {10.1561/2200000016},
eprint = {0307085},
file = {:C$\backslash$:/Users/logas/Downloads/PhD-Cano-Pedro-2007.pdf:pdf},
isbn = {9781627480031},
issn = {1935-8237},
journal = {Foundations and Trends{\textregistered} in Machine Learning},
number = {1},
pages = {1--122},
pmid = {17504609},
primaryClass = {cond-mat},
title = {{Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers}},
url = {http://www.nowpublishers.com/article/Details/MAL-016},
volume = {3},
year = {2010}
}
@article{Janer2009,
abstract = {The computer-assisted design of soundscapes for virtual environments has received far less attention than the creation of graphical content. In this “think piece” we briefly introduce the principal characteristics of a framework under development that aims towards the creation of an automatic sonification of virtual worlds. As a starting point, the proposed system is based on an on-line collaborative sound repository that, together with content-based audio retrieval tools, assists the search of sounds to be associated with 3D models or scenes.},
author = {Janer, Jordi},
doi = {10.4101/jvwr.v2i3.635},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Janer - 2009 - Supporting Soundscape Design in Virtual Environments with Content-based Audio Retrieval.pdf:pdf},
issn = {1941-8477},
journal = {Journal For Virtual Worlds Research},
keywords = {audio retrieval,based,content,freesound,soundscape,virtual worlds},
month = {sep},
number = {3},
title = {{Supporting Soundscape Design in Virtual Environments with Content-based Audio Retrieval}},
url = {https://journals.tdl.org/jvwr/index.php/jvwr/article/view/635},
volume = {2},
year = {2009}
}
@article{Gygi2010,
abstract = {Theoretical and applied environmental sounds research is gaining prominence but progress has been hampered by the lack of a comprehensive, high quality, accessible database of environmental sounds. An ongoing project to develop such a resource is described, which is based upon experimental evidence as to the way we listen to sounds in the world. The database will include a large number of sounds produced by different sound sources, with a thorough background for each sound file, including experimentally obtained perceptual data. In this way DESRA can contain a wide variety of acoustic, contextual, semantic, and behavioral information related to an individual sound. It will be accessible on the Internet and will be useful to researchers, engineers, sound designers, and musicians.},
author = {Gygi, Brian and Shafiro, Valeriy},
doi = {10.1155/2010/654914},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gygi, Shafiro - 2010 - Development of the Database for Environmental Sound Research and Application (DESRA) Design, Functionality, and R.pdf:pdf},
issn = {1687-4714},
journal = {EURASIP Journal on Audio, Speech, and Music Processing},
keywords = {Acoustics,Engineering Acoustics,Image and Speech Processing,Mathematics in Music,Signal},
month = {jun},
number = {1},
pages = {1--12},
publisher = {Nature Publishing Group},
title = {{Development of the Database for Environmental Sound Research and Application (DESRA): Design, Functionality, and Retrieval Considerations}},
url = {http://asmp.eurasipjournals.com/content/2010/1/654914},
volume = {2010},
year = {2010}
}
@misc{Roy1997,
author = {Roy, Deb and Sawhney, Nitin Nick and Schmandt, Chris and Pentland, Alex},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Roy et al. - 1997 - Wearable Audio Computing A Survey of Interaction Techniques.pdf:pdf},
title = {{Wearable Audio Computing : A Survey of Interaction Techniques}},
url = {https://www.semanticscholar.org/paper/Wearable-Audio-Computing-{\%}3A-A-Survey-of-Interaction-Roy-Sawhney/421a9204eeb9b7b2a2d49a974cfd7531e6b8eac8},
year = {1997}
}
@article{Fernstrom2001,
abstract = {Presented at the 7th International Conference on Auditory Display (ICAD), Espoo, Finland, July 29-August 1, 2001.},
author = {Fernstrom, Mikael and Brazil, Eoin},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fernstrom, Brazil - 2001 - Sonic browsing An auditory tool for multimedia asset management.pdf:pdf},
keywords = {Auditory display,Proceedings,Sonic browsing},
publisher = {Georgia Institute of Technology},
title = {{Sonic browsing: An auditory tool for multimedia asset management}},
url = {https://smartech.gatech.edu/handle/1853/50644},
year = {2001}
}
@inproceedings{Roma2012,
address = {New York, New York, USA},
author = {Roma, Gerard and Janer, Jordi and Herrera, Perfecto},
booktitle = {Proceedings of the 2nd ACM International Conference on Multimedia Retrieval - ICMR '12},
doi = {10.1145/2324796.2324872},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Roma, Janer, Herrera - 2012 - Active learning of custom sound taxonomies in unstructured audio data.pdf:pdf},
isbn = {9781450313292},
keywords = {audio databases,content based retrieval,interactive search,interface},
pages = {1},
publisher = {ACM Press},
title = {{Active learning of custom sound taxonomies in unstructured audio data}},
url = {http://dl.acm.org/citation.cfm?doid=2324796.2324872},
year = {2012}
}
@article{Westerlaken2016,
abstract = {In this exploratory paper, we advocate for a way to mitigate the anthropocentrism inherent in interaction-design methodologies. We propose to involve animals that live in anthropic environments as participants in design processes. The current relationships between animals and technology have an inevitable impact on their well-being and raise fundamental ethical questions concerning our design policies. Drawing from the work of Bruno Latour and Donna Haraway, we argue for a situated approach in which we reflect upon concrete design contexts. We explore the notion of becoming with as a conceptual framework for the intuitive and bodily understanding that takes place between humans and animals when they encounter one-another in shared contexts. Adopting a research through design approach, we further explore this notion by reflecting upon two different participatory design projects with two dogs. We found these reflections to offer valuable perspectives for designers to analyse and discuss their iterative processes.},
author = {Westerlaken, Michelle and Gualeni, Stefano},
doi = {10.1145/2995257.2995392},
isbn = {9781450347587},
journal = {Proceedings of the Third International Conference on Animal-Computer Interaction - ACI '16},
title = {{Becoming with: towards the inclusion of animals as participants in design processes}},
year = {2016}
}
@article{Logas2018,
author = {Logas, Jacob},
doi = {10.1145/3295598.3295611},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Logas - 2018 - A Toolkit for Animal Touchscreen Slider Design.pdf:pdf},
keywords = {animal com-,toolkit,touchscreen,virtual user interface},
number = {December},
title = {{A Toolkit for Animal Touchscreen Slider Design}},
year = {2018}
}
@article{Blackler2007,
abstract = {Two previously independent approaches to investigating intuitive interaction in Aus-tralia and Germany are described and compared. Both definitions are based on the literature and so agree very closely, involving the non-conscious use of prior knowl-edge for intuitive interaction. Models have been devised by both groups: a continuum of intuitive interaction and a continuum of prior knowledge. Although there are points of difference in the models it is found that these are minimal and that the models are complementary. Tools like design methodologies, design principles, questionnaires, and an online database have been devised by the two groups that can contribute to helping designers in making user interfaces more intuitive to use.},
author = {Blackler, Alethea and Hurtienne, J{\"{o}}rn},
doi = {10.1016/j.coph.2013.08.013 S1471-4892(13)00159-8 [pii]},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Blackler, Hurtienne - 2007 - Towards a unified view of intuitive interaction definitions, models and tools across the world.pdf:pdf},
isbn = {3486581295},
issn = {1439-7854},
journal = {Kindsm{\"{u}}ller, M. C. {\&} Mahlke, S. (Hrsg.), MMI Interaktiv - User Experience:},
keywords = {design methodology,intuitive interaction,intuitive use,metaphor},
number = {13},
pages = {36--54},
pmid = {24035446},
title = {{Towards a unified view of intuitive interaction: definitions, models and tools across the world}},
volume = {1},
year = {2007}
}
@incollection{Nielsen2004,
abstract = {Many disciplines of multimedia and communication go towards ubiquitous computing and hand free interaction with computers. Application domains in this direction involve virtual reality, augmented reality, wearable computing, and smart spaces. This paper presents two main approaches to developing and testing these interfaces using gestures. It presents the important issues in gesture communication, from a technological viewpoint as well as a user viewpoint such as the technological complexity, learning rate, ergonomics, and intuition. These issues must be taken into account when choosing the gesture vocabulary. A procedure is proposed which includes those issues in the selection of gestures, and to test the resulting set of gestures. The procedure is tested and demonstrated on an example application with a small test group. The procedure is concluded to be useful and time consuming. The importance of using theory from ergonomics is also concluded.},
author = {Nielsen, Michael and St{\"{o}}rring, Moritz and Moeslund, Thomas B. and Granum, Erik},
doi = {10.1007/978-3-540-24598-8_38},
isbn = {9783540245988},
issn = {03029743},
pages = {409--420},
pmid = {21189532},
publisher = {Springer, Berlin, Heidelberg},
title = {{A Procedure for Developing Intuitive and Ergonomic Gesture Interfaces for HCI}},
url = {http://link.springer.com/10.1007/978-3-540-24598-8{\_}38},
year = {2004}
}
@article{Blackler2010,
abstract = {This paper examines the role of intuition in the way that people operate unfamiliar devices. Intuition is a type of cognitive processing that is often non-conscious and utilises stored experiential knowledge. Intuitive interaction involves the use of knowledge gained from other products and/or experiences. Two initial experimental studies revealed that prior exposure to products employing similar features helped participants to complete set tasks more quickly and intuitively, and that familiar features were intuitively used more often than unfamiliar ones. A third experiment confirmed that performance is affected by a person's level of familiarity with similar technologies, and also revealed that appearance (shape, size and labelling of features) seems to be the variable that most affects time spent on a task and intuitive uses during that time. Age also seems to have an effect. These results and their implications are discussed. {\textcopyright} 2009 Elsevier Ltd. All rights reserved.},
author = {Blackler, Alethea and Popovic, Vesna and Mahar, Doug},
doi = {10.1016/j.apergo.2009.04.010},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Blackler, Popovic, Mahar - 2010 - Investigating users' intuitive interaction with complex artefacts.pdf:pdf},
isbn = {0003-6870},
issn = {00036870},
journal = {Applied Ergonomics},
keywords = {Interface design,Intuitive interaction,Intuitive use,Observational analysis,Prior experience,Product design},
month = {jan},
number = {1},
pages = {72--92},
pmid = {19586618},
publisher = {Elsevier},
title = {{Investigating users' intuitive interaction with complex artefacts}},
url = {https://www.sciencedirect.com/science/article/pii/S0003687009000593},
volume = {41},
year = {2010}
}
@book{wigdor2011brave,
author = {Wigdor, Daniel and Wixon, Dennis},
doi = {10.1016/C2009-0-64091-5},
isbn = {9780123822314},
publisher = {Elsevier},
title = {{Brave NUI World}},
url = {https://linkinghub.elsevier.com/retrieve/pii/C20090640915},
year = {2011}
}
@article{Preece1994,
abstract = {The rapid development of any field of knowledge brings with it unavoidable fragmentation and proliferation of new disciplines. The development of computer science is no exception. Software engineering (SE) and human-computer interaction (HCI) are both relatively new disciplines of computer science. Furthermore, as both names suggest, they each have strong connections with other subjects. SE is concerned with methods and tools for general software development based on engineering principles. This discipline has its roots not only in computer science but also in a number of traditional engineering disciplines. HCI is concerned with methods and tools for the development of human-computer interfaces, assessing the usability of computer systems and with broader issues about how people interact with computers. It is based on theories about how humans process information and interact with computers, other objects and other people in the organizational and social contexts in which computers are used. HCI draws on knowledge and skills from psychology, anthropology and sociology in addition to computer science. Both disciplines need ways of measuring how well their products and development processes fulfil their intended requirements. Traditionally, SE has been concerned with “how software is constructed” and HCI with “how people use software”. Given the different histories of the disciplines and their different objectives, it is not surprising that they take different approaches to measurement, Thus, each has its own distinct “measurement culture”. In this paper we analyse the differences and the commonalities of the two cultures by examining the measurement approaches used by each. We then argue the need for a common measurement taxonomy and framework, which is derived from our analyses of the two disciplines. Next we demonstrate the usefulness of the taxonomy and framework via specific example studies drawn from our own work and that of others and show that, in fact, the two disciplines have many important similarities as well as differences and that there is some evidence to suggest that they are growing closer. Finally, we discuss the role of the taxonomy as a framework to support: reuse, planning future studies, guiding practice and facilitating communication between the two disciplines. {\textcopyright} 1994 Academic Press, Inc.},
author = {Preece, Jenny and Rombach, H. Dieter},
doi = {10.1006/ijhc.1994.1073},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Preece, Rombach - 1994 - A taxonomy for combining software engineering and human-computer interaction measurement approaches towards a c.pdf:pdf},
isbn = {1071-5819},
issn = {10959300},
journal = {International Journal of Human - Computer Studies},
month = {oct},
number = {4},
pages = {553--583},
publisher = {Academic Press},
title = {{A taxonomy for combining software engineering and human-Computer interaction measurement approaches: Towards a common framework}},
url = {https://www.sciencedirect.com/science/article/pii/S1071581984710731},
volume = {41},
year = {1994}
}
@article{Campbell1997,
abstract = {A tutorial on the design and development of automatic speaker- recognition systems is presented. Automatic speaker recognition is the use of a machine to recognize a person from a spoken phrase. These systems can operate in two modes: to identify a particular person or to verify a person's claimed identity. Speech processing and the basic components of automatic speaker- recognition systems are shown and design tradeoffs are discussed. Then, a new automatic speaker-recognition system is given. This recognizer performs with 98.9{\%} correct identification. Last, the performances of various systems are compared.},
author = {Campbell, J.P.},
doi = {10.1109/5.628714},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Campbell - 1997 - Speaker recognition A tutorial.pdf:pdf},
isbn = {0018-9219},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {Access control,Authentication,Biomedical measurements,Biomedical signal processing,Biomedical transducers,Biometric,Communication system security,Computer nehvork security,Computer security,Corpus,Data bases,Identification of persons,Public safety},
number = {9},
pages = {1437--1462},
pmid = {16402617},
title = {{Speaker recognition: a tutorial}},
url = {http://ieeexplore.ieee.org/document/628714/},
volume = {85},
year = {1997}
}
@article{Rabiner1989,
author = {Rabiner, L.R.},
doi = {10.1109/5.18626},
issn = {00189219},
journal = {Proceedings of the IEEE},
number = {2},
pages = {257--286},
title = {{A tutorial on hidden Markov models and selected applications in speech recognition}},
url = {http://ieeexplore.ieee.org/document/18626/},
volume = {77},
year = {1989}
}
@inproceedings{Gemmeke2017,
abstract = {Audio event recognition, the human-like ability to identify and re-late sounds from audio, is a nascent problem in machine percep-tion. Comparable problems such as object detection in images have reaped enormous benefits from comprehensive datasets – principally ImageNet. This paper describes the creation of Audio Set, a large-scale dataset of manually-annotated audio events that endeavors to bridge the gap in data availability between image and audio research. Using a carefully structured hierarchical ontology of 632 audio classes guided by the literature and manual curation, we collect data from human labelers to probe the presence of specific audio classes in 10 second segments of YouTube videos. Segments are proposed for labeling using searches based on metadata, context (e.g., links), and content analysis. The result is a dataset of unprecedented breadth and size that will, we hope, substantially stimulate the de-velopment of high-performance audio event recognizers.},
author = {Gemmeke, Jort F. and Ellis, Daniel P. W. and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R. Channing and Plakal, Manoj and Ritter, Marvin},
booktitle = {2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
doi = {10.1109/ICASSP.2017.7952261},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gemmeke et al. - 2017 - Audio Set An ontology and human-labeled dataset for audio events.pdf:pdf},
isbn = {978-1-5090-4117-6},
issn = {15206149},
keywords = {Audio event detection,audio databases,data collection,sound ontology},
month = {mar},
pages = {776--780},
publisher = {IEEE},
title = {{Audio Set: An ontology and human-labeled dataset for audio events}},
url = {http://ieeexplore.ieee.org/document/7952261/},
year = {2017}
}
@article{Specht1990,
abstract = {By replacing the sigmoid activation function often used in neural networks with an exponential function, a probabilistic neural network (PNN) that can compute nonlinear decision boundaries which approach the Bayes optimal is formed. Alternate activation functions having similar properties are also discussed. A fourlayer neural network of the type proposed can map any input pattern to any number of classifications. The decision boundaries can be modified in real-time using new data as they become available, and can be implemented using artificial hardware “neurons” that operate entirely in parallel. Provision is also made for estimating the probability and reliability of a classification as well as making the decision. The technique offers a tremendous speed advantage for problems in which the incremental adaptation time of back propagation is a significant fraction of the total computation time. For one application, the PNN paradigm was 200,000 times faster than back-propagation.},
author = {Specht, Donald F.},
doi = {10.1016/0893-6080(90)90049-Q},
issn = {08936080},
journal = {Neural Networks},
month = {jan},
number = {1},
pages = {109--118},
publisher = {Pergamon},
title = {{Probabilistic neural networks}},
url = {https://www.sciencedirect.com/science/article/pii/089360809090049Q http://linkinghub.elsevier.com/retrieve/pii/089360809090049Q},
volume = {3},
year = {1990}
}
@article{Kilgarriff2000,
abstract = {WordNet, an electronic lexical database, is considered to be the most important resource available to researchers in computational linguistics, text analysis, and many related areas. Its design is inspired by current psycholinguistic and computational theories of human lexical memory. English nouns, verbs, adjectives, and adverbs are organized into synonym sets, each representing one underlying lexicalized concept. Different relations link the synonym sets. The purpose of this volume is twofold. First, it discusses the design of WordNet and the theoretical motivations behind it. Second, it provides a survey of representative applications, including word sense identification, information retrieval, selectional preferences of verbs, and lexical chains.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Kilgarriff, Adam and Fellbaum, Christiane},
doi = {10.2307/417141},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kilgarriff, Fellbaum - 2000 - WordNet An Electronic Lexical Database.pdf:pdf},
isbn = {026206197X},
issn = {00978507},
journal = {Language},
month = {sep},
number = {3},
pages = {706},
pmid = {21561289},
title = {{WordNet: An Electronic Lexical Database}},
url = {https://www.jstor.org/stable/417141?origin=crossref},
volume = {76},
year = {2000}
}
@article{Hsu2008,
abstract = {In this paper, we propose a tag normalization algorithm to unify the users' annotations. Meanwhile, we explore some general phenomena in a social annotation system and propose a supervised tag prediction model to predict the stabilized tag set of a resource, with feedback of a small amount of user annotation records. The experiments show that a large potion of the stabilized tag set is predicted, and it is feasible to reduce the requirement of sufficient user annotations in the applications of social annotations. $\backslash$n},
author = {Hsu, Ming Hung and Chen, Hsin Hsi},
doi = {10.1109/WIIAT.2008.92},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hsu, Chen - 2008 - Tag normalization and prediction for effective social media retrieval.pdf:pdf},
isbn = {9780769534961},
journal = {Proceedings - 2008 IEEE/WIC/ACM International Conference on Web Intelligence, WI 2008},
keywords = {10,4,analyzed the usage patterns,explored,golder and huberman,in,of websites,property to estimate the,similarity between two,social annotations for semantic,terms and the quality,web construction,wu et al},
pages = {770--774},
title = {{Tag normalization and prediction for effective social media retrieval}},
year = {2008}
}
@article{Lew2006,
abstract = {Extending beyond the boundaries of science, art, and culture, content-based multimedia information retrieval provides new paradigms and methods for searching through the myriad variety of media all over the world. This survey reviews 100+ recent articles on content-based multimedia information retrieval and discusses their role in current research directions which include browsing and search paradigms, user studies, affective computing, learning, semantic queries, new features and media types, high performance indexing, and evaluation techniques. Based on the current state of the art, we discuss the major challenges for the future.},
author = {Lew, Michael S and Sebe, Nicu and Djeraba, Chabane and Jain, Ramesh},
doi = {10.1145/1126004.1126005},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lew et al. - 2006 - Content-based multimedia information retrieval.pdf:pdf},
isbn = {1551-6857},
issn = {15516857},
journal = {ACM Transactions on Multimedia Computing, Communications, and Applications},
month = {feb},
number = {1},
pages = {1--19},
title = {{Content-based multimedia information retrieval}},
url = {http://portal.acm.org/citation.cfm?doid=1126004.1126005},
volume = {2},
year = {2006}
}
@article{Berenzweig2004a,
abstract = {A valuable goal in the field of Music Information Retrieval (MIR) is to devise an automatic measure of the similarity between two musical recordings based only on an analysis of their audio content. Such a tool—a quantitative measure of similarity— can be used to build classification, retrieval, browsing, and recommendation systems. To develop such a measure, however, presupposes some ground truth, a single underlying similarity that constitutes the desired output of the measure. Music similarity is an elusive concept—wholly subjective, multifaceted, and a moving target—but one that must be pursued in support of applications to provide automatic organization of large music collections.},
author = {Berenzweig, Adam and Logan, Beth and Ellis, Daniel P.W. and Whitman, Brian},
doi = {10.1162/014892604323112257},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Berenzweig et al. - 2004 - A Large-Scale Evaluation of Acoustic and Subjective Music-Similarity Measures.pdf:pdf},
isbn = {0148-9267},
issn = {01489267},
journal = {Computer Music Journal},
keywords = {acoustic measures,evaluation,ground-truth,music similarity},
number = {2},
pages = {63--76},
title = {{A Large-Scale Evaluation of Acoustic and Subjective Music-Similarity Measures}},
url = {http://www.mitpressjournals.org/doi/10.1162/014892604323112257},
volume = {28},
year = {2004}
}
@article{Eronen2006,
author = {Eronen, A.J. and Peltonen, V.T. and Tuomi, J.T. and Klapuri, A.P. and Fagerlund, Seppo and Sorsa, Timo and Lorho, Ga{\"{e}}tan and Huopaniemi, J.},
doi = {10.1109/TSA.2005.854103},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Eronen et al. - 2006 - Audio-based context recognition.pdf:pdf},
issn = {1558-7916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
month = {jan},
number = {1},
pages = {321--329},
title = {{Audio-based context recognition}},
url = {papers3://publication/uuid/1D35B777-4640-4436-A9B0-C44427743C2E http://ieeexplore.ieee.org/document/1561288/},
volume = {14},
year = {2006}
}
@book{Karim2017,
abstract = {""Installing TensorFlow from source"" ""Cover ""; ""Copyright""; ""Credits""; ""About the Author""; ""Acknowledgments""; ""About the Reviewers""; ""www.PacktPub.com""; ""Customer Feedback""; ""Table of Contents""; ""Preface""; ""Chapter 1: Basic Python and Linear Algebra for Predictive Analytics ""; ""A basic introduction to predictive analytics""; ""Why predictive analytics?""; ""Working principles of a predictive model""; ""A bit of linear algebra""; ""Programming linear algebra""; ""Installing and getting started with Python""; ""Installing on Windows""; ""Installing Python on Linux"" ""Installing and upgrading PIP (or PIP3)""""Installing Python on Mac OS""; ""Installing packages in Python""; ""Getting started with Python""; ""Python data types""; ""Using strings in Python""; ""Using lists in Python""; ""Using tuples in Python""; ""Using dictionary in Python""; ""Using sets in Python""; ""Functions in Python""; ""Classes in Python""; ""Vectors, matrices, graphs, and tensors""; ""Vectors""; ""Matrices""; ""Matrix addition""; ""Matrix subtraction""; ""Finding the determinant of a matrix""; ""Finding the transpose of a matrix""; ""Solving simultaneous linear equations"" ""Eigenvalues and eigenvectors""""Span and linear independence""; ""Principal component analysis""; ""Singular value decomposition""; ""Data compression in a predictive model using SVD""; ""Predictive analytics tools in Python""; ""Summary""; ""Chapter 2: Statistics, Probability, and Information Theory for Predictive Modeling ""; ""Using statistics in predictive modeling""; ""Statistical models""; ""Parametric versus nonparametric model""; ""Population and sample""; ""Random sampling""; ""Expectation""; ""Central limit theorem""; ""Skewness and data distribution"" ""Standard deviation and variance""""Covariance and correlation""; ""Interquartile, range, and quartiles""; ""Hypothesis testing""; ""Chi-square tests""; ""Chi-square independence test""; ""Basic probability for predictive modeling""; ""Probability and the random variables""; ""Generating random numbers and setting the seed""; ""Probability distributions""; ""Marginal probability""; ""Conditional probability""; ""The chain rule of conditional probability""; ""Independence and conditional independence""; ""Bayes' rule""; ""Using information theory in predictive modeling""; ""Self-information"" ""Mutual information""""Entropy""; ""Shannon entropy""; ""Joint entropy""; ""Conditional entropy""; ""Information gain""; ""Using information theory""; ""Using information theory in Python""; ""Summary""; ""Chapter 3: From Data to Decisions â{\#}x80;{\#}x93; Getting Started with TensorFlow ""; ""Taking decisions based on data -- Titanic example""; ""Data value chain for making decisions""; ""From disaster to decision â{\#}x80;{\#}x93; Titanic survival example""; ""General overview of TensorFlow""; ""Installing and configuring TensorFlow""; ""Installing TensorFlow on Linux""; ""Installing Python and nVidia driver""},
author = {Karim, Md. Rezaul.},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Karim - 2017 - Predictive Analytics with TensorFlow.pdf:pdf},
isbn = {9781788390125},
pages = {522},
title = {{Predictive Analytics with TensorFlow.}},
url = {https://ebookcentral-1proquest-1com-1ytvkzsj01a25.han.sub.uni-goettingen.de/lib/subgoettingen/detail.action?docID=5122925},
year = {2017}
}
@article{Grangier2007,
abstract = {The present study examined the acute effects of hypoxia on the regulation of skeletal muscle metabolism at rest and during 15 min of submaximal exercise. Subjects exercised on two occasions for 15 min at 55{\%} of their normoxic maximal oxygen uptake while breathing 11{\%} O(2) (hypoxia) or room air (normoxia). Muscle biopsies were taken at rest and after 1 and 15 min of exercise. At rest, no effects on muscle metabolism were observed in response to hypoxia. In the 1st min of exercise, glycogenolysis was significantly greater in hypoxia compared with normoxia. This small difference in glycogenolysis was associated with a tendency toward a greater concentration of substrate, free P(i), in hypoxia compared with normoxia. Pyruvate dehydrogenase activity (PDH(a)) was lower in hypoxia at 1 min compared with normoxia, resulting in a reduced rate of pyruvate oxidation and a greater lactate accumulation. During the last 14 min of exercise, glycogenolysis was greater in hypoxia despite a lower mole fraction of phosphorylase a. The greater glycogenolytic rate was maintained posttransformationally through significantly higher free [AMP] and [P(i)]. At the end of exercise, PDH(a) was greater in hypoxia compared with normoxia, contributing to a greater rate of pyruvate oxidation. Because of the higher glycogenolytic rate in hypoxia, the rate of pyruvate production continued to exceed the rate of pyruvate oxidation, resulting in significant lactate accumulation in hypoxia compared with no further lactate accumulation in normoxia. Hence, the elevated lactate production associated with hypoxia at the same absolute workload could in part be explained by the effects of hypoxia on the activities of the rate-limiting enzymes, phosphorylase and PDH, which regulate the rates of pyruvate production and pyruvate oxidation, respectively.},
author = {Grangier, David and Monay, Florent and Bengio, Samy},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Grangier, Monay, Bengio - 2007 - LNCS 4398 - Learning to Retrieve Images from Text Queries with a Discriminative Model.pdf:pdf},
isbn = {9783540715443},
issn = {0193-1849},
journal = {Text},
pages = {42--56},
pmid = {10710508},
title = {{LNCS 4398 - Learning to Retrieve Images from Text Queries with a Discriminative Model}},
year = {2007}
}
@inproceedings{Baluja2007,
abstract = {In this paper, we present Waveprint, a novel system for audio identification. Waveprint uses a combination of computer-vision techniques and large-scale-data-stream processing algorithms to create compact fingerprints of audio data that can be efficiently matched. The resulting system has excellent identification capabilities for small snippets of audio that have been degraded in a variety of manners, including competing noise, poor recording quality, and cell-phone playback. We measure the tradeoffs between performance, memory usage, and computation through extensive experimentation. The system is more efficient in terms of memory usage and computation, while being more accurate, when compared with previous state of the art systems.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Baluja, Shumeet and Covell, Michele},
booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
doi = {10.1109/ICASSP.2007.366210},
eprint = {arXiv:1011.1669v3},
isbn = {1424407281},
issn = {15206149},
keywords = {Acoustic applications,Acoustic signal processing,Music,Pattern recognition},
pages = {II--213--II--216},
pmid = {25246403},
publisher = {IEEE},
title = {{Audio fingerprinting: Combining computer vision {\&} data stream processing}},
url = {http://ieeexplore.ieee.org/document/4217383/},
volume = {2},
year = {2007}
}
@article{Dong2008,
abstract = {Although Locality-Sensitive Hashing (LSH) is a promising approach to similarity search in high-dimensional spaces, it has not been considered practical partly because its search quality is sensitive to several parameters that are quite data dependent. Previous research on LSH, though obtained in- teresting asymptotic results, provides little guidance on how these parameters should be chosen, and tuning parameters for a given dataset remains a tedious process. To address this problem, we present a statistical perfor- mance model of Multi-probe LSH, a state-of-the-art vari- ance of LSH. Our model can accurately predict the average search quality and latency given a small sample dataset. Apart from automatic parameter tuning with the perfor- mance model, we also use the model to devise an adaptive LSH search algorithm to determine the probing parameter dynamically for each query. The adaptive probing method addresses the problem that even though the average perfor- mance is tuned for optimal, the variance of the performance is extremely high. We experimented with three different datasets including audio, images and 3D shapes to evaluate our methods. The results show the accuracy of the proposed model: the recall errors predicted are within 5{\%} from the real values for most cases; the adaptive search method re- duces the standard deviation of recall by about 50{\%} over the existing method. Categories},
address = {New York, New York, USA},
author = {Dong, Wei and Wang, Zhe and Josephson, William and Charikar, Moses and Li, Kai},
doi = {10.1145/1458082.1458172},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dong et al. - 2008 - Modeling LSH for performance tuning.pdf:pdf},
isbn = {9781595939913},
journal = {Proceeding of the 17th ACM conference on Information and knowledge mining - CIKM '08},
keywords = {all or part of,is granted without fee,locality sensitive hashing,or hard copies of,permission to make digital,personal or classroom use,provided that copies are,similarity search,this work for},
pages = {669},
publisher = {ACM Press},
title = {{Modeling LSH for performance tuning}},
url = {http://portal.acm.org/citation.cfm?doid=1458082.1458172},
year = {2008}
}
@inproceedings{Bergen2016,
author = {Bergen, Karianne and Yoon, Clara and Beroza, Gregory C.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-46759-7_23},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bergen, Yoon, Beroza - 2016 - Scalable Similarity Search in Seismology A New Approach to Large-Scale Earthquake Detection.pdf:pdf},
isbn = {9783319467580},
issn = {16113349},
keywords = {Data mining,Earthquake detection,Locality-sensitive hashing,Signal processing,Similarity search,Template matching,Time series},
month = {oct},
pages = {301--308},
publisher = {Springer, Cham},
title = {{Scalable similarity search in seismology: A new approach to large-scale earthquake detection}},
url = {http://link.springer.com/10.1007/978-3-319-46759-7{\_}23},
volume = {9939 LNCS},
year = {2016}
}
@article{Rong2018,
abstract = {In this work, we report on a novel application of Locality Sensitive Hashing (LSH) to seismic data at scale. Based on the high waveform similarity between reoccurring earthquakes, our application identifies potential earthquakes by searching for similar time series segments via LSH. However, a straightforward implementation of this LSH-enabled application has difficulty scaling beyond 3 months of continuous time series data measured at a single seismic station. As a case study of a data-driven science workflow, we illustrate how domain knowledge can be incorporated into the workload to improve both the efficiency and result quality. We describe several end-to-end optimizations of the analysis pipeline from pre-processing to post-processing, which allow the application to scale to time series data measured at multiple seismic stations. Our optimizations enable an over 100x speed up in the end-to-end analysis pipeline. This improved scalability enabled seismologists to perform seismic analysis on more than ten years of continuous time series data from over ten seismic stations, and has directly enabled the discovery of 597 new earthquakes near the Diablo Canyon nuclear power plant in California and 6123 new earthquakes in New Zealand.},
archivePrefix = {arXiv},
arxivId = {1803.09835},
author = {Rong, Kexin and Yoon, Clara E. and Bergen, Karianne J. and Elezabi, Hashem and Bailis, Peter and Levis, Philip and Beroza, Gregory C.},
doi = {arXiv:1803.09835v2},
eprint = {1803.09835},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rong et al. - 2018 - Locality-Sensitive Hashing for Earthquake Detection A Case Study of Scaling Data-Driven Science.pdf:pdf},
month = {mar},
title = {{Locality-Sensitive Hashing for Earthquake Detection: A Case Study Scaling Data-Driven Science}},
url = {https://arxiv.org/abs/1803.09835 http://arxiv.org/abs/1803.09835},
year = {2018}
}
@article{Abadi2016,
abstract = {TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. TensorFlow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous "parameter server" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with particularly strong support for training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model in contrast to existing systems, and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.},
archivePrefix = {arXiv},
arxivId = {1605.08695},
author = {Abadi, Mart{\'{i}}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
doi = {10.1038/nn.3331},
eprint = {1605.08695},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abadi et al. - 2016 - TensorFlow A system for large-scale machine learning.pdf:pdf},
isbn = {978-1-931971-33-1},
issn = {0270-6474},
journal = {12th USENIX Symposium on Operating Systems Design and Implementation (OSDI '16)},
month = {may},
pages = {265--284},
pmid = {16411492},
title = {{TensorFlow: A system for large-scale machine learning}},
url = {https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi http://arxiv.org/abs/1605.08695},
year = {2016}
}
@article{Reynolds2000,
abstract = {In this paper we describe the major elements of MIT Lincoln Laboratory's Gaussian mixture model (GMM)-based speaker verification system used successfully in several NIST Speaker Recognition Evaluations (SREs). The system is built around the likelihood ratio test for verification, using simple but effective GMMs for likelihood functions, a universal background model (UBM) for alternative speaker representation, and a form of Bayesian adaptation to derive speaker models from the UBM. The development and use of a handset detector and score normalization to greatly improve verification performance is also described and discussed. Finally, representative performance benchmarks and system behavior experiments on NIST SRE corpora are presented.},
annote = {Implementation used for comparison},
author = {Reynolds, Douglas A. and Quatieri, Thomas F. and Dunn, Robert B.},
doi = {10.1006/dspr.1999.0361},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Reynolds, Quatieri, Dunn - 2000 - Speaker verification using adapted Gaussian mixture models(2).pdf:pdf},
isbn = {1051-2004},
issn = {10512004},
journal = {Digital Signal Processing: A Review Journal},
keywords = {gaussian mixture models,handset normalization,likelihood,nist,ratio detector,speaker recognition,universal background model},
number = {1},
pages = {19--41},
title = {{Speaker verification using adapted Gaussian mixture models}},
volume = {10},
year = {2000}
}
@article{aucouturier2006ten,
author = {Aucouturier, Jean-Julien},
journal = {Docteral dissertation, University of Paris},
title = {{Ten experiments on the modelling of polyphonic timbre}},
volume = {6},
year = {2006}
}
@article{Font2013,
abstract = {Freesound is an online collaborative sound database where people with diverse interests share recorded sound samples under Creative Commons licenses. It was started in 2005 and it is being maintained to support diverse research projects and as a service to the overall research and artistic community. In this demo we want to introduce Freesound to the multimedia community and show its potential as a research resource. We begin by describing some general aspects of Freesound, its architecture and functionalities, and then explain potential usages that this framework has for research applications.},
address = {New York, New York, USA},
author = {Font, Frederic and Roma, Gerard and Serra, Xavier},
doi = {10.1145/2502081.2502245},
isbn = {9781450324045},
journal = {Proceedings of the 21st ACM international conference on Multimedia - MM '13},
keywords = {audio clips,freesound,online databases,sound},
pages = {411--412},
publisher = {ACM Press},
title = {{Freesound technical demo}},
url = {http://dl.acm.org/citation.cfm?doid=2502081.2502245},
year = {2013}
}
@inproceedings{Piczak2015,
address = {New York, New York, USA},
author = {Piczak, Karol J.},
booktitle = {Proceedings of the 23rd ACM international conference on Multimedia - MM '15},
doi = {10.1145/2733373.2806390},
isbn = {9781450334594},
pages = {1015--1018},
publisher = {ACM Press},
title = {{ESC}},
url = {http://dl.acm.org/citation.cfm?doid=2733373.2806390},
year = {2015}
}
@article{Turnbull2008,
abstract = {We present a computer audition system that can both annotate novel audio tracks with semantically meaningful words and retrieve relevant tracks from a database of unlabeled audio content given a text-based query. We consider the related tasks of content-based audio annotation and retrieval as one supervised multiclass, multilabel problem in which we model the joint proba-bility of acoustic features and words. We collect a data set of 1700 human-generated annotations that describe 500 Western popular music tracks. For each word in a vocabulary, we use this data to train a Gaussian mixture model (GMM) over an audio feature space. We estimate the parameters of the model using the weighted mixture hierarchies expectation maximization algorithm. This algorithm is more scalable to large data sets and produces better density estimates than standard parameter estimation techniques. The quality of the music annotations produced by our system is comparable with the performance of humans on the same task. Our " query-by-text " system can retrieve appropriate songs for a large number of musically relevant words. We also show that our audition system is general by learning a model that can annotate and retrieve sound effects.},
author = {Turnbull, Douglas and Barrington, Luke and Torres, David and Lanckriet, Gert},
doi = {10.1109/TASL.2007.913750},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Turnbull et al. - 2008 - Semantic annotation and retrieval of music and sound effects.pdf:pdf},
issn = {15587916},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
keywords = {Audio annotation and retrieval,Music information retrieval,Semantic music analysis},
month = {feb},
number = {2},
pages = {467--476},
title = {{Semantic annotation and retrieval of music and sound effects}},
url = {http://ieeexplore.ieee.org/document/4432652/},
volume = {16},
year = {2008}
}
@article{Slaney2002,
abstract = {This paper describes a system for connecting sounds and words in linked multi-dimensional vector spaces. The acoustic space is represented using anchor models and partitioned using agglomerative clustering. The semantic space is modeled by a hierarchical multinomial clustering model. Nodes in one space are linked by probabilistic models to the other space. With these linked models, users retrieve sounds with natural language, and the system describes new sounds with words.},
author = {Slaney, Malcolm},
doi = {10.1109/ICASSP.2002.5745561},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Slaney - 2002 - Semantic-audio retrieval.pdf:pdf},
isbn = {0-7803-7402-9},
issn = {1520-6149},
journal = {IEEE International Conference on Acoustics Speech and Signal Processing},
pages = {IV--4108--IV--4111},
title = {{Semantic-audio retrieval}},
url = {http://ieeexplore.ieee.org/document/5745561/},
year = {2002}
}
@article{Wan2005,
abstract = {Audio retrieval is an important research topic in audio field. A good audio retrieval system is very helpful to facilitate users to find the target audio materials. In such a system, while audio features are fundamental in representing an audio clip, similarity measure is also an important fact affecting the performance of audio retrieval. In previous research works, there are many proposed audio features and used distance measures. However, there is not yet a good study about the effectiveness of different features and distance measures. Therefore, in this paper, we perform a comparative study on various audio features and various distance measures (similarity measures). The compared audio features include Mel-frequency cepstral coefficients (MFCC), Linear Predictive Coding Coefficients (LPC), sub-band energy distribution and some other temporal/spectral features, while the compared distances include Euclidean distance, Kullback-Leibler (K-L) divergence, Mahalanobis distance and Bhattacharyya distance. The study is expected to be helpful in the further design of audio retrieval system.},
author = {Wan, Pingying and Lu, Lie},
doi = {10.1117/12.629147},
editor = {Vetro, Anthony and Chen, Chang Wen and Kuo, C.C. J. and Zhang, Tong and Tian, Qi and Smith, John R.},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wan, Lu - 2005 - Content-Based Audio Retrieval A Comparative Study of Various Features and Similarity Measures.pdf:pdf},
issn = {0277786X},
journal = {Proceedings of SPIE},
keywords = {audio features,audio retrieval,comparative study,content-based analysis,similarity measure},
month = {oct},
pages = {60151H--60151H--8},
publisher = {International Society for Optics and Photonics},
title = {{Content-Based Audio Retrieval: A Comparative Study of Various Features and Similarity Measures}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=720434 http://link.aip.org/link/PSISDG/v6015/i1/p60151H/s1{\&}Agg=doi},
volume = {6015},
year = {2005}
}
@article{Turnbull2007,
abstract = {Query-by-semantic-description (QBSD)is a natural paradigm for retrieving content from large databases of music. A major impediment to the development of good QBSD systems for music information retrieval has been the lack of a cleanly-labeled, publicly-available, heterogeneous data set of songs and associated annotations. We have collected the Computer Audition Lab 500-song (CAL500) data set by having humans listen to and annotate songs using a survey designed to capture 'semantic associations' between music and words. We adapt the supervised multi-class labeling (SML) model, which has shown good performance on the task of image retrieval, and use the CAL500 data to learn a model for music retrieval. The model parameters are estimated using the weighted mixture hierarchies expectation-maximization algorithm which has been specifically designed to handle real-valued semantic association between words and songs, rather than binary class labels. The output of the SML model, a vector of class-conditional probabilities, can be interpreted as a semantic multinomial distribution over a vocabulary. By also representing a semantic query as a query multinomial distribution, we can quickly rank order the songs in a database based on the Kullback-Leibler divergence between the query multinomial and each song's semantic multinomial. Qualitative and quantitative results demonstrate that our SML model can both annotate a novel song with meaningful words and retrieve relevant songs given a multi-word, text-based query.},
address = {New York, New York, USA},
author = {Turnbull, Douglas and Barrington, Luke and Torres, David and Lanckriet, Gert},
doi = {10.1145/1277741.1277817},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Turnbull et al. - 2007 - Towards musical query-by-semantic-description using the cal500 data set.pdf:pdf},
isbn = {9781595935977},
journal = {Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval},
keywords = {content-based music information retrieval,query-by-semantic-description,sification,supervised multi-class clas-},
number = {January},
pages = {439--446},
publisher = {ACM Press},
title = {{Towards musical query-by-semantic-description using the cal500 data set}},
url = {http://portal.acm.org/citation.cfm?doid=1277741.1277817 http://dl.acm.org/citation.cfm?id=1277817},
year = {2007}
}
@phdthesis{Vanderveer1980,
address = {US},
author = {Vanderveer, Nancy J},
isbn = {0419-4217(Print)},
keywords = {*Auditory Perception,*Environment,*Memory,Recognition (Learning)},
number = {9-B},
pages = {4543},
publisher = {ProQuest Information {\&} Learning},
title = {{Ecological acoustics: Human perception of environmental sounds.}},
volume = {40},
year = {1980}
}
@article{Zheng2001,
abstract = {The performance of the Mel-Frequency Cepstrum Coefficients (MFCC) may be affected by (1) the number of filters, (2) the shape of filters, (3) the way in which filters are spaced, and (4) the way in which the power spectrum is warped. In this paper, several comparison experiments are done to find a best implementation. The traditional MFCC calculation excludes the 0th coefficient for the reason that it is regarded as somewhat unreliable. According to the analysis and experiments, the authors find that it can be regarded as the generalized frequency band energy (FBE) and is hence useful, which results in the FBE-MFCC. The authors also propose a better analysis, namely the auto-regressive analysis, on the frame energy, which outperform its 1st and/or 2nd order differential derivatives. Experiments with the 863 Speech Database show that, compared with the traditional MFCC with its corresponding auto-regressive analysis coefficients, the FBE-MFCC and the frame energy with their corresponding auto-regressive analysis coefficients form the best combination, reducing the Chinese syllable error rate (CSER) by about 10{\%}, while the FBE-MFCC with the corresponding auto-regressive analysis coefficients reduces CSER by 2.5{\%}. Comparison experiments are also done with a quite casual Chinese speech database, named Chinese Annotated Spontaneous Speech (CASS) corpus. The FBE-MFCC can reduce the error rate by about 2.9{\%} on an average.},
author = {Zheng, Fang and Zhang, Guoliang and Song, Zhanjiang},
doi = {10.1007/BF02943243},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zheng, Zhang, Song - 2001 - Comparison of different implementations of MFCC.pdf:pdf},
isbn = {1000-9000},
issn = {1000-9000},
journal = {Journal of Computer Science and Technology},
keywords = {Auto-regressive analysis,Frequency band energy,Generalized initial/final,MFCC},
month = {nov},
number = {6},
pages = {582--589},
title = {{Comparison of different implementations of MFCC}},
url = {http://link.springer.com/10.1007/BF02943243},
volume = {16},
year = {2001}
}
@article{Hermansky1990,
abstract = {A new technique for the analysis of speech, the perceptual linear predictive (PLP) technique, is presented and examined. This technique uses three concepts from the psychophysics of hearing to derive an estimate of the auditory spectrum: (1) the critical-band spectral resolution, (2) the equal-loudness curve, and (3) the intensity-loudness power law. The auditory spectrum is then approximated by an autoregressive all-pole model. A 5th-order all-pole model is effective in suppressing speaker-dependent details of the auditory spectrum. In comparison with conventional linear predictive (LP) analysis, PLP analysis is more consistent with human hearing. The effective second formant F2' and the 3.5-Bark spectral-peak integration theories of vowel perception are well accounted for. PLP analysis is computationally efficient and yields a low-dimensional representation of speech. These properties are found to be useful in speaker-independent automatic-speech recognition.},
author = {Hermansky, Hynek},
doi = {10.1121/1.399423},
isbn = {0001-4966 (Print)$\backslash$r0001-4966 (Linking)},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
month = {apr},
number = {4},
pages = {1738--1752},
pmid = {2341679},
title = {{Perceptual linear predictive (PLP) analysis of speech}},
url = {http://asa.scitation.org/doi/10.1121/1.399423},
volume = {87},
year = {1990}
}
@article{Roma2010a,
abstract = {In this paper we present a method to search for environmental sounds in large unstructured databases of user-submitted audio, using a general sound events taxonomy from ecological acoustics.We discuss the use of Support VectorMachines to classify sound recordings according to the taxonomy and describe two use cases for the obtained classificationmodels: a content-basedweb search interface for a large audio database and a method for segmenting field recordings to assist sound design.},
author = {Roma, Gerard and Janer, Jordi and Kersten, Stefan and Schirosa, Mattia and Herrera, Perfecto and Serra, Xavier},
doi = {10.1155/2010/960863},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Roma et al. - 2010 - Ecological acoustics perspective for content-based retrieval of environmental sounds(2).pdf:pdf},
isbn = {1687-4714},
issn = {16874714},
journal = {Eurasip Journal on Audio, Speech, and Music Processing},
title = {{Ecological acoustics perspective for content-based retrieval of environmental sounds}},
volume = {2010},
year = {2010}
}
@article{Gaver1993,
abstract = {Everyday listening is the experience of hearing events in the world rather than sounds per se. In this article, I take an ecological approach to everyday listening to overcome constraints on its study implied by more traditional approaches. In particular, I am concerned with deveolping a new framework for describing sound in terms of audible sources attributes. An examination of the coninuum of structured energy from events to audition suggests that sound conveys information about events at locations in an environment. Qualitative descriptions of the physics of sound-producing events into those involving vibrating solids, gasses, or liquids. Within each of these categories, basic-level events are defined by the simple interactions that can cause these materials to sound, whereas more complex events can be descrived in terms of temporal patterning, compound, or hybrid sources. The results of these investigations are used to creat a map of sound-producing events and their attributes useful in guiding furhter exploration.},
author = {Gaver, William W.},
doi = {10.1207/s15326969eco0501_1},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - gaverWhat.pdf.pdf:pdf},
isbn = {1040-7413},
issn = {15326969},
journal = {Ecological Psychology},
month = {mar},
number = {1},
pages = {1--29},
pmid = {768},
publisher = {Lawrence Erlbaum Associates, Inc.},
title = {{What in the World Do We Hear?: An Ecological Approach to Auditory Event Perception}},
url = {http://www.tandfonline.com/doi/abs/10.1207/s15326969eco0501{\_}1},
volume = {5},
year = {1993}
}
@article{Bardeli2009,
abstract = {In the past, similarity search for audio data has largely been focused on music. Recent digitization efforts in some of the larger animal sound archives bring other types of audio recordings into the focus of interest. Although recordings in animal sound archives are usually very well annotated by metadata, it is almost impossible to manually annotate all sounds made by animals in each recording. Complementary to classical text-based querying of databases that exploit available annotations, algorithms capable of automatically finding sections of recordings similar to a given query fragment provide a promising approach for content-based navigation. In our work, we present algorithms for feature extraction, as well as indexing and retrieval of animal sound recordings. Making use of a concept from image processing, the structure tensor, our feature extraction algorithm is adapted to the typical curve-like spectral features that are characteristic for many types of animal sounds. We propose a method for similarity search in animal sound databases which is obtained by adding a novel ranking scheme to an existing inverted file based approach for multimedia retrieval. Evaluation of our methods is based on recordings from the Animal Sound Archive, Berlin.},
author = {Bardeli, R.},
doi = {10.1109/TMM.2008.2008920},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bardeli - 2009 - Similarity Search in Animal Sound Databases.pdf:pdf},
isbn = {1520-9210},
issn = {1520-9210},
journal = {IEEE Transactions on Multimedia},
keywords = {Similarity search,animal sounds,feature extraction,indexing,retrieval,structure tensor},
month = {jan},
number = {1},
pages = {68--76},
title = {{Similarity Search in Animal Sound Databases}},
url = {http://ieeexplore.ieee.org/document/4729673/},
volume = {11},
year = {2009}
}
@article{Berenzweig2004,
abstract = {A valuable goal in the field of Music Information Retrieval (MIR) is to devise an automatic measure of the similarity between two musical recordings based only on an analysis of their audio content. Such a tool—a quantitative measure of similarity— can be used to build classification, retrieval, browsing, and recommendation systems. To develop such a measure, however, presupposes some ground truth, a single underlying similarity that constitutes the desired output of the measure. Music similarity is an elusive concept—wholly subjective, multifaceted, and a moving target—but one that must be pursued in support of applications to provide automatic organization of large music collections.},
author = {Berenzweig, Adam and Logan, Beth and Ellis, Daniel P.W. and Whitman, Brian},
doi = {10.1162/014892604323112257},
isbn = {0148-9267},
issn = {01489267},
journal = {Computer Music Journal},
month = {jun},
number = {2},
pages = {63--76},
title = {{A large-scale evaluation of acoustic and subjective music-similarity measures}},
url = {http://www.mitpressjournals.org/doi/10.1162/014892604323112257},
volume = {28},
year = {2004}
}
@article{Li2004,
abstract = {The paper investigates the use of acoustic based features for music information retrieval. Two specific problems are studied: similarity search (searching for music sound files similar to a given music sound file) and emotion detection (detection of emotion in music sounds). The Daubechies wavelet coefficient histograms (Li, T. et al., SIGIR'03, p.282-9, 2003), which consist of moments of the coefficients calculated by applying the Db8 wavelet filter, are combined with the timbral features extracted using the MARSYAS system of G. Tzanctakis and P. Cook (see IEEE Trans. on Speech and Audio Process., vol.10, no.5, p.293-8, 2002) to generate compact music features. For the similarity search, the distance between two sound files is defined to be the Euclidean distance of their normalized representations. Based on the distance measure, the closest sound files to an input sound file are obtained. Experiments on jazz vocal and classical sound files achieve a very high level of accuracy. Emotion detection is cast as a multiclass classification problem, decomposed as a multiple binary classification problem, and is resolved with the use of support vector machines trained on the extracted features. Our experiments on emotion detection achieved reasonably accurate performance and provided some insights on future work.},
author = {Li, Tao Li Tao and Ogihara, M.},
doi = {10.1109/ICASSP.2004.1327208},
isbn = {0-7803-8484-9},
issn = {1520-6149},
journal = {2004 IEEE International Conference on Acoustics, Speech, and Signal Processing},
keywords = {Acoustic signal detection,Daubechies wavelet coefficient histograms,Euclidean distance,Euclidean distance measure,Feature extraction,Filters,Histograms,Music information retrieval,Speech processing,Support vector machine classification,Support vector machines,Wavelet coefficients,audio signal processing,content-based music similarity search,content-based retrieval,emotion detection,feature extraction,learning (artificial intelligence),multiclass classification problem,multiple binary classification problem,music,music information retrieval,normalized representations,pattern classification,signal classification,similarity search,support vector machines,timbral feature extraction,wavelet filter,wavelet transforms},
pages = {705--708},
publisher = {IEEE},
title = {{Content-based music similarity search and emotion detection}},
url = {http://ieeexplore.ieee.org/document/1327208/},
volume = {5},
year = {2004}
}
@inproceedings{Knees2007,
abstract = {An approach is presented to automatically build a search engine for large-scale music collections that can be queried through natural language. While existing approaches depend on explicit manual annotations and meta-data assigned to the individual audio pieces, we automatically derive descriptions by making use of methods from Web Retrieval and Music Information Retrieval. Based on the ID3 tags of a collection of mp3 files, we retrieve relevant Web pages via Google queries and use the contents of these pages to characterize the music pieces and represent them by term vectors. By incorporating complementary information about acous tic similarity we are able to both reduce the dimensionality of the vector space and improve the performance of retrieval, i.e. the quality of the results. Furthermore, the usage of audio similarity allows us to also characterize audio pieces when there is no associated information found on the Web.},
address = {New York, New York, USA},
author = {Knees, Peter and Pohle, Tim and Schedl, Markus and Widmer, Gerhard},
booktitle = {Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval - SIGIR '07},
doi = {10.1145/1277741.1277818},
isbn = {9781595935977},
keywords = {context-based retrieval,cross-media retrieval,music information retrieval,music search engine,music similarity},
pages = {447},
publisher = {ACM Press},
title = {{A music search engine built upon audio-based and web-based similarity measures}},
url = {http://portal.acm.org/citation.cfm?doid=1277741.1277818},
year = {2007}
}
@inproceedings{Kim2009,
abstract = {A new algorithm for content-based audio information retrieval is introduced in this work. Assuming that there exist hidden acoustic topics and each audio clip is a mixture of those acoustic topics, we proposed a topic model that learns a probability distribution over a set of hidden topics of a given audio clip in an unsupervised manner. We use the Latent Dirichlet Allocation (LDA) method for the topic model, and introduce the notion of acoustic words for supporting modeling within this framework. In audio description classification tasks using Support Vector Machine (SVM) on the BBC database, the proposed acoustic topic model shows promising results by outperforming the Latent Perceptual Indexing (LPI) method in classifying onomatopoeia descriptions and semantic descriptions.},
author = {Kim, Samuel and Narayanan, Shrikanth and Sundaram, Shiva},
booktitle = {2009 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
doi = {10.1109/ASPAA.2009.5346483},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Narayanan, Sundaram - 2009 - Acoustic topic model for audio information retrieval.pdf:pdf},
isbn = {978-1-4244-3678-1},
month = {oct},
pages = {37--40},
publisher = {IEEE},
title = {{Acoustic topic model for audio information retrieval}},
url = {http://ieeexplore.ieee.org/document/5346483/},
year = {2009}
}
@article{McLoughlin2015,
abstract = {The automatic recognition of sound events by computers is an important aspect of emerging applications such as automated surveillance, machine hearing and auditory scene understanding. Recent advances in machine learning, as well as in computational models of the human auditory system, have contributed to advances in this increasingly popular research field. Robust sound event classification, the ability to recognise sounds under real-world noisy conditions, is an especially challenging task. Classification methods translated from the speech recognition domain, using features such as mel-frequency cepstral coefficients, have been shown to perform reasonably well for the sound event classification task, although spectrogram-based or auditory image analysis techniques reportedly achieve superior performance in noise. This paper outlines a sound event classification framework that compares auditory image front end features with spectrogram image-based front end features, using support vector machine and deep neural network classifiers. Performance is evaluated on a standard robust classification task in different levels of corrupting noise, and with several system enhancements, and shown to compare very well with current state-of-the-art classification techniques.},
author = {McLoughlin, Ian and Zhang, Haomin and Xie, Zhipeng and Song, Yan and Xiao, Wei},
doi = {10.1109/TASLP.2015.2389618},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/McLoughlin et al. - 2015 - Robust Sound Event Classification Using Deep Neural Networks.pdf:pdf},
isbn = {9781467300469},
issn = {2329-9290},
journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
keywords = {Auditory event detection,Auditory system,DNN,Feature extraction,Spectrogram,Speech,Speech processing,Support vector machines,Vectors,acoustic signal processing,auditory image front end feature,deep neural network,feature extraction,machine hearing,neural nets,signal classification,sound event classification,spectrogram image-based front end feature,support vector machine,support vector machines},
month = {mar},
number = {3},
pages = {540--552},
title = {{Robust Sound Event Classification Using Deep Neural Networks}},
url = {http://ieeexplore.ieee.org/document/7003973/},
volume = {23},
year = {2015}
}
@inproceedings{Lane2015,
abstract = {Microphones are remarkably powerful sensors of human be- havior and context. However, audio sensing is highly sus- ceptible to wild fluctuations in accuracy when used in di- verse acoustic environments (such as, bedrooms, vehicles, or cafes), that users encounter on a daily basis. Towards ad- dressing this challenge, we turn to the field of deep learn- ing; an area of machine learning that has radically changed related audio modeling domains like speech recognition. In this paper, we present DeepEar – the first mobile audio sens- ing framework built from coupled Deep Neural Networks (DNNs) that simultaneously perform common audio sens- ing tasks. We train DeepEar with a large-scale dataset in- cluding unlabeled data from 168 place visits. The resulting learned model, involving 2.3M parameters, enables DeepEar to significantly increase inference robustness to background noise beyond conventional approaches present in mobile de- vices. Finally, we show DeepEar is feasible for smartphones by building a cloud-free DSP-based prototype that runs con- tinuously, using only 6{\%} of the smartphone's battery daily.},
address = {New York, New York, USA},
author = {Lane, Nicholas D. and Georgiev, Petko and Qendro, Lorena},
booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing - UbiComp '15},
doi = {10.1145/2750858.2804262},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lane, Georgiev, Qendro - 2015 - DeepEar.pdf:pdf},
isbn = {9781450335744},
keywords = {audio sensing,deep learning,mobile sensing},
pages = {283--294},
publisher = {ACM Press},
title = {{DeepEar}},
url = {http://dl.acm.org/citation.cfm?doid=2750858.2804262},
year = {2015}
}
@inproceedings{Kim2009,
abstract = {A new algorithm for content-based audio information retrieval is introduced in this work. Assuming that there exist hidden acoustic topics and each audio clip is a mixture of those acoustic topics, we proposed a topic model that learns a probability distribution over a set of hidden topics of a given audio clip in an unsupervised manner. We use the Latent Dirichlet Allocation (LDA) method for the topic model, and introduce the notion of acoustic words for supporting modeling within this framework. In audio description classification tasks using Support Vector Machine (SVM) on the BBC database, the proposed acoustic topic model shows promising results by outperforming the Latent Perceptual Indexing (LPI) method in classifying onomatopoeia descriptions and semantic descriptions.},
author = {Kim, Samuel and Narayanan, Shrikanth and Sundaram, Shiva},
booktitle = {IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
doi = {10.1109/ASPAA.2009.5346483},
isbn = {9781424436798},
issn = {1931-1168},
month = {oct},
pages = {37--40},
publisher = {IEEE},
title = {{Acoustic topic model for audio information retrieval}},
url = {http://ieeexplore.ieee.org/document/5346483/},
year = {2009}
}
@article{Roma2010,
abstract = {In this paper we present a method to search for environmental sounds in large unstructured databases of user-submitted audio, using a general sound events taxonomy from ecological acoustics.We discuss the use of Support VectorMachines to classify sound recordings according to the taxonomy and describe two use cases for the obtained classificationmodels: a content-basedweb search interface for a large audio database and a method for segmenting field recordings to assist sound design.},
author = {Roma, Gerard and Janer, Jordi and Kersten, Stefan and Schirosa, Mattia and Herrera, Perfecto and Serra, Xavier},
doi = {10.1155/2010/960863},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Roma et al. - 2010 - Ecological Acoustics Perspective for Content-Based Retrieval of Environmental Sounds.pdf:pdf},
isbn = {1687-4714},
issn = {16874714},
journal = {Eurasip Journal on Audio, Speech, and Music Processing},
pages = {1--11},
publisher = {Hindawi Publishing Corp.},
title = {{Ecological acoustics perspective for content-based retrieval of environmental sounds}},
url = {http://asmp.eurasipjournals.com/content/2010/1/960863},
volume = {2010},
year = {2010}
}
@article{Kim2012,
abstract = {{\textcopyright} The Authors, 2012.We propose the notion of latent acoustic topics to capture contextual information embedded within a collection of audio signals. The central idea is to learn a probability distribution over a set of latent topics of a given audio clip in an unsupervised manner, assuming that there exist latent acoustic topics and each audio clip can be described in terms of those latent acoustic topics. In this regard, we use the latent Dirichlet allocation (LDA) to implement the acoustic topic models over elemental acoustic units, referred as acoustic words, and perform text-like audio signal processing. Experiments on audio tag classification with the BBC sound effects library demonstrate the usefulness of the proposed latent audio context modeling schemes. In particular, the proposed method is shown to be superior to other latent structure analysis methods, such as latent semantic analysis and probabilistic latent semantic analysis. We also demonstrate that topic models can be used as complementary features to content-based features and offer about 9{\%} relative improvement in audio classification when combined with the traditional Gaussian mixture model (GMM)-Support Vector Machine (SVM) technique.},
author = {Kim, Samuel and Georgiou, Panayiotis and Narayanan, Shrikanth},
doi = {10.1017/ATSIP.2012.7},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim, Georgiou, Narayanan - 2012 - Latent acoustic topic models for unstructured audio classification.pdf:pdf},
isbn = {2048770312},
issn = {17441382},
journal = {Journal of Institutional Economics},
keywords = {Acoustic topic models,Audio information retrieval,Latent topic models,Unstructured Audio,text-like audio signal processing},
month = {dec},
number = {2},
pages = {e6},
publisher = {Cambridge University Press},
title = {{Latent acoustic topic models for unstructured audio classification}},
url = {http://www.journals.cambridge.org/abstract{\_}S2048770312000078},
volume = {1},
year = {2012}
}
@inproceedings{Chechik2008,
abstract = {In content-based audio retrieval, the goal is to find sound recordings (audio documents) based on their acoustic features. This content-based approach differs from retrieval approaches that index media files using metadata such as file names and user tags. In this paper, we propose a machine learning approach for retrieving sounds that is novel in that it (1) uses free-form text queries rather sound sample based queries, (2) searches by audio content rather than via textual meta data, and (3) can scale to very large number of audio documents and very rich query vocabulary. We handle generic sounds, including a wide variety of sound effects, animal vocalizations and natural scenes. We test a scalable approach based on a passive-aggressive model for image retrieval (PAMIR), and compare it to two state-of-the-art approaches; Gaussian mixture models (GMM) and support vector machines (SVM). We test our approach on two large real-world datasets: a collection of short sound effects, and a noisier and larger collection of user-contributed user-labeled recordings (25K files, 2000 terms vocabulary). We find that all three methods achieved very good retrieval performance. For instance, a positive document is retrieved in the first position of the ranking more than half the time, and on average there are more than 4 positive documents in the first 10 retrieved, for both datasets. PAMIR completed both training and retrieval of all data in less than 6 hours for both datasets, on a single machine. It was one to three orders of magnitude faster than the competing approaches. This approach should therefore scale to much larger datasets in the future.},
address = {New York, New York, USA},
author = {Chechik, Gal and Ie, Eugene and Rehn, Martin and Bengio, Samy and Lyon, Dick},
booktitle = {Proceeding of the 1st ACM international conference on Multimedia information retrieval - MIR '08},
doi = {10.1145/1460096.1460115},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chechik et al. - 2008 - Large-scale content-based audio retrieval from text queries.pdf:pdf},
isbn = {9781605583129},
pages = {105},
publisher = {ACM Press},
title = {{Large-scale content-based audio retrieval from text queries}},
url = {http://portal.acm.org/citation.cfm?doid=1460096.1460115},
year = {2008}
}
@inproceedings{LiWei2005,
abstract = {In many applications, it is desirable to monitor a streaming time series for predefined patterns. In domains as diverse as the monitoring of space telemetry, patient intensive care data, and insect populations, where data streams at a high rate and the number of predefined patterns is large, it may be impossible for the comparison algorithm to keep up. We propose a novel technique that exploits the commonality among the predefined patterns to allow monitoring at higher bandwidths, while maintaining a guarantee of no false dismissals. Our approach is based on the widely used envelope-based lower bounding technique. Extensive experiments demonstrate that our approach achieves tremendous improvements in performance in the offline case, and significant improvements in the fastest possible arrival rate of the data stream that can be processed with guaranteed no false dismissal.},
author = {{Li Wei} and Keogh, Eamonn and {Van Herle}, Helga and Mafra-Neto, Agenor},
booktitle = {Fifth IEEE International Conference on Data Mining (ICDM'05)},
doi = {10.1109/ICDM.2005.28},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2005 - Atomic wedgie Efficient query filtering for streaming time series.pdf:pdf},
isbn = {0-7695-2278-5},
issn = {15504786},
pages = {490--497},
publisher = {IEEE},
title = {{Atomic Wedgie: Efficient Query Filtering for Streaming Times Series}},
url = {http://ieeexplore.ieee.org/document/1565716/},
year = {2005}
}
@article{Dasgupta2006,
abstract = {This text, extensively class-tested over a decade at UC Berkeley and UC San Diego, explains the fundamentals of algorithms in a story line that makes the material enjoyable and easy to digest. Emphasis is placed on understanding the crisp mathematical idea behind each algorithm, in a manner that is intuitive and rigorous without being unduly formal. Features include: The use of boxes to strengthen the narrative: pieces that provide historical context, descriptions of how the algorithms are used in practice, and excursions for the mathematically sophisticated. Carefully chosen advanced topics that can be skipped in a standard one-semester course, but can be covered in an advanced algorithms course or in a more leisurely two-semester sequence. An accessible treatment of linear programming introduces students to one of the greatest achievements in algorithms. An optional chapter on the quantum algorithm for factoring provides a unique peephole into this exciting topic. In addition to the text, DasGupta also offers a Solutions Manual, which is available on the Online Learning Center. "Algorithms is an outstanding undergraduate text, equally informed by the historical roots and contemporary applications of its subject. Like a captivating novel, it is a joy to read." Tim Roughgarden Stanford University},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Dasgupta, Sanjoy and Papadimitriou, Christos and Vazirani, Umesh},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dasgupta, Papadimitriou, Vazirani - 2006 - Algorithms.pdf:pdf},
isbn = {0073523402},
issn = {1098-6596},
keywords = {algorithms},
pages = {318},
pmid = {25246403},
title = {{Algorithms}},
url = {http://www.cse.ucsd.edu/{~}dasgupta/mcgrawhill/{\%}5Cnhttp://beust.com/algorithms.pdf{\%}5Cnhttp://www.e-booksdirectory.com/details.php?ebook=1050{\%}5Cnhttp://algorithmics.lsi.upc.edu/docs/Dasgupta-Papadimitriou-Vazirani.pdf},
year = {2006}
}
@article{Ivory2001,
author = {Ivory, Melody Y. and Hearst, Marti A.},
doi = {10.1145/503112.503114},
issn = {03600300},
journal = {ACM Computing Surveys},
month = {dec},
number = {4},
pages = {470--516},
title = {{The state of the art in automating usability evaluation of user interfaces}},
url = {http://portal.acm.org/citation.cfm?doid=503112.503114},
volume = {33},
year = {2001}
}
@article{doi:10.1142/S0219635212500069,
abstract = { In this work we present a new mechatronic platform for measuring behavior of nonhuman primates, allowing high reprogrammability and providing several possibilities of interactions. The platform is the result of a multidisciplinary design process, which has involved bio-engineers, developmental neuroscientists, primatologists, and roboticians to identify its main requirements and specifications. Although such a platform has been designed for the behavioral analysis of capuchin monkeys (Cebus apella), it can be used for behavioral studies on other nonhuman primates and children. First, a state-of-the-art principal approach used in nonhuman primate behavioral studies is reported. Second, the main advantages of the mechatronic approach are presented. In this section, the platform is described in all its parts and the possibility to use it for studies on learning mechanism based on intrinsic motivation discussed. Third, a pilot study on capuchin monkeys is provided and preliminary data are presented and discussed. },
annote = {PMID: 22744785},
author = {Taffoni, Fabrizio and Vespignani, Massimo and Formica, Domenico and Cavallo, Giuseppe and {Di Sorrentino}, Eugenia Polizzi and Sabbatini, Gloria and Truppa, Valentina and Mirolli, Marco and Baldassarre, Gianluca and Visalberghi, Elisabetta and Keller, Flavio and Guglielmelli, Eugenio},
doi = {10.1142/S0219635212500069},
journal = {Journal of Integrative Neuroscience},
number = {01},
pages = {87--101},
title = {{A mechatronic platform for behavioral analysis on nonhuman primates}},
url = {https://doi.org/10.1142/S0219635212500069},
volume = {11},
year = {2012}
}
@article{HART200886,
author = {Hart, Benjamin L and Hart, Lynette A and Pinter-Wollman, Noa},
doi = {https://doi.org/10.1016/j.neubiorev.2007.05.012},
issn = {0149-7634},
journal = {Neuroscience {\&} Biobehavioral Reviews},
keywords = {Cognitive behavior,Elephants,Higher order brain functions,Large brains,Memory},
number = {1},
pages = {86--98},
title = {{Large brains and cognition: Where do elephants fit in?}},
url = {http://www.sciencedirect.com/science/article/pii/S014976340700070X},
volume = {32},
year = {2008}
}
@article{Pepperberg1983,
abstract = {An African Grey parrot, previously taught to discriminate more than 40 objects by means of vocal labels, has now acquired a limited understanding of abstract class concepts. The subject, Alex, can routinely decode and successfully reply vocally to queries concerning either coloror shape for exemplars which simultaneously incorporate both variables (e.g., colored and shaped keys, wood, and rawhide).},
author = {Pepperberg, Irene M},
doi = {10.3758/BF03199646},
issn = {0090-4996},
journal = {Animal Learning {\&} Behavior},
month = {jun},
number = {2},
pages = {179--185},
title = {{Cognition in the African Grey parrot: Preliminary evidence for auditory/vocal comprehension of the class concept}},
url = {https://doi.org/10.3758/BF03199646 http://www.springerlink.com/index/10.3758/BF03199646},
volume = {11},
year = {1983}
}
@article{Perdue2012,
author = {Perdue, Bonnie M and Clay, {\~{A}} Andrea W and Gaalema, Diann E and Maple, Terry L and Stoinski, Tara S and Atlanta, Zoo and Zoo, Palm Beach and Beach, West Palm},
doi = {10.1002/zoo.20378},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Perdue et al. - 2012 - Technology at the Zoo The Influence of a Touchscreen Computer on Orangutans and Zoo Visitors.pdf:pdf},
number = {October 2010},
pages = {27--39},
title = {{Technology at the Zoo : The Influence of a Touchscreen Computer on Orangutans and Zoo Visitors}},
volume = {39},
year = {2012}
}
@article{Clark2017,
abstract = {“Cognitive enrichment” is a subset of enrichment that has gained interest from researchers over the past decade, particularly those working in zoos. This review explores the forms of cognitive enrichment that have been attempted for laboratory, farmed and zoo animals with a focus on the latter, including various definitions, aims, and approaches. This review reveals the fundamental theoretical and practical problems associated with cognitive enrichment, leading to recommendations for further research in this field. Critically, more research is needed to elucidate what makes challenges appropriate for certain taxa, acknowledging that individual differences exist. Going forward, we should be prepared to incorporate more computer technology into cognitive tasks, and examine novel welfare indicators such as flow, competence, and agency. Keywords},
author = {Clark, Fay},
doi = {10.12966/abc.05.02.2017},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Clark - 2017 - Cognitive enrichment and welfare Current approaches and future directions.pdf:pdf},
issn = {23725052},
journal = {Animal Behavior and Cognition},
keywords = {2016,TCPDF,agency,and behie,animal welfare,as stated by kim-mccormack,captive animal management,cognitive challenge,competence,context-dependent but broadly consists,environmental enrichment,flow,is now a routine,its definition is,of alterations or additions,or social,part of modern,shortened to enrichment,smith,the term,to the physical and,zoo},
number = {1},
pages = {52--71},
title = {{Cognitive enrichment and welfare: Current approaches and future directions}},
url = {http://www.animalbehaviorandcognition.org/article.php?id=907},
volume = {4},
year = {2017}
}
@inproceedings{Ritvo2014,
abstract = {Despite a marked increase in the number of hardware and software systems being adapted and designed specifically for nonhuman animals, to date, nearly all computer interaction design and assessment has been anthropocentric. Ironically, because nonhuman animals cannot provide, refuse, or withdraw consent to participate with ACI systems, valid and reliable evaluation of usability and user satisfaction is crucial. The current paper explores a) the potential benefits and costs of engaging in animal-computer interaction for nonhuman animal users, b) potential animal-computer interaction evaluation concerns, and c) the assessment of 'liking' and 'preference' in noncommunicative subjects.},
address = {New York, New York, USA},
author = {Ritvo, Sarah E. and Allison, Robert S.},
booktitle = {Proceedings of the 2014 Workshops on Advances in Computer Entertainment Conference - ACE '14 Workshops},
doi = {10.1145/2693787.2693795},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ritvo, Allison - 2014 - Challenges Related to Nonhuman Animal-Computer Interaction.pdf:pdf},
isbn = {9781450333146},
pages = {1--7},
publisher = {ACM Press},
title = {{Challenges Related to Nonhuman Animal-Computer Interaction}},
url = {http://dl.acm.org/citation.cfm?doid=2693787.2693795},
year = {2014}
}
@inproceedings{Pons2017,
abstract = {{\textcopyright} 2017 ACM. User-centered design applied to non-human animals is showing to be a promising research line known as Animal Computer Interaction (ACI), aimed at improving animals' wellbeing using technology. Within this research line, intelligent systems for animal entertainment could have remarkable benefits for their mental and physical wellbeing, while providing new ways of communication and amusement between humans and animals. In order to create user-centered interactive intelligent systems for animals, we first need to understand how they spontaneously interact with technology, and develop suitable mechanisms to adapt to the animals' observed interactions and preferences. Therefore, this paper describes a pioneer study on cats' preferences and behaviors with different technological devices. It also presents the design and evaluation of a promising depth-based tracking system for the detection of cats' body parts and postures. The contributions of this work lay foundations towards providing a framework for the development of future intelligent systems for animal entertainment.},
address = {New York, New York, USA},
author = {Pons, Patricia and Jaen, Javier and Catala, Alejandro},
booktitle = {Proceedings of the 22nd International Conference on Intelligent User Interfaces - IUI '17},
doi = {10.1145/3025171.3025175},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pons, Jaen, Catala - 2017 - Towards Future Interactive Intelligent Systems for Animals.pdf:pdf},
isbn = {9781450343480},
pages = {389--400},
publisher = {ACM Press},
title = {{Towards Future Interactive Intelligent Systems for Animals}},
url = {http://dl.acm.org/citation.cfm?doid=3025171.3025175},
year = {2017}
}
@article{Vonk2012,
abstract = {Despite their large relative brain size, bears have been neglected in studies of comparative cognition in comparison to their fellow carnivores, the social canines and pinnipeds. Here, three captive adult American black bears were presented with a series of natural concept discrimination tasks on a touchscreen computer, in which the discriminations varied in degree of abstraction. The more abstract discriminations could not be performed by attending to perceptual features of the stimuli alone. For instance, at the most abstract level, the bears were required to select images of animals rather than nonanimals, and exemplars within both categories were perceptually diverse. At least one bear performed at above-chance levels with transfer to novel images at each level of abstraction. The bear that began testing with the most abstract problems showed the best transfer on more abstract discriminations, suggesting that the usual practice of overtraining animals on perceptual discriminations may hinder their ability to acquire concepts at more abstract levels. The bears' performance suggests that a generalized diet may be more critical than group living with regard to the evolution of complex cognition in carnivores. {\textcopyright} 2012.},
author = {Vonk, Jennifer and Jett, Stephanie E. and Mosteller, Kelly W.},
doi = {10.1016/j.anbehav.2012.07.020},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Vonk, Jett, Mosteller - 2012 - Concept formation in American black bears, Ursus americanus.pdf:pdf},
isbn = {0003-3472},
issn = {00033472},
journal = {Animal Behaviour},
keywords = {Black bear,Cognition,Concept formation,Level of abstraction,Ursus americanus},
month = {oct},
number = {4},
pages = {953--964},
publisher = {Elsevier Ltd},
title = {{Concept formation in American black bears, Ursus americanus}},
url = {http://dx.doi.org/10.1016/j.anbehav.2012.07.020 http://linkinghub.elsevier.com/retrieve/pii/S0003347212003284},
volume = {84},
year = {2012}
}
@article{Pons2017a,
abstract = {There is growing interest in the automatic detection of animals' behaviors and body postures within the field of Animal Computer Interaction, and the benefits this could bring to animal welfare, enabling remote communication, welfare assessment, detection of behavioral patterns, interactive and adaptive systems, etc. Most of the works on animals' behavior recognition rely on wearable sensors to gather information about the animals' postures and movements, which are then processed using machine learning techniques. However, non-wearable mechanisms such as depth-based tracking could also make use of machine learning techniques and classifiers for the automatic detection of animals' behavior. These systems also offer the advantage of working in set-ups in which wearable devices would be difficult to use. This paper presents a depth-based tracking system for the automatic detection of animals' postures and body parts, as well as an exhaustive evaluation on the performance of several classification algorithms based on both a supervised and a knowledge-based approach. The evaluation of the depth-based tracking system and the different classifiers shows that the system proposed is promising for advancing the research on animals' behavior recognition within and outside the field of Animal Computer Interaction.},
author = {Pons, Patricia and Jaen, Javier and Catala, Alejandro},
doi = {10.1016/j.eswa.2017.05.063},
issn = {09574174},
journal = {Expert Systems with Applications},
keywords = {Animal Computer Interaction,Classification algorithms,Depth-based tracking,Intelligent system,Tracking system},
pages = {235--246},
title = {{Assessing machine learning classifiers for the detection of animals' behavior using depth-based tracking}},
volume = {86},
year = {2017}
}
@article{Jukan2016,
abstract = {Animals play a profoundly important and intricate role in our lives today. Dogs have been human companions for thousands of years, but they now work closely with us to assist the disabled, and in combat and search and rescue situations. Farm animals are a critical part of the global food supply chain, and there is increasing consumer interest in organically fed and humanely raised livestock, and how it impacts our health and environmental footprint. Wild animals are threatened with extinction by human induced factors, and shrinking and compromised habitat. This review sets the goal to systematically survey the existing literature in smart computing and sensing technologies for domestic, farm and wild animal welfare. We use the notion of $\backslash$emph{\{}animal welfare{\}} in broad terms, to review the technologies for assessing whether animals are healthy, free of pain and suffering, and also positively stimulated in their environment. Also the notion of $\backslash$emph{\{}smart computing and sensing{\}} is used in broad terms, to refer to computing and sensing systems that are not isolated but interconnected with communication networks, and capable of remote data collection, processing, exchange and analysis. We review smart technologies for domestic animals, indoor and outdoor animal farming, as well as animals in the wild and zoos. The findings of this review are expected to motivate future research and contribute to data, information and communication management as well as policy for animal welfare.},
archivePrefix = {arXiv},
arxivId = {1609.00627},
author = {Jukan, Admela and Masip-Bruin, Xavi and Amla, Nina},
doi = {10.1145/3041960},
eprint = {1609.00627},
isbn = {0360-0300},
issn = {03600300},
title = {{Smart Computing and Sensing Technologies for Animal Welfare: A Systematic Review}},
url = {http://arxiv.org/abs/1609.00627},
year = {2016}
}
@misc{Ritvo2017,
abstract = {As sophisticated computer technologies become more affordable, flexible, and accessible, there is increasing interest in their application to nonhuman animals. A limiting factor however, is that traditional computer design has been anthropocentric. Animal factors have not driven the design of the majority of computer technologies that have, or could be applied to this user population. The anthropocentric nature of current hardware and software may act as a barrier for successful animal-computer interaction (ACI). In this review, the authors consolidate literature from diverse disciplines including psychology, computer science, human-computer interaction, animal behaviour and welfare, biology, ergonomics, medicine, human factors and disability studies to explore (a) how human-computer interaction (HCI) principles may apply (or not apply) to ACI, (b) how principles and computer system designs exclusive for ACI may be developed, and (c) how animal-centered computer designs may benefit HCI and its user population.},
author = {Ritvo, Sarah E. and Allison, Robert S.},
booktitle = {Computers in Human Behavior},
doi = {10.1016/j.chb.2016.12.062},
isbn = {0747-5632},
issn = {07475632},
keywords = {ACI,Animal-computer interaction,Anthropocentric interface,Exceptional users,Inclusive design,User-centered design},
pages = {222--233},
title = {{Designing for the exceptional user: Nonhuman animal-computer interaction (ACI)}},
volume = {70},
year = {2017}
}
@article{Pons2015,
abstract = {{\textcopyright} 2015 ACM.Digital games for animals within Animal Computer Interaction are usually single-device oriented, however richer interactions could be delivered by considering multimodal environments and expanding the number of technological elements involved. In these playful ecosystems, animals could be either alone or accompanied by human beings, but in both cases the system should react properly to the interactions of all the players, creating more engaging and natural games. Technologically-mediated playful scenarios for animals will therefore require contextual information about the game participants, such as their location or body posture, in order to suitably adapt the system reactions. This paper presents a depth-based tracking system for cats capable of detecting their location, body posture and field of view. The proposed system could also be extended to locate and detect human gestures and track small robots, becoming a promising component in the creation of intelligent interspecies playful environments.},
author = {Pons, Patricia and Jaen, Javier and Catala, Alejandro},
doi = {10.1145/2832932.2837007},
isbn = {9781450338523},
journal = {Proceedings of the 12th International Conference on Advances in Computer Entertainment Technology - ACE '15},
keywords = {animal computer interaction,depth-based tracking,interaction design,play,smart environment,tracking system},
pages = {1--8},
title = {{Developing a depth-based tracking system for interactive playful environments with animals}},
url = {http://dl.acm.org/citation.cfm?doid=2832932.2837007},
year = {2015}
}
@article{Filippi2017,
abstract = {PF, 0000-0002-2990-9344; DLB, 0000-0002-5303-5472; SAR, 0000-0002-8819-7009; AP, 0000-0002-5742-8222 Writing over a century ago, Darwin hypothesized that vocal expression of emotion dates back to our earliest terrestrial ancestors. If this hypothesis is true, we should expect to find cross-species acoustic universals in emotional vocalizations. Studies suggest that acoustic attributes of aroused vocalizations are shared across many mammalian species, and that humans can use these attributes to infer emotional content. But do these acoustic attributes extend to non-mammalian vertebrates? In this study, we asked human participants to judge the emotional content of vocalizations of nine vertebrate species repre-senting three different biological classes—Amphibia, Reptilia (non-aves and aves) and Mammalia. We found that humans are able to identify higher levels of arousal in vocalizations across all species. This result was consistent across different language groups (English, German and Mandarin native speakers), suggesting that this ability is biologically rooted in humans. Our findings indicate that humans use multiple acoustic parameters to infer relative arousal in vocalizations for each species, but mainly rely on fundamen-tal frequency and spectral centre of gravity to identify higher arousal vocalizations across species. These results suggest that fundamental mechan-isms of vocal emotional expression are shared among vertebrates and could represent a homologous signalling system.},
author = {Filippi, Piera and Congdon, Jenna V. and Hoang, John and Bowling, Daniel L. and Reber, Stephan A. and Pa{\v{s}}ukonis, Andrius and Hoeschele, Marisa and Ocklenburg, Sebastian and de Boer, Bart and Sturdy, Christopher B. and Newen, Albert and G{\"{u}}nt{\"{u}}rk{\"{u}}n, Onur},
doi = {10.1098/rspb.2017.0990},
file = {:C$\backslash$:/Users/logas/Downloads/20170990.full.pdf:pdf},
isbn = {0000000257428},
issn = {14712954},
journal = {Proceedings of the Royal Society B: Biological Sciences},
keywords = {Acoustic universals,Cross-species communication,Emotional arousal,Emotional prosody,Language evolution,Vocal communication},
number = {1859},
pmid = {28747478},
title = {{Humans recognize emotional arousal in vocalizations across all classes of terrestrial vertebrates: Evidence for acoustic universals}},
volume = {284},
year = {2017}
}
@inproceedings{Brugarolas2016,
abstract = {{\textcopyright} 2016 IEEE.Although numerous advances have been made in instrumental odor detection systems, these still cannot match the efficient sampling, odor discrimination, agile mobility and the olfactory acuity of odor detection dogs. A limiting step in using dogs to detect odors is the subjectivity of the translation of odor information processed by the dog to its handler. We present our preliminary efforts towards a wireless wearable system for continuous auscultation of respiratory behavior by recording internal sounds at the neck and chest by means of a commercially available electronic stethoscope to provide objective decision support for handlers. We have identified discrete features of sniffing and panting in the time domain and utilize event duration, event rate, event mean energy, and the number of consecutive events in a row to build a decision tree classifier. Since feature extraction requires segmentation of individual sniffing and panting events, we developed an adaptive method using short-time energy contour and an adaptive threshold. The performance of the system was evaluated on recordings from a Greyhound and a Labrador Retriever and achieved high classification accuracies.},
author = {Brugarolas, R. and Agcayazi, T. and Yuschak, S. and Roberts, D. L. and Sherman, B. L. and Bozkurt, A.},
booktitle = {BSN 2016 - 13th Annual Body Sensor Networks Conference},
doi = {10.1109/BSN.2016.7516276},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brugarolas et al. - 2016 - Towards a wearable system for continuous monitoring of sniffing and panting in dogs.pdf:pdf},
isbn = {9781509030873},
pages = {292--295},
title = {{Towards a wearable system for continuous monitoring of sniffing and panting in dogs}},
year = {2016}
}
@inproceedings{Feng2012,
abstract = {The increasing use of statistical data analysis in enterprise applications has created an arms race among database vendors to offer ever more sophisticated in-database analytics. One challenge in this race is that each new statistical technique must be implemented from scratch in the RDBMS, which leads to a lengthy and complex development process. We argue that the root cause for this overhead is the lack of a unified architecture for in-database analytics. Our main contribution in this work is to take a step towards such a unified architecture. A key benefit of our unified architecture is that performance optimizations for analytics techniques can be studied generically instead of an ad hoc, per-technique fashion. In particular, our technical contributions are theoretical and empirical studies of two key factors that we found impact performance: the order data is stored, and parallelization of computations on a single-node multicore RDBMS. We demonstrate the feasibility of our architecture by integrating several popular analytics techniques into two commercial and one open-source RDBMS. Our architecture requires changes to only a few dozen lines of code to integrate a new statistical technique. We then compare our approach with the native analytics tools offered by the commercial RDBMSes on various analytics tasks, and validate that our approach achieves competitive or higher performance, while still achieving the same quality.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1203.2574},
author = {Feng, Xixuan and Kumar, Arun and Recht, Benjamin and R{\'{e}}, Christopher},
booktitle = {Proceedings of the 2012 international conference on Management of Data - SIGMOD '12},
doi = {10.1145/2213836.2213874},
eprint = {1203.2574},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Feng et al. - 2012 - Towards a unified architecture for in-RDBMS analytics.pdf:pdf},
isbn = {9781450312479},
issn = {07308078},
pages = {325},
publisher = {ACM Press},
title = {{Towards a unified architecture for in-RDBMS analytics}},
url = {http://arxiv.org/abs/1203.2574 http://dl.acm.org/citation.cfm?doid=2213836.2213874},
year = {2012}
}
@inproceedings{Wasay2017,
abstract = {During exploratory statistical analysis, data scientists repeatedly compute statistics on data sets to infer knowledge. Moreover, statis-tics form the building blocks of core machine learning classifi-cation and filtering algorithms. Modern data systems, software libraries, and domain-specific tools provide support to compute statistics but lack a cohesive framework for storing, organizing, and reusing them. This creates a significant problem for exploratory statistical analysis as data grows: Despite existing overlap in ex-ploratory workloads (which are repetitive in nature), statistics are always computed from scratch. This leads to repeated data move-ment and recomputation, hindering interactive data exploration. We address this challenge in Data Canopy, where descriptive and dependence statistics are synthesized from a library of basic ag-gregates. These basic aggregates are stored within an in-memory data structure, and and are reused for overlapping data parts and for various statistical measures What this means for exploratory statis-tical analysis is that repeated requests to compute different statis-tics do not trigger a full pass over the data. We discuss in detail the basic design elements in Data Canopy, which address multiple challenges: (1) How to decompose statistics into basic aggregates for maximal reuse? (2) How to represent, store, maintain, and ac-cess these basic aggregates? (3) Under different scenarios, which basic aggregates to maintain? (4) How to tune Data Canopy in a hardware conscious way for maximum performance and how to maintain good performance as data grows and memory pressure increases? We demonstrate experimentally that Data Canopy results in an average speed-up of at least 10× after just 100 exploratory queries when compared with state-of-the-art systems used for exploratory statistical analysis.},
address = {New York, New York, USA},
author = {Wasay, Abdul and Wei, Xinding and Dayan, Niv and Idreos, Stratos},
booktitle = {Proceedings of the 2017 ACM International Conference on Management of Data - SIGMOD '17},
doi = {10.1145/3035918.3064051},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wasay et al. - 2017 - Data Canopy.pdf:pdf},
isbn = {9781450341974},
issn = {07308078},
pages = {557--572},
publisher = {ACM Press},
title = {{Data Canopy}},
url = {http://dl.acm.org/citation.cfm?doid=3035918.3064051},
year = {2017}
}
@article{Krishnan2018,
abstract = {Exhaustive enumeration of all possible join orders is often avoided, and most optimizers leverage heuristics to prune the search space. The design and implementation of heuristics are well-understood when the cost model is roughly linear, and we find that these heuristics can be significantly suboptimal when there are non-linearities in cost. Ideally, instead of a fixed heuristic, we would want a strategy to guide the search space in a more data-driven way---tailoring the search to a specific dataset and query workload. Recent work in deep reinforcement learning (Deep RL) may provide a new perspective on this problem. Deep RL poses sequential problems, like join optimization, as a series of 1-step prediction problems that can be learned from data. We present our deep RL-based DQ optimizer, which currently optimizes select-project-join blocks, and we evaluate DQ on the Join Order Benchmark. We found that DQ achieves plan costs within a factor of 2 of the optimal solution on all cost models and improves on the next best heuristic by up to {\$}3\backslashtimes{\$}. Furthermore, DQ executes 10,000{\$}\backslashtimes{\$} faster than exhaustive enumeration and more than 10{\$}\backslashtimes{\$} faster than left/right-deep enumeration on the largest queries in the benchmark.},
archivePrefix = {arXiv},
arxivId = {1808.03196},
author = {Krishnan, Sanjay and Yang, Zongheng and Goldberg, Ken and Hellerstein, Joseph and Stoica, Ion},
eprint = {1808.03196},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Krishnan et al. - 2018 - Learning to Optimize Join Queries With Deep Reinforcement Learning.pdf:pdf},
month = {aug},
title = {{Learning to Optimize Join Queries With Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1808.03196},
year = {2018}
}
@article{Jeffrey2017,
abstract = {Enterprises increasingly employ a wide array of tools and processes to make data-driven decisions. However, there are large inefficiencies in the enterprise-wide workflow that stem from the fact that business workflows are expressed in nat-ural language but the actual computational workflow has to be manually translated into computational programs. In this paper, we present an initial approach to bridge this gap by targeting the data science component of enterprise work-flows. In many cases, this component is the slowest part of the overall enterprise process, and focusing on it allows us to take an initial step in solving the larger enterprise-wide pro-ductivity problem. In this initial approach, we propose using a chatbot to allow a data scientist to assemble data analytics pipelines. A crucial insight is that while precise interpreta-tion of general natural language continues to be challenging, controlled natural language methods are starting to become practical as natural interfaces in complex decision-making domains. In addition, we recognize that data science work-flow components are often templatized. Putting these two insights together, we develop a practical system, called Ava, that uses (controlled) natural language to program data sci-ence workflows. We have an initial proof-of-concept that demonstrates the potential of our approach.},
author = {Jeffrey, Rogers and John, Leo},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jeffrey, John - 2017 - Ava From Data to Insights Through Conversation.pdf:pdf},
journal = {Cidr},
title = {{Ava : From Data to Insights Through Conversation}},
url = {https://pdfs.semanticscholar.org/168f/f6d977c0e2267223f189cfa70555851def54.pdf},
year = {2017}
}
@article{Poms2018,
abstract = {A growing number of visual computing applications depend on the analysis of large video collections. The challenge is that scaling applications to operate on these datasets requires efficient systems for pixel data access and parallel processing across large numbers of machines. Few programmers have the capability to operate efficiently at these scales, limiting the field's ability to explore new applications that leverage big video data. In response, we have created Scanner, a system for productive and efficient video analysis at scale. Scanner organizes video collections as tables in a data store optimized for sampling frames from compressed video, and executes pixel processing computations, expressed as dataflow graphs, on these frames. Scanner schedules video analysis applications expressed using these abstractions onto heterogeneous throughput computing hardware, such as multi-core CPUs, GPUs, and media processing ASICs, for high-throughput pixel processing. We demonstrate the productivity of Scanner by authoring a variety of video processing applications including the synthesis of stereo VR video streams from multi-camera rigs, markerless 3D human pose reconstruction from video, and data-mining big video datasets such as hundreds of feature-length films or over 70,000 hours of TV news. These applications achieve near-expert performance on a single machine and scale efficiently to hundreds of machines, enabling formerly long-running big video data analysis tasks to be carried out in minutes to hours.},
archivePrefix = {arXiv},
arxivId = {1805.07339},
author = {Poms, Alex and Crichton, Will and Hanrahan, Pat and Fatahalian, Kayvon},
doi = {10.1145/3197517.3201394},
eprint = {1805.07339},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Poms et al. - 2018 - Scanner.pdf:pdf},
issn = {07300301},
journal = {ACM Transactions on Graphics},
month = {jul},
number = {4},
pages = {1--13},
title = {{Scanner}},
url = {http://arxiv.org/abs/1805.07339{\%}0Ahttp://dx.doi.org/10.1145/3197517.3201394 http://dl.acm.org/citation.cfm?doid=3197517.3201394},
volume = {37},
year = {2018}
}
@inproceedings{VanAken2017,
abstract = {Database management system (DBMS) configuration tuning is an essential aspect of any data-intensive application effort. But this is historically a difficult task because DBMSs have hundreds of configuration " knobs " that control everything in the system, such as the amount of memory to use for caches and how often data is written to storage. The problem with these knobs is that they are not standardized (i.e., two DBMSs use a different name for the same knob), not independent (i.e., changing one knob can impact others), and not universal (i.e., what works for one application may be sub-optimal for another). Worse, information about the effects of the knobs typically comes only from (expensive) experience. To overcome these challenges, we present an automated approach that leverages past experience and collects new information to tune DBMS configurations: we use a combination of supervised and un-supervised machine learning methods to (1) select the most impact-ful knobs, (2) map unseen database workloads to previous work-loads from which we can transfer experience, and (3) recommend knob settings. We implemented our techniques in a new tool called OtterTune and tested it on three DBMSs. Our evaluation shows that OtterTune recommends configurations that are as good as or better than ones generated by existing tools or a human expert.},
address = {New York, New York, USA},
author = {{Van Aken}, Dana and Pavlo, Andrew and Gordon, Geoffrey J. and Zhang, Bohan},
booktitle = {Proceedings of the 2017 ACM International Conference on Management of Data - SIGMOD '17},
doi = {10.1145/3035918.3064029},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Aken et al. - 2017 - Automatic Database Management System Tuning Through Large-scale Machine Learning.pdf:pdf},
isbn = {9781450341974},
issn = {07308078},
keywords = {autonomic compu,database tuning,machine learning},
pages = {1009--1024},
publisher = {ACM Press},
title = {{Automatic Database Management System Tuning Through Large-scale Machine Learning}},
url = {http://dl.acm.org/citation.cfm?doid=3035918.3064029},
year = {2017}
}
@article{Zhang2017,
abstract = {Video cameras are pervasively deployed for security and smart city scenarios, with millions of them in large cities worldwide. Achieving the potential of these cam-eras requires efficiently analyzing the live videos in real-time. We describe VideoStorm, a video analytics system that processes thousands of video analytics queries on live video streams over large clusters. Given the high costs of vision processing, resource management is cru-cial. We consider two key characteristics of video ana-lytics: resource-quality tradeoff with multi-dimensional configurations, and variety in quality and lag goals. VideoStorm's offline profiler generates query resource-quality profile, while its online scheduler allocates re-sources to queries to maximize performance on quality and lag, in contrast to the commonly used fair sharing of resources in clusters. Deployment on an Azure clus-ter of 101 machines shows improvement by as much as 80{\%} in quality of real-world queries and 7× better lag, processing video from operational traffic cameras.},
author = {Zhang, Haoyu and Ananthanarayanan, Ganesh and Bod$\backslash$'$\backslash$ik, Peter and Philipose, Matthai and Bahl, Paramvir and Freedman, Michael J},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - Live Video Analytics at Scale with Approximation and Delay-Tolerance.pdf:pdf},
isbn = {9781931971379},
journal = {Nsdi},
keywords = {Video Analytics, Big Data Analytics, Cloud Computi},
pages = {377--392},
title = {{Live Video Analytics at Scale with Approximation and Delay-Tolerance}},
url = {https://www.usenix.org/conference/nsdi17/technical-sessions/presentation/zhang},
year = {2017}
}
@inproceedings{Ma2018,
abstract = {The first step towards an autonomous database management system (DBMS) is the ability to model the target application's workload. This is necessary to allow the system to anticipate future work-load needs and select the proper optimizations in a timely manner. Previous forecasting techniques model the resource utilization of the queries. Such metrics, however, change whenever the physical design of the database and the hardware resources change, thereby rendering previous forecasting models useless. We present a robust forecasting framework called QueryBot 5000 that allows a DBMS to predict the expected arrival rate of queries in the future based on historical data. To better support highly dynamic environments, our approach uses the logical composition of queries in the workload rather than the amount of physical resources used for query execution. It provides multiple horizons (short-vs. long-term) with different aggregation intervals. We also present a clustering-based technique for reducing the total number of forecasting models to maintain. To evaluate our approach, we compare our forecasting models against other state-of-the-art models on three real-world database traces. We implemented our models in an external controller for PostgreSQL and MySQL and demonstrate their effectiveness in selecting indexes.},
address = {New York, New York, USA},
author = {Ma, Lin and {Van Aken}, Dana and Hefny, Ahmed and Mezerhane, Gustavo and Pavlo, Andrew and Gordon, Geoffrey J},
booktitle = {Proceedings of the 2018 International Conference on Management of Data - SIGMOD '18},
doi = {10.1145/3183713.3196908},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma et al. - 2018 - Query-based Workload Forecasting for Self-Driving Database Management Systems.pdf:pdf},
isbn = {9781450347037},
issn = {07308078},
pages = {631--645},
publisher = {ACM Press},
title = {{Query-based Workload Forecasting for Self-Driving Database Management Systems}},
url = {https://doi.org/10.1145/3183713.3196908 http://dl.acm.org/citation.cfm?doid=3183713.3196908},
year = {2018}
}
@article{Ortiz2018,
abstract = {Deep reinforcement learning is quickly changing the field of artificial intelligence. These models are able to capture a high level understanding of their environment, enabling them to learn difficult dynamic tasks in a variety of domains. In the database field, query optimization remains a difficult problem. Our goal in this work is to explore the capabilities of deep reinforcement learning in the context of query optimization. At each state, we build queries incrementally and encode properties of subqueries through a learned representation. The challenge here lies in the formation of the state transition function, which defines how the current subquery state combines with the next query operation (action) to yield the next state. As a first step in this direction, we focus the state representation problem and the formation of the state transition function. We describe our approach and show preliminary results. We further discuss how we can use the state representation to improve query optimization using reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {1803.08604},
author = {Ortiz, Jennifer and Balazinska, Magdalena and Gehrke, Johannes and Keerthi, S. Sathiya},
eprint = {1803.08604},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ortiz et al. - 2018 - Learning State Representations for Query Optimization with Deep Reinforcement Learning.pdf:pdf},
isbn = {9781450358286},
month = {mar},
number = {Section 4},
title = {{Learning State Representations for Query Optimization with Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1803.08604},
year = {2018}
}
@article{Mahajan2018,
abstract = {The data revolution is fueled by advances in several areas, including databases, high-performance computer architecture, and machine learning. Although timely, there is a void of solutions that brings these disjoint directions together. This paper sets out to be the initial step towards such a union. The aim is to devise a solution for the in-Database Acceleration of Advanced Analytics (DAnA). DAnA empowers database users to leap beyond traditional data summarization techniques and seamlessly utilize hardware-accelerated machine learning. Deploying specialized hardware, such as FPGAs, for in-database analytics currently requires hand-designing the hardware and manually routing the data. Instead, DAnA automatically maps a high-level specification of in-database analytics queries to the FPGA accelerator. The accelerator implementation is generated from a User Defined Function (UDF), expressed as part of a SQL query in a Python-embedded Domain Specific Language (DSL). To realize efficient in-database integration, DAnA accelerators contain a novel hardware structure, Striders, that directly interface with the buffer pool of the database. DAnA obtains the schema and page layout information from the database catalog to configure the Striders. In turn, Striders extract, cleanse, and process the training data tuples, which are consumed by a multi-threaded FPGA engine that executes the analytics algorithm. We integrated DAnA with PostgreSQL to generate hardware accelerators for a range of real-world and synthetic datasets running diverse ML algorithms. Results show that DAnA-enhanced PostgreSQL provides, on average, 11.3x end-to-end speedup than MADLib and 5.4x faster than multi-threaded MADLib running on Greenplum. DAnA provides these benefits while hiding the complexity of hardware design from data scientists and allowing them to express the algorithm in 30-60 lines of Python.},
archivePrefix = {arXiv},
arxivId = {1801.06027},
author = {Mahajan, Divya and Kim, Joon Kyung and Sacks, Jacob and Ardalan, Adel and Kumar, Arun and Esmaeilzadeh, Hadi},
doi = {arXiv:1801.06027v1},
eprint = {1801.06027},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahajan et al. - 2018 - In-RDBMS Hardware Acceleration of Advanced Analytics.pdf:pdf},
month = {jan},
title = {{In-RDBMS Hardware Acceleration of Advanced Analytics}},
url = {http://arxiv.org/abs/1801.06027},
year = {2018}
}
@inproceedings{VanRenen2018,
abstract = {Non-volatile memory (NVM) is a new storage technology that combines the performance and byte addressability of DRAM with the persistence of traditional storage devices like flash (SSD). While these properties make NVM highly promising, it is not yet clear how to best integrate NVM into the storage layer of modern database systems. Two system designs have been proposed. The first is to use NVM exclusively, i.e., to store all data and index structures on it. However, because NVM has a higher latency than DRAM, this design can be less efficient than main-memory database systems. For this reason, the second approach uses a page-based DRAM cache in front of NVM. This approach, however, does not utilize the byte addressability of NVM and, as a result, accessing an uncached tuple on NVM requires retrieving an entire page. In this work, we evaluate these two approaches and compare them with in-memory databases as well as more traditional buffer managers that use main memory as a cache in front of SSDs. This al-lows us to determine how much performance gain can be expected from NVM. We also propose a lightweight storage manager that si-multaneously supports DRAM, NVM, and flash. Our design utilizes the byte addressability of NVM and uses it as an additional caching layer that improves performance without losing the benefits from the even faster DRAM and the large capacities of SSDs.},
address = {New York, New York, USA},
author = {van Renen, Alexander and Leis, Viktor and Kemper, Alfons and Neumann, Thomas and Hashida, Takushi and Oe, Kazuichi and Doi, Yoshiyasu and Harada, Lilian and Sato, Mitsuru},
booktitle = {Proceedings of the 2018 International Conference on Management of Data - SIGMOD '18},
doi = {10.1145/3183713.3196897},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/van Renen et al. - 2018 - Managing Non-Volatile Memory in Database Systems.pdf:pdf},
isbn = {9781450347037},
issn = {07308078},
pages = {1541--1555},
publisher = {ACM Press},
title = {{Managing Non-Volatile Memory in Database Systems}},
url = {https:{\%}0Ahttps://doi.org/10.1145/3183713.3196897. http://dl.acm.org/citation.cfm?doid=3183713.3196897},
volume = {18},
year = {2018}
}
@article{Li2016,
abstract = {As data sets grow and conventional processor performance scaling slows, data analytics move towards heterogeneous architectures that incorporate hardware accelerators (notably GPUs) to continue scaling performance. However, existing GPU-based databases fail to deal with big data applications efficiently: their execution model suffers from scalability limitations on GPUs whose memory capacity is limited; existing systems fail to consider the discrepancy between fast GPUs and slow storage, which can counteract the benefit of GPU accelerators. In this paper, we propose HippogriffDB, an efficient, scalable GPU-accelerated OLAP system. It tackles the bandwidth discrepancy using compression and an optimized data transfer path. HippogriffDB stores tables in a compressed format and uses the GPU for decompression, trading GPU cycles for the improved I/O bandwidth. To improve the data transfer efficiency, HippogriffDB introduces a peer-to-peer, multi-threaded data transfer mechanism, directly transferring data from the SSD to the GPU. HippogriffDB adopts a query-over-block execution model that provides scalability using a stream-based approach. The model improves kernel efficiency with the operator fusion and double buffering mechanism. We have implemented HippogriffDB using an NVMe SSD, which talks directly to a commercial GPU. Results on two popular benchmarks demonstrate its scalability and efficiency. HippogriffDB outperforms existing GPU-based databases (YDB) and in-memory data analytics (MonetDB) by 1-2 orders of magnitude.},
author = {Li, Jing and Tseng, Hung-Wei and Lin, Chunbin and Papakonstantinou, Yannis and Swanson, Steven},
doi = {10.14778/3007328.3007331},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2016 - HippogriffDB.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
month = {oct},
number = {14},
pages = {1647--1658},
title = {{HippogriffDB}},
url = {http://dx.doi.org/10.14778/3007328.3007331 http://dl.acm.org/citation.cfm?doid=3007328.3007331},
volume = {9},
year = {2016}
}
@inproceedings{Yan2017,
abstract = {Many modern database-backed web applications are built upon Object Relational Mapping (ORM) frameworks. While such frame-works ease application development by abstracting persistent data as objects, such convenience comes with a performance cost. In this paper, we studied 27 real-world open-source applications built on top of the popular Ruby on Rails ORM framework, with the goal to understand the database-related performance inefficiencies in these applications. We discovered a number of inefficiencies rang-ing from physical design issues to how queries are expressed in the application code. We applied static program analysis to identify and measure how prevalent these issues are, then suggested techniques to alleviate these issues and measured the potential performance gain as a result. These techniques significantly reduce database query time (up to 91{\%}) and the webpage response time (up to 98{\%}). Our study provides guidance to the design of future database en-gines and ORM frameworks to support database application that are performant yet without sacrificing programmability.},
address = {New York, New York, USA},
author = {Yan, Cong and Cheung, Alvin and Yang, Junwen and Lu, Shan},
booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management - CIKM '17},
doi = {10.1145/3132847.3132954},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yan et al. - 2017 - Understanding Database Performance Inefficiencies in Real-world Web Applications.pdf:pdf},
isbn = {9781450349185},
pages = {1299--1308},
publisher = {ACM Press},
title = {{Understanding Database Performance Inefficiencies in Real-world Web Applications}},
url = {http://dl.acm.org/citation.cfm?doid=3132847.3132954},
year = {2017}
}
@inproceedings{Sharma2018,
abstract = {Context: Databases are an integral element of enterprise applications. Similarly to code, database schemas are also prone to smells - best practice violations. Objective: We aim to explore database schema quality, associated characteristics and their relationships with other software artifacts. Method: We present a catalog of 13 database schema smells and elicit developers' perspective through a survey. We extract embedded sql statements and identify database schema smells by employing the DbDeo tool which we developed. We analyze 2925 production-quality systems (357 industrial and 2568 well-engineered open-source projects) and empirically study quality characteristics of their database schemas. In total, we analyze 629 million lines of code containing more than 393 thousand sql statements. Results: We find that the index abuse smell occurs most frequently in database code, that the use of an orm framework doesn't immune the application from database smells, and that some database smells, such as adjacency list, are more prone to occur in industrial projects compared to open-source projects. Our co-occurrence analysis shows that whenever the clone table smell in industrial projects and the values in attribute definition smell in open-source projects get spotted, it is very likely to find other database smells in the project. Conclusion: The awareness and knowledge of database smells are crucial for developing high-quality software systems and can be enhanced by the adoption of better tools helping developers to identify database smells early.},
address = {New York, New York, USA},
author = {Sharma, Tushar and Fragkoulis, Marios and Rizou, Stamatia and Bruntink, Magiel and Spinellis, Diomidis},
booktitle = {Proceedings of the 40th International Conference on Software Engineering Software Engineering in Practice - ICSE-SEIP '18},
doi = {10.1145/3183519.3183529},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sharma et al. - 2018 - Smelly relations.pdf:pdf},
isbn = {9781450356596},
keywords = {acm reference format,antipatterns,code smells,database schema smells,ity,software maintenance,software qual-,technical debt},
pages = {55--64},
publisher = {ACM Press},
title = {{Smelly relations}},
url = {http://dl.acm.org/citation.cfm?doid=3183519.3183529},
year = {2018}
}
@article{Mitzenmacher2018,
abstract = {Recent work has suggested enhancing Bloom filters by using a pre-filter, based on applying machine learning to model the data set the Bloom filter is meant to represent. Here we model such learned Bloom filters, clarifying what guarantees can and cannot be associated with such a structure.},
archivePrefix = {arXiv},
arxivId = {1802.00884},
author = {Mitzenmacher, Michael},
eprint = {1802.00884},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitzenmacher - 2018 - A Model for Learned Bloom Filters and Related Structures.pdf:pdf},
month = {feb},
title = {{A Model for Learned Bloom Filters and Related Structures}},
url = {http://arxiv.org/abs/1802.00884},
year = {2018}
}
@article{Xu2017,
abstract = {Synthesizing SQL queries from natural language is a long-standing open problem and has been attracting considerable interest recently. Toward solving the problem, the de facto approach is to employ a sequence-to-sequence-style model. Such an approach will necessarily require the SQL queries to be serialized. Since the same SQL query may have multiple equivalent serializations, training a sequence-to-sequence-style model is sensitive to the choice from one of them. This phenomenon is documented as the "order-matters" problem. Existing state-of-the-art approaches rely on reinforcement learning to reward the decoder when it generates any of the equivalent serializations. However, we observe that the improvement from reinforcement learning is limited. In this paper, we propose a novel approach, i.e., SQLNet, to fundamentally solve this problem by avoiding the sequence-to-sequence structure when the order does not matter. In particular, we employ a sketch-based approach where the sketch contains a dependency graph so that one prediction can be done by taking into consideration only the previous predictions that it depends on. In addition, we propose a sequence-to-set model as well as the column attention mechanism to synthesize the query based on the sketch. By combining all these novel techniques, we show that SQLNet can outperform the prior art by 9{\%} to 13{\%} on the WikiSQL task.},
archivePrefix = {arXiv},
arxivId = {1711.04436},
author = {Xu, Xiaojun and Liu, Chang and Song, Dawn},
eprint = {1711.04436},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu, Liu, Song - 2017 - SQLNet Generating Structured Queries From Natural Language Without Reinforcement Learning.pdf:pdf},
month = {nov},
pages = {1--13},
title = {{SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning}},
url = {http://arxiv.org/abs/1711.04436},
year = {2017}
}
@inproceedings{Idreos2018,
abstract = {Data structures are critical in any data-driven scenario, but they are notoriously hard to design due to a massive design space and the dependence of performance on workload and hardware which evolve continuously. We present a design engine, the Data Cal-culator, which enables interactive and semi-automated design of data structures. It brings two innovations. First, it o{\"{i}}¿¿ers a set of {\"{i}}¿¿ne-grained design primitives that capture the {\"{i}}¿¿rst principles of data layout design: how data structure nodes lay data out, and how they are positioned relative to each other. This allows for a structured description of the universe of possible data structure designs that can be synthesized as combinations of those primi-tives. The second innovation is computation of performance using learned cost models. These models are trained on diverse hardware and data pro{\"{i}}¿¿les and capture the cost properties of fundamental data access primitives (e.g., random access). With these models, we synthesize the performance cost of complex operations on arbi-trary data structure designs without having to: 1) implement the data structure, 2) run the workload, or even 3) access the target hardware. We demonstrate that the Data Calculator can assist data structure designers and researchers by accurately answering rich what-if design questions on the order of a few seconds or minutes, i.e., computing how the performance (response time) of a given data structure design is impacted by variations in the: 1) design, 2) hardware, 3) data, and 4) query workloads. This makes it e{\"{i}}¿¿ortless to test numerous designs and ideas before embarking on lengthy implementation, deployment, and hardware acquisition steps. We also demonstrate that the Data Calculator can synthesize entirely new designs, auto-complete partial designs, and detect suboptimal design choices. Let us calculate. —Gottfried Leibniz},
address = {New York, New York, USA},
author = {Idreos, Stratos and Zoumpatianos, Kostas and Hentschel, Brian and Kester, Michael S and Guo, Demi},
booktitle = {Proceedings of the 2018 International Conference on Management of Data - SIGMOD '18},
doi = {10.1145/3183713.3199671},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Idreos et al. - 2018 - The Data Calculator.pdf:pdf},
isbn = {9781450347037},
issn = {07308078},
pages = {535--550},
publisher = {ACM Press},
title = {{The Data Calculator}},
url = {https://d1b10bmlvqabco.cloudfront.net/attach/jcisy46qcj01e7/hqy74luvhhy3zh/jgqh4bcq5fji/Calculator.pdf http://dl.acm.org/citation.cfm?doid=3183713.3199671},
year = {2018}
}
@article{Trummer2017,
abstract = {Research on data visualization aims at finding the best way to present data via visual interfaces. We introduce the com-plementary problem of " data vocalization " . Our goal is to present relational data in the most efficient way via voice output. This problem setting is motivated by emerging tools and devices (e.g., Google Home, Amazon Echo, Apple's Siri, or voice-based SQL interfaces) that communicate data pri-marily via audio output to their users. We treat voice output generation as an optimization prob-lem. The goal is to minimize speaking time while trans-mitting an approximation of a relational table to the user. We consider constraints on the precision of the transmitted data as well as on the cognitive load placed on the listener. We formalize voice output optimization and show that it is NP-hard. We present three approaches to solve that prob-lem. First, we show how the problem can be translated into an integer linear program which enables us to apply corre-sponding solvers. Second, we present a two-phase approach that forms groups of similar rows in a pre-processing step, using a variant of the apriori algorithm. Then, we select an optimal combination of groups to generate a speech. Fi-nally, we present a greedy algorithm that runs in polynomial time. Under simplifying assumptions, we prove that it gen-erates near-optimal output by leveraging the sub-modularity property of our cost function. We compare our algorithms experimentally and analyze their complexity.},
author = {Trummer, Immanuel and Zhu, Jiancheng and Bryan, Mark},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Trummer, Zhu, Bryan - 2017 - Optimizing voice-based output of relational data.pdf:pdf},
journal = {Vldb},
pages = {1574--1585},
title = {{Optimizing voice-based output of relational data}},
year = {2017}
}
@article{Xin2018,
abstract = {Development of machine learning (ML) workflows is a tedious process of iterative experimentation: developers repeatedly make changes to workflows until the desired accuracy is attained. We describe our vision for a "human-in-the-loop" ML system that accelerates this process: by intelligently tracking changes and intermediate results over time, such a system can enable rapid iteration, quick responsive feedback, introspection and debugging, and background execution and automation. We finally describe Helix, our preliminary attempt at such a system that has already led to speedups of up to 10x on typical iterative workflows against competing systems.},
archivePrefix = {arXiv},
arxivId = {1804.05892},
author = {Xin, Doris and Ma, Litian and Liu, Jialin and Macke, Stephen and Song, Shuchen and Parameswaran, Aditya},
eprint = {1804.05892},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Xin et al. - 2018 - Accelerating Human-in-the-loop Machine Learning Challenges and Opportunities.pdf:pdf},
month = {apr},
title = {{Accelerating Human-in-the-loop Machine Learning: Challenges and Opportunities}},
url = {http://arxiv.org/abs/1804.05892},
year = {2018}
}
@article{Zhong2017,
abstract = {A significant amount of the world's knowledge is stored in relational databases. However, the ability for users to retrieve facts from a database is limited due to a lack of understanding of query languages such as SQL. We propose Seq2SQL, a deep neural network for translating natural language questions to corresponding SQL queries. Our model leverages the structure of SQL queries to significantly reduce the output space of generated queries. Moreover, we use rewards from in-the-loop query execution over the database to learn a policy to generate unordered parts of the query, which we show are less suitable for optimization via cross entropy loss. In addition, we will publish WikiSQL, a dataset of 80654 hand-annotated examples of questions and SQL queries distributed across 24241 tables from Wikipedia. This dataset is required to train our model and is an order of magnitude larger than comparable datasets. By applying policy-based reinforcement learning with a query execution environment to WikiSQL, our model Seq2SQL outperforms attentional sequence to sequence models, improving execution accuracy from 35.9{\%} to 59.4{\%} and logical form accuracy from 23.4{\%} to 48.3{\%}.},
archivePrefix = {arXiv},
arxivId = {1709.00103},
author = {Zhong, Victor and Xiong, Caiming and Socher, Richard},
eprint = {1709.00103},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhong, Xiong, Socher - 2017 - Seq2SQL Generating Structured Queries from Natural Language using Reinforcement Learning.pdf:pdf},
month = {aug},
pages = {1--12},
title = {{Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning}},
url = {http://arxiv.org/abs/1709.00103},
year = {2017}
}
@article{Kang2018,
abstract = {As video volumes grow, analysts have increasingly turned to deep learning to process visual data. While these deep networks deliver impressive levels of accuracy, they execute as much as 10x slower than real time (3 fps) on a {\$}8,000 GPU, which is infeasible at scale. In addition, deploying these methods requires writing complex, imperative code with many low-level libraries (e.g., OpenCV, MXNet), an often ad-hoc and time-consuming process that ignores opportunities for cross-operator optimization. To address the computational and usability challenges of video analytics at scale, we introduce BLAZEIT, a system that optimizes queries over video for spatiotemporal information of objects. BLAZEIT accepts queries via FRAMEQL, a declarative language for exploratory video analytics, that enables video-specific query optimization. We propose new query optimization techniques uniquely suited to video analytics that are not supported by prior work. First, we adapt control variates to video analytics and provide advances in specialization for aggregation queries. Second, we adapt importance-sampling using specialized NNs for cardinality-limited video search (i.e. scrubbing queries). Third, we show how to infer new classes of filters for content-based selection. By combining these optimizations, BLAZEIT can deliver over three order of magnitude speedups over the recent literature on video processing.},
archivePrefix = {arXiv},
arxivId = {1805.01046},
author = {Kang, Daniel and Bailis, Peter and Zaharia, Matei},
eprint = {1805.01046},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kang, Bailis, Zaharia - 2018 - BlazeIt Fast Exploratory Video Queries using Neural Networks.pdf:pdf},
journal = {Pvldb},
month = {may},
number = {5},
title = {{BlazeIt: Fast Exploratory Video Queries using Neural Networks}},
url = {https://doi.org/TBD http://arxiv.org/abs/1805.01046},
volume = {11},
year = {2018}
}
@article{Haynes2018,
author = {Haynes, Brandon and Mazumdar, Amrita and Alaghi, Armin and Balazinska, Magdalena and Ceze, Luis and Cheung, Alvin},
doi = {10.14778/3231751.3231768},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Haynes et al. - 2018 - LightDB.pdf:pdf},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
month = {jun},
number = {10},
pages = {1192--1205},
title = {{LightDB}},
url = {http://dl.acm.org/citation.cfm?doid=3231751.3242938},
volume = {11},
year = {2018}
}
@inproceedings{Lu2018,
address = {New York, New York, USA},
author = {Lu, Yao and Chowdhery, Aakanksha and Kandula, Srikanth and Chaudhuri, Surajit},
booktitle = {Proceedings of the 2018 International Conference on Management of Data - SIGMOD '18},
doi = {10.1145/3183713.3183751},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu et al. - 2018 - Accelerating Machine Learning Inference with Probabilistic Predicates.pdf:pdf},
isbn = {9781450347037},
issn = {07308078},
pages = {1493--1508},
publisher = {ACM Press},
title = {{Accelerating Machine Learning Inference with Probabilistic Predicates}},
url = {http://dl.acm.org/citation.cfm?doid=3183713.3183751},
year = {2018}
}
@article{Mancini:2011:AIM:1978822.1978836,
address = {New York, NY, USA},
author = {Mancini, Clara},
doi = {10.1145/1978822.1978836},
issn = {1072-5520},
journal = {interactions},
month = {jul},
number = {4},
pages = {69--73},
publisher = {ACM},
title = {{Animal-computer Interaction: A Manifesto}},
url = {http://doi.acm.org/10.1145/1978822.1978836},
volume = {18},
year = {2011}
}
@article{Resner2001,
author = {Resner, Benjamin Ishak},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Resner - 2001 - Rover @ Home Computer Mediated Remote Interaction Between Humans and Dogs Rover @ Home Computer Mediated Remote Intera.pdf:pdf},
pages = {1--109},
title = {{Rover @ Home : Computer Mediated Remote Interaction Between Humans and Dogs Rover @ Home : Computer Mediated Remote Interaction Between Humans and Dogs}},
year = {2001}
}
@article{Paci2016,
author = {Paci, Patrizia and Mancini, Clara and Price, Blaine A},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Paci, Mancini, Price - 2016 - Towards a wearer-centred framework for animal biotelemetry.pdf:pdf},
number = {May},
pages = {25--27},
title = {{Towards a wearer-centred framework for animal biotelemetry}},
year = {2016}
}
@inproceedings{Lawson:2015:PUT:2702123.2702260,
address = {New York, NY, USA},
author = {Lawson, Shaun and Kirman, Ben and Linehan, Conor and Feltwell, Tom and Hopkins, Lisa},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
doi = {10.1145/2702123.2702260},
isbn = {978-1-4503-3145-6},
keywords = {animal-computer interaction,critical design,design fiction,personal informatics,the quantified dog.},
pages = {2663--2672},
publisher = {ACM},
series = {CHI '15},
title = {{Problematising Upstream Technology Through Speculative Design: The Case of Quantified Cats and Dogs}},
url = {http://doi.acm.org/10.1145/2702123.2702260},
year = {2015}
}
@article{Muller1993,
abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article. ACM has opted to expose the complete List rather than only correct and linked references.},
author = {Muller, MJ Michael J. and Kuhn, Sarah},
doi = {10.1145/153571.255960},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Muller, Kuhn - 1993 - Participatory design.pdf:pdf},
isbn = {0805809511},
issn = {00010782},
journal = {Communications of the ACM},
number = {6},
pages = {24--28},
title = {{Participatory design}},
url = {http://portal.acm.org/citation.cfm?id=153571.255960{\&}coll=ACM{\&}dl=ACM{\&}CFID=86979473{\&}CFTOKEN=59738617{\%}5Cnhttp://portal.acm.org/ft{\_}gateway.cfm?id=255960{\&}type=pdf{\&}coll=ACM{\&}dl=ACM{\&}CFID=86979473{\&}CFTOKEN=59738617{\%}5Cnhttp://dl.acm.org/citation.cfm?id=255960},
volume = {36},
year = {1993}
}
@inproceedings{10.1007/978-3-642-15231-3_11,
abstract = {A study exploring the focus on usability in testing practices in software development teams in Iceland using the agile software process Scrum is described in this paper. A survey was conducted to describe how testing is conducted and to what extent testing techniques are used. The results show that unit, integration, system and acceptance testing are the most frequent testing techniques used, but usability testing is not that common. Neither are alpha, beta, performance/load and security testing. Interviews were conducted to exemplify how practitioners conduct usability testing and what they describe as the difference between usability and acceptance testing. Some examples from the interviews show that practitioners are willing to do formal usability testing on extensive parts of the system, but because the iterations in Scrum are short and the changes to the system in each iteration are small, formal usability testing does not fit into the project work.},
address = {Berlin, Heidelberg},
author = {Larusdottir, Marta Kristin and Bjarnadottir, Emma Run and Gulliksen, Jan},
booktitle = {Human-Computer Interaction},
doi = {10.1007/978-3-642-15231-3_11},
editor = {Forbrig, Peter and Patern{\'{o}}, Fabio and {Mark Pejtersen}, Annelise},
isbn = {1868-4238$\backslash$r978-3-64215-230-6},
issn = {18684238},
pages = {98--109},
publisher = {Springer Berlin Heidelberg},
title = {{The Focus on Usability in Testing Practices in Industry}},
url = {http://link.springer.com/10.1007/978-3-642-15231-3{\_}11},
year = {2010}
}
@inproceedings{Forlizzi2004,
address = {New York, New York, USA},
author = {Forlizzi, Jodi and Battarbee, Katja},
booktitle = {Proceedings of the 2004 conference on Designing interactive systems processes, practices, methods, and techniques - DIS '04},
doi = {10.1145/1013115.1013152},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Forlizzi, Battarbee - 2004 - Understanding experience in interactive systems.pdf:pdf},
isbn = {1581137877},
pages = {261},
publisher = {ACM Press},
title = {{Understanding experience in interactive systems}},
url = {http://portal.acm.org/citation.cfm?doid=1013115.1013152},
year = {2004}
}
@article{Mancini2017a,
abstract = {The emerging discipline of Animal–Computer Interaction (ACI) aims to take what in Interaction Design is known as a user-centred approach to the design of technology intended for animals, placing them at the centre of the design process as stakeholders, users, and contributors. However, current regulatory frameworks for the involvement of animals in research are not animal-centred, regarding them as research instruments, unable to consent to procedures that may harm them, rather than consenting research participants and design contributors. Such frameworks aim to minimise the impacts of research procedures on the welfare of individual animals, but this minimisation is subordinated to specific scientific and societal interests, and to the integrity of the procedures required to serve those interests. From this standpoint, the universally advocated principles of replacement, reduction and refinement aim to address the ethical conflicts arising from the assumed inability of individual animals to consent to potentially harmful procedures, but such principles in fact reflect a lack of individual centrality. This paper makes the case for moving beyond existing regulations and guidelines towards an animal-centred framework that can better support the development of ACI as a discipline. Firstly, recognising animal welfare as a fundamental requirement for users and research participants alike, the paper articulates the implications of a welfare-centred ethics framework. Secondly, recognising consent as an essential requirement of participation, the paper also defines criteria for obtaining animals׳ mediated and contingent consent to engaging with research procedures. Further, the paper argues for the methodological necessity, as well as the ethical desirability, of such an animal-centred framework, examining the boundaries of its applicability as well as the benefits of its application. Finally, the paper puts forward a series of practical principles for conducting ACI research, which imply but also essentially exceed the welfare and ethics requirements of current regulatory frameworks.},
author = {Mancini, Clara},
doi = {10.1016/j.ijhcs.2016.04.008},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mancini - 2017 - Towards an animal-centred ethics for Animal–Computer Interaction.pdf:pdf},
isbn = {9725233859},
issn = {10959300},
journal = {International Journal of Human Computer Studies},
keywords = {Animal-centred design,Contingent consent,Mediated consent,Other-than-human animal participants,Participant-centred ethics,Welfare-centred ethics},
month = {feb},
pages = {221--233},
publisher = {Academic Press},
title = {{Towards an animal-centred ethics for Animal–Computer Interaction}},
url = {https://www.sciencedirect.com/science/article/pii/S1071581916300180},
volume = {98},
year = {2017}
}
@article{Epstein2000,
author = {Epstein, Robert and Rogers, Jessica},
doi = {10.1007/BF03392006},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Epstein, Rogers - 2000 - On books.pdf:pdf},
issn = {0738-6729},
journal = {The Behavior Analyst},
month = {apr},
number = {1},
pages = {117--129},
title = {{On books}},
url = {http://link.springer.com/10.1007/BF03392006},
volume = {23},
year = {2000}
}
@article{Hunt2004,
abstract = {The 'crafting' of tools involves (i) selection of appropriate raw material, (ii) preparatory trimming and (iii) fine, three-dimensional sculpting. Its evolution is technologically important because it allows the open-ended development of tools. New Caledonian crows manufacture an impressive range of stick and leaf tools. We previously reported that their toolkit included hooked implements made from leafy twigs, although their manufacture had never been closely observed. We describe the manufacture of 10 hooked-twig tools by an adult crow and its dependent juvenile. To make all 10 tools, the crows carried out a relatively invariant three-step sequence of complex manipulations that involved (i) the selection of raw material, (ii) trimming and (iii) a lengthy sculpting of the hook. Hooked-twig manufacture contrasts with the lack of sculpting in the making of wooden tools by other non-humans such as chimpanzees and woodpecker finches. This fine, three-stage crafting process removes another alleged difference between humans and other animals.},
author = {Hunt, Gavin R. and Gray, Russell D.},
doi = {10.1098/rsbl.2003.0085},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hunt, Gray - 2004 - The crafting of hook tools by wild New Caledonian crows.pdf:pdf},
isbn = {0962-8452},
issn = {14712970},
journal = {Proceedings of the Royal Society B: Biological Sciences},
keywords = {Cognition,Crafting tools,Goal directedness,Hooks,Tool manufacture},
number = {SUPPL. 3},
pages = {88--90},
pmid = {15101428},
title = {{The crafting of hook tools by wild New Caledonian crows}},
volume = {271},
year = {2004}
}
@book{Garton2001,
abstract = {Design studies that use radiotelemetry require careful consideration of the goals of a project and the resources available to meet those goals. Success in meeting the research goals depends on thoughtful planning of field methods and ancillary data collection, selection of telemetry equipment appropriate to the study animal and budget, careful execution of the field protocols, and creative analysis of the data. Some of the most important design factors include consideration of the study's purpose; degree of experimental manipulation, controls, and replication; selection of an efficient yet unbiased sampling scheme; definition of the sample unit; calculation of sample size requirements; identification and removal of sources of bias; and clear specification of biological significance. This chapter emphasizes the need to integrate univariate metrics of animal choice, such as estimates of home range size and resource selection, with metrics for the demographic consequences of these choices, all of which can be generated from radiotelemetry. Radiotelemetry is an essential tool in modern studies of movement, migration, and dispersal of most vertebrates. Its use has dramatically increased the amount and detail of information available for estimating movements of larger animals, and provides extremely valuable additions to information from studies that use tagging, banding (ringing), and other forms of marking for smaller animals. In addition, radiotelemetry studies are an important complement to recent approaches that use genetic markers.},
author = {Garton, Edward O. and Wisdom, Michael J. and Leban, Frederick A. and Johnson, Bruce K.},
booktitle = {Radio Tracking and Animal Populations},
doi = {10.1016/B978-012497781-5/50003-7},
isbn = {9780124977815},
month = {jan},
pages = {15--42},
publisher = {Academic Press},
title = {{Radio Tracking and Animal Populations}},
url = {https://www.sciencedirect.com/science/article/pii/B9780124977815500037 http://www.sciencedirect.com/science/article/pii/B9780124977815500037},
year = {2001}
}
@book{Fugazza2014,
address = {Berlin, Heidelberg},
author = {Fugazza, Claudia and Mikl{\'{o}}si, {\'{A}}dam},
booktitle = {Domestic Dog Cognition and Behavior: The Scientific Study of Canis familiaris},
doi = {10.1007/978-3-642-53994-7},
editor = {Horowitz, Alexandra},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fugazza, Mikl{\'{o}}si - 2014 - Domestic Dog Cognition and Behavior.pdf:pdf},
isbn = {978-3-642-53993-0},
pages = {177--200},
publisher = {Springer Berlin Heidelberg},
title = {{Domestic Dog Cognition and Behavior}},
url = {http://link.springer.com/10.1007/978-3-642-53994-7},
year = {2014}
}
@article{Bensky2013,
abstract = {Driven by both applied and theoretical goals, scientific interest in canine cognition has experienced a rapid surge in popularity, especially over the last 15 years. Here we provide the most comprehensive review to date of dog cognition research, capturing all the articles (285) we could find on the subject going back to 1911. We begin by summarizing the general research trends, first documenting the rapid recent growth in dog cognition research (particularly in the domain of social cognition), and then identifying a number of trends in terms of the cognition topics and dog populations studied. Next, we summarize and synthesize the substantive conclusions emerging from research on nonsocial (discrimination learning, object permanence, object learning, categorization, object manipulation, quantitative understanding, spatial cognition, and memory) and social (responses to human cues, perspective taking, dog-human communication, and social learning) cognition. In light of the burgeoning research on individual differences in cognition and on the biological organization of cognitive domains, we highlight the potential impact of these topics on the dog cognition field. Finally, based on our syntheses, we outline some ideas for future research, including recommendations that studies focus on: (1) incorporating multiple sensory modalities (most notably olfaction); (2) using more diverse populations of subjects; (3) replicating studies where current knowledge is based on small study sets or on small samples; (4) identifying fundamental developmental patterns of cognitive development; (5) identifying individual differences in cognitive ability; and (6) identifying potential cognitive constraints (e.g. cognitive abilities that are nonindependent due to pleiotropic biological organization).},
author = {Bensky, Miles K. and Gosling, Samuel D. and Sinn, David L.},
doi = {10.1016/B978-0-12-407186-5.00005-7},
isbn = {9780124071865},
issn = {0065-3454},
journal = {Advances in the Study of Behavior},
month = {jan},
pages = {209--406},
publisher = {Academic Press},
title = {{The World from a Dog's Point of View: A Review and Synthesis of Dog Cognition Research}},
url = {https://www.sciencedirect.com/science/article/pii/B9780124071865000057},
volume = {45},
year = {2013}
}
@article{Pogany2018,
abstract = {Excessive food intake and the resulting excess weight gain is a growing problem in human and canine populations. Dogs, due to their shared living environment with humans, may provide a beneficial model to study the causes and consequences of obesity. Here, we make use of two well-established research paradigms (two-way choice paradigm and cognitive bias test), previously applied with dogs, to investigate the role of obesity and obesity-prone breeds for food responsiveness. We found no evidence of breed differences in food responsiveness due to one breed being more prone to obesity than another. Breed differences found in this study, however, can be explained by working dog status, i.e. whether the dog works in cooperation with, or independently from, humans. Our results also confirm that overweight dogs, as opposed to normal weight dogs, tried to maximize food intake from the higher quality food and hesitated to do the task when the food reward was uncertain. These results are very similar to those expected from the parallel models that exist between certain personality traits and being overweight in humans, suggesting that dogs are indeed a promising model for experimentally investigating obesity in humans.},
author = {Pog{\'{a}}ny, {\'{A}}kos and Torda, Orsolya and Marinelli, Lieta and Lenkei, Rita and Jun{\'{o}}, Vanda and Pongr{\'{a}}cz, P{\'{e}}ter},
doi = {10.1098/rsos.172398},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pog{\'{a}}ny et al. - 2018 - The behaviour of overweight dogs shows similarity with personality traits of overweight humans.pdf:pdf;:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pog{\'{a}}ny et al. - 2018 - The behaviour of overweight dogs shows similarity with personality traits of overweight humans(2).pdf:pdf},
issn = {2054-5703},
journal = {Royal Society Open Science},
keywords = {behaviour,cognition,health and disease},
number = {6},
pages = {172398},
title = {{The behaviour of overweight dogs shows similarity with personality traits of overweight humans}},
url = {http://rsos.royalsocietypublishing.org/lookup/doi/10.1098/rsos.172398},
volume = {5},
year = {2018}
}
@article{Mancini2017,
abstract = {In this editorial to the IJHCS Special Issue on Animal-Computer Interaction (ACI), we provide an overview of the state-of-the-art in this emerging field, outlining the main scientific interests of its developing community, in a broader cultural context of evolving human-animal relations. We summarise the core aims proposed for the development of ACI as a discipline, discussing the challenges these pose and how ACI researchers are trying to address them. We then introduce the contributions to the Special Issue, showing how they illustrate some of the key issues that characterise the current state-of-the-art in ACI, and finally reflect on how the journey ahead towards developing an ACI discipline could be undertaken.},
author = {Mancini, Clara and Lawson, Shaun and Juhlin, Oskar},
doi = {10.1016/j.ijhcs.2016.10.003},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mancini, Lawson, Juhlin - 2017 - Animal-Computer Interaction The emergence of a discipline.pdf:pdf;:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mancini, Lawson, Juhlin - 2017 - Animal-Computer Interaction The emergence of a discipline(2).pdf:pdf},
issn = {10959300},
journal = {International Journal of Human Computer Studies},
keywords = {Animal-Computer Interaction,Animal-centred design,Human-animal relations,More-than-human participatory research},
number = {October 2016},
pages = {129--134},
title = {{Animal-Computer Interaction: The emergence of a discipline}},
volume = {98},
year = {2017}
}
@inproceedings{Robinson2014,
abstract = {In a questionnaire survey of dog owners, 88{\%} of respondents' dogs had received some form of training. Training methods varied; 16{\%} of owners said that they used only positive reinforcement, 12{\%} used a combination of positive reinforcement and negative reinforcement, 32{\%} used a combination of positive reinforcement and positive punishment, and the remaining 40{\%} used a combination of all categories. Seventy-two percent of owners used some form of positive punishment. The mean number of potentially undesirable behaviors reported was 11.3 per dog. Attendance at formal training classes did not significantly affect the total number of potentially undesirable behaviors reported. However, dogs that had attended puppy socialization classes were less likely to show an undesirable reaction to dogs from outside the household, and owners who carried out informal training at home, but did not attend any form of formal training class, were more likely to report some form of aggression in their dog. The training method used by owners was also related to the total number of potentially undesirable behaviors shown by the dogs. When individual categories of potentially undesirable behavior were investigated, the type of training method used was also significantly associated with attention-seeking score, fear (avoidance) score, and aggression score. Other factors related to the overall number of potentially undesirable behaviors included the age and origin of the dog.},
address = {New York, New York, USA},
author = {Robinson, Charlotte L. and Mancini, Clara and van der Linden, Janet and Guest, Claire and Harris, Robert},
booktitle = {Proceedings of the 32nd annual ACM conference on Human factors in computing systems - CHI '14},
doi = {10.1145/2556288.2557396},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Robinson et al. - 2014 - Canine-centered interface design.pdf:pdf},
isbn = {9781450324731},
issn = {1558-7878},
keywords = {animal-computer interaction,diabetes alert dog,human-animal interaction,multispecies ethnography,user-centered design},
pages = {3757--3766},
publisher = {ACM Press},
title = {{Canine-centered interface design}},
url = {http://dl.acm.org/citation.cfm?doid=2556288.2557396},
year = {2014}
}
@article{Brooks1991,
abstract = {Artificial intelligence research has foundered on the issue of representation. When intelligence is approached in an incremental manner, with strict reliance on interfacing to the real world through perception and action, reliance on representation disappears. In this paper we outline our approach to incrementally building complete intelligent Creatures. The fundamental decomposition of the intelligent system is not into independent information processing units which must interface with each other via representations. Instead, the intelligent system is decomposed into independent and parallel activity producers which all interface directly to the world through perception and action, rather than interface to each other particularly much. The notions of central and peripheral systems evaporate-everything is both central and peripheral. Based on these principles we have built a very successful series of mobile robots which operate without supervision as Creatures in standard office environments. {\textcopyright} 1991.},
author = {Brooks, Rodney A.},
doi = {10.1016/0004-3702(91)90053-M},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brooks - 1991 - Intelligence without representation.pdf:pdf},
isbn = {0004-3702},
issn = {00043702},
journal = {Artificial Intelligence},
number = {1-3},
pages = {139--159},
pmid = {14599324},
title = {{Intelligence without representation}},
volume = {47},
year = {1991}
}
@article{Byrne2014,
author = {Byrne, Ceara and Kerwin, Ryan and Zuerndorfer, Jay and Gilliland, Scott and Guo, Zehua and Jackson, Melody and Starner, Thad E and Tech, Georgia},
doi = {10.1109/MPRV.2014.38},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Byrne et al. - 2014 - Two-Way Communication between Working Dogs and Their Handlers.pdf:pdf},
issn = {1536-1268},
journal = {IEEE Pervasive Computing},
number = {2},
pages = {80--83},
title = {{Two-Way Communication between Working Dogs and Their Handlers}},
url = {http://ieeexplore.ieee.org/document/6818510/},
volume = {13},
year = {2014}
}
@article{Hirskyj-Douglas2018,
author = {Hirskyj-Douglas, Ilyena and Pons, Patricia and Read, Janet C. and Jaen, Javier},
doi = {10.3390/mti2020030},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hirskyj-Douglas et al. - 2018 - Seven years after the Manifesto Literature Review and Research Directions for Technologies in Animal Com.pdf:pdf},
journal = {Multimodal Technologies and Interactions},
number = {Special Issue on Multimodal Technologies in Animal Computer Interaction},
pages = {(accepted)},
title = {{Seven years after the Manifesto: Literature Review and Research Directions for Technologies in Animal Computer Interaction}},
year = {2018}
}
@article{Freil2017,
abstract = {Canine-Centered Computing},
author = {Freil, Larry and Byrne, Ceara and Valentin, Giancarlo and Zeagler, Clint and Roberts, David and Starner, Thad and Jackson, Melody},
doi = {10.1561/1100000064},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Freil et al. - 2017 - Canine-Centered Computing.pdf:pdf},
issn = {1551-3955},
journal = {Foundations and Trends{\textregistered} in Human–Computer Interaction},
number = {2},
pages = {87--164},
title = {{Canine-Centered Computing}},
url = {http://www.nowpublishers.com/article/Details/HCI-064},
volume = {10},
year = {2017}
}
@article{Byrne2017,
abstract = {Working dogs perform a variety of essential services for their human partners, from assisting people with disabilities, to Search and Rescue, police, and military work. Recent interest in the nascent field of Animal–Computer Interaction has prompted research in computer-mediated technology for communication between working dogs and their handlers. Haptic (touch) interfaces in the form of vibrating motors are a promising approach for handler-to-dog communication. Haptic interfaces can provide a silent, long-range method of sending commands to a dog, when voice or hand signals are inappropriate or impossible. However, evaluating haptic interfaces for dogs, who cannot self-report sensations, creates interesting challenges. This study draws on human–computer interaction concepts, such as Just Noticeable Difference, to explore methods and issues in evaluating haptic interfaces for working dogs. We created a haptic system and developed an evaluation method, reporting results for ten dogs of widely varying breeds, sizes, and coat types.},
author = {Byrne, Ceara and Freil, Larry and Starner, Thad and Jackson, Melody Moore},
doi = {10.1016/j.ijhcs.2016.04.004},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Byrne et al. - 2017 - A method to evaluate haptic interfaces for working dogs.pdf:pdf},
issn = {10959300},
journal = {International Journal of Human Computer Studies},
pages = {196--207},
publisher = {Elsevier},
title = {{A method to evaluate haptic interfaces for working dogs}},
url = {http://dx.doi.org/10.1016/j.ijhcs.2016.04.004},
volume = {98},
year = {2017}
}
@article{Zeagler2016a,
abstract = {{\textcopyright} 2016 ACM.Search and Rescue (SAR) is a critical component of disaster recovery efforts. Every second saved in the search increases the chances of finding survivors and the majority of these teams prefer using canines [5]. Our goal is to help enable SAR dog and handler teams to work together more effectively. Using a semi-structured interviews and guidance from K9-SAR experts as we iterate through designs, we develop a two-part system consisting of a wearable computer interface for working SAR dogs that communicates with their handler via a mobile application. Additionally, we discuss the system around a heuristic framework that includes dogs as active participants. Finally, we show the viability of our tool by evaluating it with feedback from three SAR experts.},
author = {Zeagler, Clint and Byrne, Ceara and Valentin, Giancarlo and Freil, Larry and Kidder, Eric and Crouch, James and Starner, Thad and Jackson, Melody Moore},
doi = {10.1145/2995257.2995390},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zeagler et al. - 2016 - Search and rescue dog and handler collaboration through wearable and mobile interfaces.pdf:pdf},
isbn = {9781450347587},
journal = {Proceedings of the Third International Conference on Animal-Computer Interaction - ACI '16},
pages = {1--9},
title = {{Search and rescue: dog and handler collaboration through wearable and mobile interfaces}},
url = {http://dl.acm.org/citation.cfm?doid=2995257.2995390},
year = {2016}
}
@article{Byrne2018,
abstract = {Working dogs are significantly beneficial to society; however, a substantial number of dogs are released from time consuming and expensive training programs because of unsuitability in behavior. Early prediction of successful service dog placement could save time, resources, and funding. Our research focus is to explore whether aspects of canine temperament can be detected from interactions with sensors, and to develop classifiers that correlate sensor data to predict the success (or failure) of assistance dogs in advanced training. In a 2-year longitudinal study, our team tested a cohort of dogs entering advanced training in the Canine Companions for Independence (CCI) Program with 2 instrumented dog toys: a silicone ball and a silicone tug sensor. We then create a logistic model tree classifier to predict service dog success using only 5 features derived from dog-toy interactions. During randomized 10-fold cross validation where 4 of the 40 dogs were kept in an independent test set for each fold, our classifier predicts the dogs' outcomes with 87.5{\%} average accuracy. We assess the reliability of our model by performing the testing routine 10 times over 1.5 years for a single suitable working dog, which predicts that the dog would pass each time. We calculate the resource benefit of identifying dogs who will fail early in their training, and the value for a cohort of 40 dogs using our toys and our methods for prediction is over {\$}70,000. With CCI's 6 training centers, annual savings could be upwards of {\$}5 million per year.},
author = {Byrne, Ceara and Zuerndorfer, Jay and Freil, Larry and Han, Xiaochuang and Sirolly, Andrew and Cilliland, Scott and Starner, Thad and Jackson, Melody},
doi = {10.1145/3161184},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Byrne et al. - 2018 - Predicting the Suitability of Service Animals Using Instrumented Dog Toys.pdf:pdf},
issn = {24749567},
journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
keywords = {acm reference format,and melody,andrew sirolly,ceara byrne,jay zuerndorfer,larry freil,scott gilliland,service dogs,smart objects,tangible computing,tangibles,temperament,thad starner,xiaochuang han},
number = {4},
pages = {1--20},
title = {{Predicting the Suitability of Service Animals Using Instrumented Dog Toys}},
url = {http://dl.acm.org/citation.cfm?doid=3178157.3161184},
volume = {1},
year = {2018}
}
@article{Morell2009,
author = {Morell, V.},
doi = {10.1126/science.325_1062},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Morell - 2009 - Going to the Dogs.pdf:pdf},
issn = {0036-8075},
journal = {Science},
month = {aug},
number = {5944},
pages = {1062--1065},
pmid = {16594533},
title = {{Going to the Dogs}},
url = {http://muse.jhu.edu/content/crossref/journals/elh/v076/76.4.dekoven.html http://www.sciencemag.org/cgi/doi/10.1126/science.325{\_}1062},
volume = {325},
year = {2009}
}
@article{Aust2008,
abstract = {The ability to reason by exclusion (which is defined as the selection of the correct alternative by logically excluding other potential alternatives; Call in Anim Cogn 9:393-403 2006) is well established in humans. Several studies have found it to be present in some nonhuman species as well, whereas it seems to be somewhat limited or even absent in others. As inconsistent methodology might have contributed to the revealed inter-species differences, we examined reasoning by exclusion in pigeons (n = 6), dogs (n = 6), students (n = 6), and children (n = 8) under almost equal experimental conditions. After being trained in a computer-controlled two-choice procedure to discriminate between four positive (S+) and four negative (S-) photographs, the subjects were tested with displays consisting of one S- and one of four novel stimuli (S'). One pigeon, half of the dogs and almost all humans preferred S' over S-, thereby choosing either by novelty, or by avoiding S- without acquiring any knowledge about S', or by inferring positive class membership of S' by excluding S-. To decide among these strategies the subjects that showed a preference for S' were then tested with displays consisting of one of the S' and one of four novel stimuli (S''). Although the pigeon preferentially chose the S'' and by novelty, dogs and humans maintained their preference for S', thereby showing evidence of reasoning by exclusion. Taken together, the results of the present study suggest that none of the pigeons, but half of the dogs and almost all humans inferred positive class membership of S' by logically excluding S-.},
author = {Aust, Ulrike and Range, Friederike and Steurer, Michael and Huber, Ludwig},
doi = {10.1007/s10071-008-0149-0},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aust et al. - 2008 - Inferential reasoning by exclusion in pigeons, dogs, and humans.pdf:pdf},
isbn = {14359448 (ISSN)},
issn = {14359448},
journal = {Animal Cognition},
keywords = {Categorization,Dogs,Humans,Pigeons,Reasoning by exclusion},
number = {4},
pages = {587--597},
pmid = {18309524},
title = {{Inferential reasoning by exclusion in pigeons, dogs, and humans}},
volume = {11},
year = {2008}
}
@article{Range2008,
abstract = {One of the fundamental issues in the study of animal cognition concerns categorization. Although domestic dogs (Canis familiaris) are on the brink to become one of the model animals in animal psychology, their categorization abilities are unknown. This is probably largely due to the absence of an adequate method for testing dogs' ability to discriminate between large sets of pictures in the absence of human cueing. Here we present a computer-automated touch-screen testing procedure, which enabled us to test visual discrimination in dogs while social cueing was ruled out. Using a simultaneous discrimination procedure, we first trained dogs (N = 4) to differentiate between a set of dog pictures (N = 40) and an equally large set of landscape pictures. All subjects learned to discriminate between the two sets and showed successful transfer to novel pictures. Interestingly, presentation of pictures providing contradictive information (novel dog pictures mounted on familiar landscape pictures) did not disrupt performance, which suggests that the dogs made use of a category-based response rule with classification being coupled to category-relevant features (of the dog) rather than to item-specific features (of the background). We conclude that dogs are able to classify photographs of natural stimuli by means of a perceptual response rule using a newly established touch-screen procedure.},
author = {Range, Friederike and Aust, Ulrike and Steurer, Michael and Huber, Ludwig},
doi = {10.1007/s10071-007-0123-2},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Range et al. - 2008 - Visual categorization of natural stimuli by domestic dogs.pdf:pdf},
isbn = {1007100701232},
issn = {14359448},
journal = {Animal Cognition},
keywords = {Discrimination,Domestic dogs,Touch-screen procedure,Visual categorization},
number = {2},
pages = {339--347},
pmid = {18026761},
title = {{Visual categorization of natural stimuli by domestic dogs}},
volume = {11},
year = {2008}
}
@article{Zeagler2014,
abstract = {Computer-mediated interaction for working dogs is an important new domain for interaction research. In domestic settings, touchscreens could provide a way for dogs to communicate critical information to humans. In this paper we explore how a dog might interact with a touchscreen interface. We observe dogs' touchscreen interactions and record difficulties against what is expected of humans' touchscreen interactions. We also solve hardware issues through screen adaptations and projection styles to make a touchscreen usable for a canine's nose touch interactions. We also compare our canine touch data to humans' touch data on the same system. Our goal is to understand the affordances needed to make touchscreen interfaces usable for canines and help the future design of touchscreen interfaces for assistive dogs in the home.},
author = {Zeagler, Clint and Gilliland, Scott and Freil, Larry and Starner, Thad and Jackson, Melody},
doi = {10.1145/2642918.2647364},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zeagler et al. - 2014 - Going to the dogs towards an interactive touchscreen interface for working dogs.pdf:pdf},
isbn = {9781450330695},
journal = {Proceedings of the 27th annual ACM symposium on User interface software and technology},
pages = {497--507},
title = {{Going to the dogs: towards an interactive touchscreen interface for working dogs}},
year = {2014}
}
@article{Wallis2017,
abstract = {{\textcopyright} 2017 Copyright is held by the owner/author(s). Aged dogs suffer from reduced mobility and activity levels, which can affect their daily lives. It is quite typical for owners of older dogs to reduce all activities such as walking, playing and training, since their dog may appear to no longer need them. Previous studies have shown that ageing can be slowed by mental and physical stimulation, and thus stopping these activities might actually lead to faster ageing in dogs, which can result in a reduction in the quality of life of the animal, and may even decrease the strength of the dog-owner bond. In this paper, we describe in detail a touchscreen apparatus, software and training method that we have used to facilitate dog computer interaction (DCI). We propose that DCI has the potential to improve the welfare of older dogs in particular through cognitive enrichment. We provide hypotheses for future studies to examine the possible effects of touchscreen use on physiological, behavioural and cognitive measures of dogs' positive affect and well-being, and any impact on the dog-owner bond. In the future, collaborations between researchers in animal-computer interaction, dog trainers, and cognitive scientists are essential to develop the hardware and software necessary to realise the full potential of this training and enrichment tool.},
author = {Wallis, Lisa J. and Range, Friederike and Kubinyi, Enikő and Chapagain, Durga and Serra, Jessica and Huber, Ludwig},
doi = {10.1145/3152130.3152146},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wallis et al. - 2017 - Utilising dog-computer interactions to provide mental stimulation in dogs especially during ageing.pdf:pdf},
isbn = {9781450353649},
journal = {Proceedings of the Fourth International Conference on Animal-Computer Interaction  - ACI2017},
keywords = {Animal welfare,Dog computer interaction,Dogs,Learning,Motivation,Senior,Touchscreen},
pages = {1--12},
title = {{Utilising dog-computer interactions to provide mental stimulation in dogs especially during ageing}},
url = {http://dl.acm.org/citation.cfm?doid=3152130.3152146},
year = {2017}
}
@article{Zeagler2016,
abstract = {{\textcopyright} 2016 ACM.Touchscreens can provide a way for service dogs to relay emergency information about their handlers from a home or office environment. In this paper, we build on work exploring the ability of canines to interact with touchscreen interfaces. We observe new requirements for training and explain best practices found in training techniques. Learning from previous work, we also begin to test new dog interaction techniques such as lift-off selection and sliding gestural motions. Our goal is to understand the affordances needed to make touchscreen interfaces usable for canines and help the future design of touchscreen interfaces for assistance dogs in the home.},
author = {Zeagler, Clint and Zuerndorfer, Jay and Lau, Andrea and Freil, Larry and Gilliland, Scott and Starner, Thad and Jackson, Melody Moore},
doi = {10.1145/2995257.2995384},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zeagler et al. - 2016 - Canine computer interaction towards designing a touchscreen interface for working dogs.pdf:pdf},
isbn = {9781450347587},
journal = {Proceedings of the Third International Conference on Animal-Computer Interaction - ACI '16},
pages = {1--5},
title = {{Canine computer interaction: towards designing a touchscreen interface for working dogs}},
url = {http://dl.acm.org/citation.cfm?doid=2995257.2995384},
year = {2016}
}
@inproceedings{Krachunov2017,
abstract = {Many countries are facing burdens on their health care systems due to ageing populations. A promising strategy to address the problem is to allow selected people to remain in their homes and be monitored using recent advances in wearable devices, saving in-hospital resources. With respect to heart monitoring, wearable devices to date have principally used optical techniques by shining light through the skin. However, these techniques are severely hampered by motion artifacts and are limited to heart rate detection. Further, these optical devices consume a large amount of power in order to receive a sufficient signal, resulting in the need for frequent battery recharging. To address these shortcomings we present a new wrist ECG wearable that is similar to the clinical approach for heart monitoring. Our device weighs less than 30 g, and is ultra low power, extending the battery lifetime to over a month to make the device more appropriate for in-home health care applications. The device uses two electrodes activated by the user to measure the voltage across the wrists. The electrodes are made from a flexible ink and can be painted on to the device casing, making it adaptable for different shapes and users. In this paper we show how the ECG sensor can be integrated into an existing IoT wearable and compare the device's accuracy against other common commercial devices.},
author = {Krachunov, Sammy and Beach, Christopher and Casson, Alexander J. and Pope, James and Fafoutis, Xenofon and Piechocki, Robert J. and Craddock, Ian},
booktitle = {GIoTS 2017 - Global Internet of Things Summit, Proceedings},
doi = {10.1109/GIOTS.2017.8016260},
isbn = {9781509058730},
keywords = {Body sensor networks,Electrocardiography,Heart rate,Heart rate variability,Low power sensors},
month = {jun},
pages = {1--6},
publisher = {IEEE},
title = {{Energy efficient heart rate sensing using a painted electrode ECG wearable}},
url = {http://ieeexplore.ieee.org/document/8016260/},
year = {2017}
}
@article{BA¡lint2016,
abstract = {Body size is an important feature that affects fighting ability; however, size-related parameters of agonistic vocalizations are difficult to manipulate because of anatomical constraints within the vocal production system. Rare examples of acoustic size modulation are due to specific features that enable the sender to steadily communicate exaggerated body size. However, one could argue that it would be more adaptive if senders could adjust their signaling behavior to the fighting potential of their actual opponent. So far there has been no experimental evidence for this possibility. We tested this hypothesis by exposing family dogs (Canis familiaris) to humans with potentially different fighting ability. In a within-subject experiment, 64 dogs of various breeds consecutively faced two threateningly approaching humans, either two men or two women of different stature, or a man and a woman of similar or different stature. We found that the dogs' vocal responses were affected by the gender of the threatening stranger and the dog owner's gender. Dogs with a female owner, or those dogs which came from a household where both genders were present, reacted with growls of lower values of the Pitch–Formant component (including deeper fundamental frequency and lower formant dispersion) to threatening men. Our results are the first to show that non-human animals react with dynamic alteration of acoustic parameters related to their individual indexical features (body size), depending on the level of threat in an agonistic encounter.},
author = {B{\~{A}}¡lint, Anna and Farag{\~{A}}³, Tam{\~{A}}¡s and Mikl{\~{A}}³si, {\~{A}}d{\~{A}}¡m and Pongr{\~{A}}¡cz, P{\~{A}}{\textcopyright}ter},
doi = {10.1007/s10071-016-1019-9},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/B{\~{A}}¡lint et al. - 2016 - Threat-level-dependent manipulation of signaled body size dog growls' indexical cues depend on the different lev.pdf:pdf},
isbn = {1007101610199},
issn = {14359448},
journal = {Animal Cognition},
keywords = {Communication,Dog growl,Indexical information,Manipulation,Threat},
number = {6},
pages = {1115--1131},
pmid = {28077769},
title = {{Threat-level-dependent manipulation of signaled body size: dog growls' indexical cues depend on the different levels of potential danger}},
volume = {19},
year = {2016}
}
@article{Pongracz2017,
abstract = {The visual sense of dogs is in many aspects different than that of humans. Unfortunately, authors do not explicitly take into consideration dog-human differences in visual perception when designing their experiments. With an image manipulation program we altered stationary images, according to the present knowledge about dog-vision. Besides the effect of dogs' dichromatic vision, the software shows the effect of the lower visual acuity and brightness discrimination, too. Fifty adult humans were tested with pictures showing a female experimenter pointing, gazing or glancing to the left or right side. Half of the pictures were shown after they were altered to a setting that approximated dog vision. Participants had difficulty to find out the direction of glancing when the pictures were in dog-vision mode. Glances in dog-vision setting were followed less correctly and with a slower response time than other cues. Our results are the first that show the visual performance of humans under circumstances that model how dogs' weaker vision would affect their responses in an ethological experiment. We urge researchers to take into consideration the differences between perceptual abilities of dogs and humans, by developing visual stimuli that fit more appropriately to dogs' visual capabilities.},
author = {Pongr{\'{a}}cz, P{\'{e}}ter and Ujv{\'{a}}ri, Vera and Farag{\'{o}}, Tam{\'{a}}s and Mikl{\'{o}}si, {\'{A}}d{\'{a}}m and P{\'{e}}ter, Andr{\'{a}}s},
doi = {10.1016/j.beproc.2017.04.002},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pongr{\'{a}}cz et al. - 2017 - Do you see what I see The difference between dog and human visual perception may affect the outcome of experime.pdf:pdf},
isbn = {0201503311048},
issn = {18728308},
journal = {Behavioural Processes},
keywords = {Dog,Ethology,Human,Visual perception},
number = {March},
pages = {53--60},
title = {{Do you see what I see? The difference between dog and human visual perception may affect the outcome of experiments}},
volume = {140},
year = {2017}
}
@misc{Filippi2016,
abstract = {Across a wide range of animal taxa, prosodic modulation of the voice can express emotional information and is used to coordinate vocal interactions between multiple individuals. Within a comparative approach to animal communication systems, I hypothesize that the ability for emotional and interactional prosody (EIP) paved the way for the evolution of linguistic prosody - and perhaps also of music, continuing to play a vital role in the acquisition of language. In support of this hypothesis, I review three research fields: (i) empirical studies on the adaptive value of EIP in non-human primates, mammals, songbirds, anurans, and insects; (ii) the beneficial effects of EIP in scaffolding language learning and social development in human infants; (iii) the cognitive relationship between linguistic prosody and the ability for music, which has often been identified as the evolutionary precursor of language.},
author = {Filippi, Piera},
booktitle = {Frontiers in Psychology},
doi = {10.3389/fpsyg.2016.01393},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Filippi - 2016 - Emotional and interactional prosody across animal communication systems A comparative approach to the emergence of lang.pdf:pdf},
issn = {16641078},
keywords = {Arousal,Entrainment,Infant-directed speech,Interaction,Language evolution,Musical protolanguage,Prosody,Turn-taking},
number = {SEP},
pmid = {27733835},
title = {{Emotional and interactional prosody across animal communication systems: A comparative approach to the emergence of language}},
volume = {7},
year = {2016}
}
@article{Larranaga2014,
abstract = {Barking is perhaps the most characteristic form of vocalization in dogs; however, very little is known about its role in the intraspecific communication of this species. Besides the obvious need for ethological research, both in the field and in the laboratory, the possible information content of barks can also be explored by computerized acoustic analyses. This study compares four different supervised learning methods (naive Bayes, classification trees, [Formula: see text]-nearest neighbors and logistic regression) combined with three strategies for selecting variables (all variables, filter and wrapper feature subset selections) to classify Mudi dogs by sex, age, context and individual from their barks. The classification accuracy of the models obtained was estimated by means of [Formula: see text]-fold cross-validation. Percentages of correct classifications were 85.13 {\%} for determining sex, 80.25 {\%} for predicting age (recodified as young, adult and old), 55.50 {\%} for classifying contexts (seven situations) and 67.63 {\%} for recognizing individuals (8 dogs), so the results are encouraging. The best-performing method was [Formula: see text]-nearest neighbors following a wrapper feature selection approach. The results for classifying contexts and recognizing individual dogs were better with this method than they were for other approaches reported in the specialized literature. This is the first time that the sex and age of domestic dogs have been predicted with the help of sound analysis. This study shows that dog barks carry ample information regarding the caller's indexical features. Our computerized analysis provides indirect proof that barks may serve as an important source of information for dogs as well.},
author = {Larra{\~{n}}aga, Ana and Bielza, Concha and Pongr{\'{a}}cz, P{\'{e}}ter and Farag{\'{o}}, Tam{\'{a}}s and B{\'{a}}lint, Anna and Larra{\~{n}}aga, Pedro},
doi = {10.1007/s10071-014-0811-7},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Larra{\~{n}}aga et al. - 2014 - Comparing supervised learning methods for classifying sex, age, context and individual Mudi dogs from barking.pdf:pdf},
isbn = {1435-9448},
issn = {14359448},
journal = {Animal Cognition},
keywords = {Acoustic communication,Feature subset selection,K-fold cross-validation,Machine learning,Mudi dog barks,Supervised classification},
month = {mar},
number = {2},
pages = {405--421},
pmid = {25308549},
publisher = {Springer Berlin Heidelberg},
title = {{Comparing supervised learning methods for classifying sex, age, context and individual Mudi dogs from barking}},
url = {http://link.springer.com/10.1007/s10071-014-0811-7},
volume = {18},
year = {2014}
}
@article{Farago2017,
abstract = {{\textcopyright} 2017 The Authors.Vocal expressions of emotions follow simple rules to encode the inner state of the caller into acoustic parameters, not just within species, but also in cross-species communication. Humans use these structural rules to attribute emotions to dog vocalizations, especially to barks, which match with their contexts. In contrast, humans were found to be unable to differentiate between playful and threatening growls, probably because single growls' aggression level was assessed based on acoustic size cues. To resolve this contradiction, we played back natural growl bouts from three social contexts (food guarding, threatening and playing) to humans, who had to rate the emotional load and guess the context of the playbacks. Listeners attributed emotions to growls according to their social contexts. Within threatening and playful contexts, bouts with shorter, slower pulsing growls and showing smaller apparent body size were rated to be less aggressive and fearful, but more playful and happy. Participants associated the correct contexts with the growls above chance. Moreover, women and participants experienced with dogs scored higher in this task. Our results indicate that dogs may communicate honestly their size and inner state in a serious contest situation, while manipulatively in more uncertain defensive and playful contexts.},
author = {Farag{\'{o}}, T. and Tak{\'{a}}cs, N. and Mikl{\'{o}}si, {\'{A}}. and Pongr{\'{a}}cz, P.},
doi = {10.1098/rsos.170134},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Farag{\'{o}} et al. - 2017 - Dog growls express various contextual and affective content for human listeners.pdf:pdf},
isbn = {0000000159},
issn = {2054-5703},
journal = {Royal Society Open Science},
month = {may},
number = {5},
pages = {170134},
pmid = {28573021},
publisher = {The Royal Society},
title = {{Dog growls express various contextual and affective content for human listeners}},
url = {http://rsos.royalsocietypublishing.org/lookup/doi/10.1098/rsos.170134},
volume = {4},
year = {2017}
}
@book{Dietterich,
author = {Dietterich, Thomas and Bishop, Christopher and Heckerman, David and Jordan, Michael and Kearns, Michael},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dietterich et al. - Unknown - Introduction to Machine Learning Second Edition Adaptive Computation and Machine Learning.pdf:pdf;:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dietterich et al. - Unknown - Introduction to Machine Learning Second Edition Adaptive Computation and Machine Learning(2).pdf:pdf},
isbn = {9780262193986},
title = {{Introduction to Machine Learning Second Edition Adaptive Computation and Machine Learning}}
}
@article{Minnen2006,
abstract = {In this paper we examine several factors that influ- ence the evaluation of multi-class, continuous activity recognition. Currently, there is no standard metric for evaluating and com- paring such systems, although many possible error formulations and performance metrics could be adapted from other domains. In order to make progress toward a standard metric appropriate for evaluating activity recognition, we outline the sources of errors in such systems, present different methods for detecting and labeling these errors, and compare existing metrics with a more nuanced performance visualization. We conclude with a discussion concerning the interpretation of the visualization for comparing recognition systems in different domains.},
author = {Minnen, David and Westeyn, Tracy L and Starner, Thad and Ward, Jamie a and Lukowicz, Paul},
doi = {10.1145/1889681.1889687},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Minnen et al. - 2006 - Performance Metrics and Evaluation Issues for Continuous Activity Recognition.pdf:pdf},
issn = {21576904},
journal = {Proc. Int. Workshop on Performance Metrics for Intelligent Systems},
pages = {141--148},
title = {{Performance Metrics and Evaluation Issues for Continuous Activity Recognition}},
year = {2006}
}
@article{Horowitz2013,
abstract = {The performance of tracking dogs and drug-, disease-, and explosives-detection dogs is a testament to trained dogs' olfactory acuity. The olfactory experience of an untrained dog, by contrast, has not been well documented. In the current research we begin to remedy that by testing untrained pet dogs' olfactory perception of quantity. While previous research found that dogs could discriminate visible quantities of more or less food (Prato-Previde, Marshall-Pescini, {\&} Valsecchi, 2008), our results find that, by contrast, companion dogs do not reliably discriminate quantities when the food can be smelled but not seen. Sixty-one percent of dogs (39 of 64), given a choice between closed plates with one and five morsels of food, approached plates with the larger quantity: not significantly more than approached plates with the lesser quantity (binomial, p = .169). We did find that during dogs' initial investigation of both food amounts, subjects gave more attention to the plate containing the larger quantity (binomial, p{\textless} 0.001). In a second condition, we replicated, with closed plates, Prato-Previde et al.'s (2008) finding that owner interest in a plate holding a lesser quantity of food reliably leads dogs to approach that plate (binomial, p{\textless} 0.001). Though research has demonstrated dogs' preference for a larger amount of food (Ward {\&} Smuts, 2007), in a third condition testing the effect of adding a strong odor to a visibly larger food quantity, we found that the addition of odor often reversed that preference (44/69 dogs; p{\textless} .03). Finally, we consider the methodological implications of this work on future dog cognition studies. {\textcopyright} 2013 Elsevier Inc.},
author = {Horowitz, Alexandra and Hecht, Julie and Dedrick, Alexandra},
doi = {10.1016/j.lmot.2013.02.002},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Horowitz, Hecht, Dedrick - 2013 - Smelling more or less Investigating the olfactory experience of the domestic dog.pdf:pdf},
isbn = {00239690 (ISSN)},
issn = {00239690},
journal = {Learning and Motivation},
month = {nov},
number = {4},
pages = {207--217},
publisher = {Academic Press},
title = {{Smelling more or less: Investigating the olfactory experience of the domestic dog}},
url = {https://www.sciencedirect.com/science/article/pii/S0023969013000234},
volume = {44},
year = {2013}
}
@article{Gogoleva2008,
abstract = {In this study we classify call structures and compare vocalizations toward humans by captive red foxes Vulpes vulpes, artificially selected for behaviour: 25 domesticated, or "Tame" animals, selected for tameness toward people, 25 "Aggressive" animals, selected for aggression toward people, and 25 "Unselected" control foxes, representing the "wild" model of vocal behaviour. In total, 12,964 calls were classified visually from spectrograms into five voiced (tonal) (whine, moo, cackle, growl and bark), and three unvoiced, or noisy (pant, snort and cough) call types. The classification results were verified with discriminant function analysis (DFA) and randomization. We found that the Aggressive and Unselected foxes produced the same call type sets toward humans, whereas the Tame foxes used distinctive vocalizations toward humans. The Tame and Aggressive foxes had significantly higher percentages of time spent vocalizing than the Unselected, in support of Cohen {\&} Fox (1976) hypothesis that domestication relaxes the selection pressure for silence, still acting in wild canids. Unlike in dogs, the "domesticated" Tame foxes did not show hypertrophied barking toward humans, using instead the cackle and pant. We conclude that the use of a certain call type for communication between humans and canids is species-specific, and not is the direct effect of domestication per se. ¬{\textcopyright} 2008 AB Academic Publishers.},
author = {Gogoleva, S. S. and Volodin, J. A. and Volodina, E. V. and Trut, L. N.},
doi = {10.1080/09524622.2008.9753595},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gogoleva et al. - 2008 - To bark or not to bark Vocalizations by red foxes selected for tameness or aggressiveness toward humans.pdf:pdf},
isbn = {0952-4622},
issn = {21650586},
journal = {Bioacoustics},
keywords = {Articulation,Canidae,Domestication,Nonlinear phenomena,Red fox,Vocal communication,Vocalization,Vulpes vulpes},
number = {2},
pages = {99--132},
pmid = {46},
title = {{To bark or not to bark: Vocalizations by red foxes selected for tameness or aggressiveness toward humans}},
volume = {18},
year = {2008}
}
@article{Gogoleva2011,
abstract = {Domestication affects behavioral and vocal responses, involved in communication with humans; in particular, those that attract human attention. In this study, we found that silver foxes of Tame strain, experimentally domesticated for a few tenses of generation, displayed bursts of vocal activity during the first minute after appearance of an unfamiliar human, that faded quickly during the remaining time of the test, when the experimenter stayed passively before the cage. Distinctively, foxes of Aggressive strain, artificially selected for tenses of generation for aggressive behavior toward humans, and the control group of Unselected for behavior silver foxes kept steady levels of vocal activity for the duration of the tests. We found also that Aggressive foxes vocalized for a larger proportion of time than Unselected foxes for all 5min of the test. We discuss the obtained data in relation to proposal effects of domestication on mechanisms directed to involving people into human–animal interactions and structural similarity between human laughter and vocalization of Tame foxes.},
author = {Gogoleva, Svetlana S. and Volodin, Ilya A. and Volodina, Elena V. and Kharlamova, Anastasia V. and Trut, Lyudmila N.},
doi = {10.1016/J.BEPROC.2010.12.001},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gogoleva et al. - 2011 - Explosive vocal activity for attracting human attention is related to domestication in silver fox.pdf:pdf},
issn = {0376-6357},
journal = {Behavioural Processes},
month = {feb},
number = {2},
pages = {216--221},
publisher = {Elsevier},
title = {{Explosive vocal activity for attracting human attention is related to domestication in silver fox}},
url = {https://www.sciencedirect.com/science/article/pii/S0376635710002949},
volume = {86},
year = {2011}
}
@article{Izso2000,
abstract = {Elementary steps of H uman Computer Interaction (HCI), like users' mental actions followed by a series of keystrokes and mouse-clicks, are the basic components of using information technological systems. This is why examination methods capable of assessing users' actual mental effort corresponding to these elementary steps during HCI in a scientifically sound way have great importance. It is known that under certain circumstances, Heart Period Variability (HPV) could be a measure of actual mental effort. This paper gives a short overview of applications of HPV in ergonomics in general and, based on empirical evidence intends to prove that this methodology, after a careful adaptation, could be powerful technique for monitoring mental effort in HCI. The paper outlines the main components of the INTERFACE testing workstation and the related methodology for investigatingamong others-users mental effort. A detailed application example is also provided.},
author = {Izs{\'{o}}, Lajos and L{\'{a}}ng, Eszter},
doi = {10.1080/01449290050086408},
isbn = {0144-929X},
issn = {0144929X},
journal = {Behaviour and Information Technology},
month = {jan},
number = {4},
pages = {297--306},
publisher = {Taylor {\&} Francis Group},
title = {{Heart period variability as mental effort monitor in Human Computer Interaction}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01449290050086408},
volume = {19},
year = {2000}
}
@article{Albuquerque2016,
abstract = {The perception of emotional expressions allows animals to evaluate the social intentions and motivations of each other. This usually takes place within species; however, in the case of domestic dogs, it might be advantageous to recognize the emotions of humans as well as other dogs. In this sense, the combination of visual and auditory cues to categorize others' emotions facilitates the information processing and indicates high-level cognitive representations. Using a cross-modal preferential looking paradigm, we presented dogs with either human or dog faces with different emotional valences (happy/playful versus angry/aggressive) paired with a single vocalization from the same individual with either a positive or negative valence or Brownian noise. Dogs looked significantly longer at the face whose expression was congruent to the valence of vocalization, for both conspecifics and heterospecifics, an ability previously known only in humans. These results demonstrate that dogs can extract and integrate bimodal sensory emotional information, and discriminate between positive and negative emotions from both humans and dogs.},
author = {Albuquerque, Natalia and Guo, Kun and Wilkinson, Anna and Savalli, Carine and Otta, Emma and Mills, Daniel},
doi = {10.1098/rsbl.2015.0883},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Albuquerque et al. - 2016 - Dogs recognize dog and human emotions.pdf:pdf},
issn = {1744-957X},
journal = {Biology letters},
keywords = {Canis familiaris,cross-modal sensory integration,emotion recognition,social cognition},
month = {jan},
number = {1},
pages = {20150883},
pmid = {26763220},
publisher = {The Royal Society},
title = {{Dogs recognize dog and human emotions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26763220 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4785927},
volume = {12},
year = {2016}
}
@article{Rosas,
annote = {The horse picked up on the subconcious movements of audience members to give the correct arithmetic answers.},
author = {Rosas, Juan M},
doi = {10.1007/978-3-319-47829-6_1283-1},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rosas - Unknown - C Clever Hans.pdf:pdf},
title = {{C Clever Hans}},
url = {https://link.springer.com/content/pdf/10.1007/978-3-319-47829-6{\_}1283-1.pdf}
}
@article{Molnar2008,
author = {Moln{\'{a}}r, Csaba and Kaplan, Fr{\'{e}}d{\'{e}}ric and Roy, Pierre and Pachet, Fran{\c{c}}ois and Pongr{\'{a}}cz, P{\'{e}}ter and D{\'{o}}ka, Antal and Mikl{\'{o}}si, {\'{A}}d{\'{a}}m},
doi = {10.1007/s10071-007-0129-9},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Moln{\'{a}}r et al. - 2008 - Classification of dog barks a machine learning approach.pdf:pdf},
issn = {1435-9448},
journal = {Animal Cognition},
month = {jul},
number = {3},
pages = {389--400},
publisher = {Springer-Verlag},
title = {{Classification of dog barks: a machine learning approach}},
url = {http://link.springer.com/10.1007/s10071-007-0129-9},
volume = {11},
year = {2008}
}
@article{Molnar2009,
abstract = {In the present study we explored whether dogs (Canis familiaris) are able to discriminate between conspecific barks emitted in different contexts recorded either from the same or different individuals. Playback experiments were conducted with dogs using barks as stimuli in a habituation–dishabituation paradigm. Barks were recorded in two contexts (stranger at the fence and when the dog was left alone) from different individuals. We found that dogs distinguished between barks emitted in these two contexts and were also able to discriminate between different individuals which were barking in the same context. These findings suggest that dog bark may carry context- and individual-specific information for the conspecifics.},
author = {Moln{\'{a}}r, Csaba and Pongr{\'{a}}cz, P{\'{e}}ter and Farag{\'{o}}, Tam{\'{a}}s and D{\'{o}}ka, Antal and Mikl{\'{o}}si, {\'{A}}d{\'{a}}m},
doi = {10.1016/J.BEPROC.2009.06.011},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Moln{\'{a}}r et al. - 2009 - Dogs discriminate between barks The effect of context and identity of the caller.pdf:pdf},
issn = {0376-6357},
journal = {Behavioural Processes},
month = {oct},
number = {2},
pages = {198--201},
publisher = {Elsevier},
title = {{Dogs discriminate between barks: The effect of context and identity of the caller}},
url = {https://www.sciencedirect.com/science/article/pii/S0376635709001557},
volume = {82},
year = {2009}
}
@article{Maros2008,
abstract = {We investigated if dogs can discriminate barks of another individual recorded in two markedly different situations: (a) when a stranger entered the property where the dog lived, and (b) when the dog was tethered to a tree and left alone. We used a habituation–dishabituation paradigm for testing discriminatory abilities. Three 25-s long samples of “stranger” bark were followed by a single “alone” bark sample. As a control, we used two types of mechanical noise (an electric drill and a refrigerator). Dogs (n=14) were equipped with a portable heart rate monitor which recorded the data during the whole experiment. Upon hearing the first barking sound, the heart rate of the dogs increased significantly, followed by a habituation when the same barks were played back the second and third time. The fourth, different bark caused dishabituation of the heart rate. This suggests that heart rate can be a sensitive indicator of changes in attentiveness. The dogs did not show any significant evidence of dishabituation to the Control condition of the mechanical noises. Our experiment showed that dogs can perceive the difference between barks originating from different situations, thus barking is perhaps a communicative tool not only for dogs to humans, but for dogs to dogs as well.},
annote = {Hypothesis: Dogs can distinguish between barks recorded in different situtations ("Stranger" and "Alone")
Subjects: German Shepard (4), Tervueren, Border Collie, Golden Retriever (2), German Pointer, Labrador Retriever, Czechoslovakian Wolfdog, mongrel
Methodology: Using telemetric system, cardiac activity of dogs monitored during different contexts. Used recorded vocalizations to elicit a response from test animal. Control sounds of mechanical equipment were played as well. Owner and assistant present in the room (3m x 5m) during experiment. To avoid anticipatory response owner and assistant discussed ambient topics not paying attention to the noises.
Results: Definitely a change in heart rate due to different contextual vocalizations. As time goes on during playback, heart rate change increases.},
author = {Maros, Katalin and Pongr{\'{a}}cz, P{\'{e}}ter and B{\'{a}}rdos, Gy{\"{o}}rgy and Moln{\'{a}}r, Csaba and Farag{\'{o}}, Tam{\'{a}}s and Mikl{\'{o}}si, {\'{A}}d{\'{a}}m},
doi = {10.1016/J.APPLANIM.2008.01.022},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Maros et al. - 2008 - Dogs can discriminate barks from different situations.pdf:pdf},
issn = {0168-1591},
journal = {Applied Animal Behaviour Science},
month = {nov},
number = {1-2},
pages = {159--167},
publisher = {Elsevier},
title = {{Dogs can discriminate barks from different situations}},
url = {https://www.sciencedirect.com/science/article/pii/S0168159108000427?{\_}rdoc=1{\&}{\_}fmt=high{\&}{\_}origin=gateway{\&}{\_}docanchor={\&}md5=b8429449ccfc9c30159a5f9aeaa92ffb{\&}ccp=y},
volume = {114},
year = {2008}
}
@article{Peter2014,
abstract = {Besides being a widely investigated behavioural phenomenon, barks of dogs often represent a factor of nuisance for people. Although some argue that dog barking has no or only minimal communicative function, it was shown recently that these acoustic signals carry various information that humans can decipher. However, apart from a few laboratory studies, until now no targeted research has been done about the communicative role of barks in the intraspecific domain. In this field experiment companion dogs were tested with bark playbacks at home, in a suburban environment. From a hidden sound system, placed near to the gate outside of the property, each subject was exposed to pre-recorded barks of an unfamiliar and a familiar dog. Barks for the playbacks were recorded in two different contexts: when the dog was either left alone or when it was barking at a stranger at the fence. We found differences in the behaviour of dogs depending on both the familiarity and context of the playback barks. The position of the dogs (near the house or near the gate) was mainly influenced by the context of the barks (p=0.011), in a significant interaction with the familiarity of the barking dog (p=0.020). Subjects stayed at the gate (nearest to the source of the sound) the longest when they heard an unfamiliar dog barking at a stranger (padj=0.012). Meanwhile they stayed at the house mostly during the barks of a lonely unfamiliar dog (padj=0.001). Dogs oriented more towards the house (where the familiar dog stayed during the experiment) when they heard the familiar dog's barking (p=0.019). Subjects barked more often when they heard the ‘stranger' barks, independently of the familiarity of the caller (p=0.035). As a conclusion, dogs seemingly distinguished among the callers based on familiarity and between the contexts of the barks. This is the first study on companion dogs in their natural environment that found evidence that dogs are able to extract detailed information from the barks. The relevance of our findings for the management of excessive bark is discussed.},
author = {P{\'{e}}ter, Pongr{\'{a}}cz and {\'{E}}va, Szab{\'{o}} and Anna, Kis and Andr{\'{a}}s, P{\'{e}}ter and {\'{A}}d{\'{a}}m, Mikl{\'{o}}si},
doi = {10.1016/J.APPLANIM.2014.08.003},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/P{\'{e}}ter et al. - 2014 - More than noise—Field investigations of intraspecific acoustic communication in dogs (Canis familiaris).pdf:pdf},
issn = {0168-1591},
journal = {Applied Animal Behaviour Science},
month = {oct},
pages = {62--68},
publisher = {Elsevier},
title = {{More than noise?—Field investigations of intraspecific acoustic communication in dogs (Canis familiaris)}},
url = {https://www.sciencedirect.com/science/article/pii/S0168159114002093},
volume = {159},
year = {2014}
}
@article{Pongracz2005,
abstract = {The authors investigated whether human listeners could categorize played-back dog (Canis familiaris) barks recorded in various situations and associate them with emotional ratings. Prerecorded barks of a Hungarian herding dog breed (Mudi) provided the sample. Human listeners were asked to rate emotionality of the vocalization and to categorize the situations on the basis of alternative situations provided on a questionnaire. The authors found almost no effect of previous experience with the given dog breed or of owning a dog. Listeners were able to categorize bark situations high above chance level. Emotionality ratings for particular bark samples correlated with peak and fundamental frequency and interbark intervals. The authors did not find a significant effect of tonality (harmonic-to-noise ratio) on either the emotionality rating or situation categorization of the human listeners. Humans' ability to recognize meaning suggests that barks could serve as an effective means of communication between dog and human.},
annote = {Subjects: Three groups Mudi owners, dog owners, never owned dog. Recordings collected from 19 Mudis
Hypothesis: Humans are able to determine dog internal state based on vocalization
Mudi vocalizations were collected in home setting
Six different contexts: Stranger, Schutzhund, going for walk, alone, ball, play.
Recorded all interactions by having researcher present and holding microphone within 1-4 m of dog
Random sets of dog vocalizations were played back to human subjects who had to rate by emotion.},
author = {Pongr{\'{a}}cz, P{\'{e}}ter and Moln{\'{a}}r, Csaba and Mikl{\'{o}}si, {\'{A}}d{\'{a}}m and Cs{\'{a}}nyi, Vilmos},
doi = {10.1037/0735-7036.119.2.136},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pongr{\'{a}}cz et al. - 2005 - Human listeners are able to classify dog (Canis familiaris) barks recorded in different situations.pdf:pdf},
isbn = {0735-7036},
issn = {07357036},
journal = {Journal of Comparative Psychology},
number = {2},
pages = {136--144},
pmid = {15982157},
title = {{Human listeners are able to classify dog (Canis familiaris) barks recorded in different situations}},
volume = {119},
year = {2005}
}
@article{Pongracz2010,
abstract = {Although it is one of the most conspicuous features of dog behaviour, barking has received little attention from ethologists or from an applied perspective. In this review, an ethological look is taken at the communicative aspect of dog barking. Emerging new research has indicated that in the repertoire of dog vocalisations barking has unique features in showing wide ranges of acoustic parameters, such as frequency, tonality and rhythmicity. Barking has been shown to be context dependent, and provides information for humans about the inner state of the dog although there are few indications that barking is used for intra-species communication. It is assumed that dog barking emerged through selective processes in which human preferences for certain acoustic aspects of the vocalisation may have been paramount. A more experiment-oriented approach is required for the study of dog vocalisation that could shed light on the possible communicative function of these acoustic signals.},
annote = {Literature review up to 2008
Referenced several other papers collected
Brought few new things to project
Provides a few ideas for future work},
author = {Pongr{\'{a}}cz, P{\'{e}}ter and Moln{\'{a}}r, Csaba and Mikl{\'{o}}si, {\'{A}}d{\'{a}}m},
doi = {10.1016/J.TVJL.2008.12.010},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pongr{\'{a}}cz, Moln{\'{a}}r, Mikl{\'{o}}si - 2010 - Barking in family dogs An ethological approach.pdf:pdf},
issn = {1090-0233},
journal = {The Veterinary Journal},
month = {feb},
number = {2},
pages = {141--147},
publisher = {W.B. Saunders},
title = {{Barking in family dogs: An ethological approach}},
url = {https://www.sciencedirect.com/science/article/pii/S1090023308004437},
volume = {183},
year = {2010}
}
@article{Farago2010,
abstract = {A number of species are considered to use functionally referential signals such as alarm calls or food-related vocalizations. However, this particular function of communicative interaction has not previously been found in canids. We provide the first experimental indication that domestic dogs, Canis familiaris, rely on context-dependent signals during interspecific agonistic encounters. We recorded several sequences of growls from dogs in three different contexts: during play, guarding a bone from another dog, and reacting to a threatening stranger. We analysed the acoustic structure of the growls and additionally performed playback tests in a seminatural food-guarding situation. We found that play growls differed acoustically from the other two (agonistic) types of growls, mainly in their fundamental frequencies and formant dispersions. Results of the playback experiment showed that food-guarding growls deterred other dogs from taking away a seemingly unattended bone more effectively than growls recorded in the threatening stranger situation. We ruled out an effect of the signaller's body weight on the subjects' responses. These results provide the first evidence of context specificity of agonistic vocalizations in the dog. We discuss the possible aspects of honesty and deception through acoustic modulation of growls. {\textcopyright} 2010 The Association for the Study of Animal Behaviour.},
annote = {- Hypothesis: Dogs are able to tell the difference between Food Guarding, Play, and threatening stranger growls.
- Subjects: 20 adult dogs for recording, 41 adult for recording playback
- Methodology: Record with directional microphone, elicit about 10 growls in each situation, disqualify animals with no response. Acoustical analysis on growl waveforms.
- Params: growl duration (L), fundamental frequency (F0), formant frequencies (F1-F5), formant dispersion (dF), standard deviation of formant dispersion, harmonic to noise ratio
- Strong order effect, dogs were able to learn the experiment quickly
- Results: significant diffs btwn PL and FG growls and PL and TS growls.},
author = {Farag{\'{o}}, Tam{\'{a}}s and Pongr{\'{a}}cz, P{\'{e}}ter and Range, Friederike and Vir{\'{a}}nyi, Zs{\'{o}}fia and Mikl{\'{o}}si, {\'{A}}d{\'{a}}m},
doi = {10.1016/j.anbehav.2010.01.005},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Farag{\'{o}} et al. - 2010 - 'The bone is mine' affective and referential aspects of dog growls.pdf:pdf},
isbn = {0003-3472},
issn = {00033472},
journal = {Animal Behaviour},
keywords = {Canis familiaris,acoustical analysis,dog,graded signal,growl,referential communication},
number = {4},
pages = {917--925},
title = {{'The bone is mine': affective and referential aspects of dog growls}},
volume = {79},
year = {2010}
}
@article{Feddersen-Petersen2000,
abstract = {Barking in domestic dogs still remains a topic of controversial discussions. While some authors assess dog- barking an acoustic means of expression becoming more and more sophisticated during domestication, others name this sound type "non-communicative". Vocal repertoires as works on individual sound types are rare, however, and there has been almost no work done on Iow-intensity, close-range vocalizations, yet such types of vocalization are especially important with the more social canids, hence, with the human-dog-communication and understanding of dogs. Most of the investigations published so far are based on auditive sound impressions and lack objectivity. The principal method used in this study was sonagraphic. This facilitates the identiftcation of sounds and reveales, whether subjective Classification can be verified by objectively measured parameters. Finally, meanings, funetions and emotions were examined for all the major sounds described and are discussed in terms of relationships between sound structure and Signal function, signal emission and social context as behavioural response, and overlapping Channels of communication. Ontogeny of acoustic communication in 11 European wolves has been compared to various dog breeds (8 Standard Poodles, 8 Toy Poodles, 15 Kleine M{\"{u}}nsterl{\"{a}}nder, 11 Weimaraner Hunting Dogs, 16 Tervueren, 12 American Staffordshire Terriers, and 13 German Shepherds, 12 Alaskan Malamutes, and 9 Bull Terriers) from birth up to 8 (12) weeks resp. 4 (12) months of age. Noisy and harmonic sound groups were analysed separately as overriding units. Following parameters were used: fmax=maximum of spectrographic pietured sounds (Hz), xfo=mean of the lowest frequency band of harmonic sounds (Hz), xfd=mean of the frequency of strongest amplitude of noisy sounds (Hz), delta f=frequency r{\"{a}}nge of sounds (Hz), duration of sounds (ms). Statistical analysis was run on "Statistica", Release 4,0. Within the sound type barking 2 to 12 subunits were classified in the different breeds, aecording to their context-speeifie spectrographic design, and behavioural responses. Categories of function / emotion include f.e. social play, play soliticing, exploration, caregiving, social contact and "greeting", loneliness, and agonistc behaviours. "Interaction" was the most common category of social context for masted barkings (56{\%} of oecurences). Especially close-range vocalizations, conceming the major sound type of most domestic dogs, the bark, evolved highly variable. However, the ecological niche of domestic dogs is highly variable, just as the individual differences in the dogs are, which seem to be breed-typical to a great extent. Thus, complexity within the dog's vocal repertoire, and therefore enhancement of its communicative value, is achieved by many subunits of bark, some standing for specific motivations, informations and expressions. Complexity within the dogs'vocal repertoire is extended by the use of mixed sounds in the barking context. Transitions and gradations to a great extend oeeur via bark sounds: harmonic, intermediate and noisy subunits.},
annote = {Wolves and domestic dogs studied
Hypothesis: Dog vocaliations have contextual meaning via statistical analysis
Results: Found that the statistical analysis shows variations based on context
Wolves on the other hand do not have such variations in vocalizations},
author = {Feddersen-Petersen, Dorit Urd},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Feddersen-Petersen - 2000 - Vocalization of European wolves (Canis lupus lupus L.) and various dog breeds (Canis lupus f. fam.).pdf:pdf},
isbn = {0003-9438},
issn = {00039438 (ISSN)},
journal = {Archiv f{\"{u}}r Tierzucht},
keywords = {communication,domestication,functions of barking,funetions of barking,interaction,selection,selection.,vocalization},
number = {4},
pages = {387--397},
pmid = {930},
title = {{Vocalization of European wolves (Canis lupus lupus L.) and various dog breeds (Canis lupus f. fam.)}},
volume = {43},
year = {2000}
}
@article{Yeon2007,
abstract = {Canine vocalizations can be divided into several types and these types of vocalizations can carry the senders' emotional state to receivers such as other dogs and humans. When humans send a signal consisting of short notes, it can elicit a reactive response and increase motor activity levels more so than a signal consisting of a longer continuous note. This means that humans and dogs can communicate with each other using acoustic signals. These canine vocalizations can be analyzed by computer-aided programs that evaluate several parameters including fundamental frequency, and other frequency variables like minimum and maximum frequency, duration of call, inter-call duration, amplitude variables, harmonic to noise ratio (HNR), nonlinear phenomena, like limit cycle, subharmonic, biphonation, and chaos. Dogs' vocalizations can be analyzed using objective scientific criteria with these parameters, and using this analysis, we know that dog vocalizations fall into several context based vocal types. Also humans can distinguish the difference in dog barks. The dogs' barking can be a behavioral problem because of their high intensity especially in urban areas. Treatment methods may include environmental manipulation, behavior modification, and positive re-enforcement. This paper discusses the literature related to scientific analysis of canine vocalization. {\textcopyright} 2007 Elsevier Inc. All rights reserved.},
annote = {- Only a few studies done on topic
- Several ethologists consider domestication too altering
- Other research says otherwise
- Interbark intervals affected how humans percieve bark
- Howling occurs in small {\#} of breeds
- That howling doesn't match wolf howling in meaning
- Multiple complex accoustic structs making it difficult
- Computer-aided analysis of dog acoustic sinals is still issue
- bark analysis with HNR found to be consistent with people's perception of bark},
author = {Yeon, Seong Chan},
doi = {10.1016/j.jveb.2007.07.006},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yeon - 2007 - The vocal communication of canines.pdf:pdf},
isbn = {1558-7878},
issn = {15587878},
journal = {Journal of Veterinary Behavior: Clinical Applications and Research},
keywords = {communication,dog,spectrogram,vocalization},
number = {4},
pages = {141--144},
title = {{The vocal communication of canines}},
volume = {2},
year = {2007}
}
@article{Darden2003,
abstract = {The prevalence of complex acoustic structures in mammalian vocalisations can make it difficult to quantify frequency characteristics. We describe two methods developed for the frequency analysis of a complex swift fox Vulpes uelox vocalisation, the barking sequence: (1) autocorrelation function analysis and (2) instantaneous frequency analysis. The autocorrelation function analysis results in an energy density spectrum of the signal's averaged amplitude and frequency information. This analysis was used for locating possible formant structures and quantifying the energy distribution of single barks in the barking sequence. The instantaneous frequency analysis is applied to individual continuous frequency bands and generates frequency contours with a resolution of a couple of Hertz. It was used to quantify frequency modulation and calculate average frequencies of harmonic bands in individual barks and to estimate fundamental frequencies. This second method of analysis had to be evaluated with spectrographic analysis to gauge its reliability for each band analysed. The algorithms used should make both of these methods applicable to other complex vocalisations. Keywords:},
author = {Darden, Safi K. and Pedersen, Simon B. and Dabelsteen, Torben},
doi = {10.1080/09524622.2003.9753501},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Darden, Pedersen, Dabelsteen - 2003 - Methods of frequency analysis of a complex mammalian vocalisation.pdf:pdf},
issn = {21650586},
journal = {Bioacoustics},
keywords = {Autocorrelation,Instantaneous frequency,Mammalian vocalization,Sound analysis,Vulpes velox},
number = {3},
pages = {247--263},
pmid = {2833},
title = {{Methods of frequency analysis of a complex mammalian vocalisation}},
volume = {13},
year = {2003}
}
@article{Riede1999,
abstract = {The physical nature of the vocal tract results in the production of formants during vocalisation. In some animals (including humans), receivers can derive information (such as body size) about sender characteristics on the basis of formant characteristics. Domestication and selective breeding have resulted in a high variability in head size and shape in the dog (Canis familiaris), suggesting that there might be large differences in the vocal tract length, which could cause formant behaviour to affect interbreed communication. Lateral radiographs were made of dogs from several breeds ranging in size from a Yorkshire terrier (2.5 kg) to a German shepherd (50 kg) and were used to measure vocal tract length. In addition, we recorded an acoustic signal (growling) from some dogs. Significant correlations were found between vocal tract length, body mass and formant dispersion, suggesting that formant dispersion can deliver information about the body size of the vocalizer. Because of the low correlation between vocal tract length and the first formant, we predict a non-uniform vocal tract shape.},
author = {Riede, T and Fitch, T},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Riede, Fitch - 1999 - Vocal tract length and acoustics of vocalization in the domestic dog (Canis familiaris).pdf:pdf},
isbn = {0022-0949},
issn = {0022-0949},
journal = {The Journal of experimental biology},
keywords = {canidae,dog,formant,growling,source-tract theory},
pages = {2859--2867},
pmid = {10504322},
title = {{Vocal tract length and acoustics of vocalization in the domestic dog (Canis familiaris).}},
volume = {202},
year = {1999}
}
@article{Yin2004,
abstract = {In this study we sought to determine whether dog barks could be divided into subtypes based on context. We recorded barking from 10 adult dogs, Canis familiaris, of six breeds in three different test situations: (1) a disturbance situation in which a stranger rang the doorbell, (2) an isolation situation in which the dog was locked outside or in a room isolated from its owner and (3) a play situation in which either two dogs or a human and a dog played together. We analysed spectrograms of 4672 barks using macros that took 60 sequential frequency measurements and 60 sequential amplitude measurements along the length of the call. Statistical analyses revealed that barks are graded vocalizations that range from harsh, low-frequency, unmodulated calls to harmonically rich, higher-frequency, modulated calls. The harsh, low-frequency, unmodulated barks were more commonly given in the disturbance situation, and the more tonal, higher-pitch, modulated barks were more commonly given in the isolation and play situations. Disturbance barks were also longer in duration with more rapid repetition than the barks given in other contexts. Discriminant analysis revealed that dog barks can be divided into different subtypes based on context even within individual dogs, and that dogs can be identified by their bark spectrograms despite the context of the bark. {\textcopyright} 2004 The Association for the Study of Animal Behaviour. Published by Elsevier Ltd. All rights reserved.},
annote = {Hypothesis: Dog barks are able to be divided into subtypes based on context.
Subjects: 10 adult dogs of six breeds
Methodology: Three situations (door ring, isolation, play). Situtations repeated five times for each dog. Same situations were collected on different days. Microphone in room between 1 and 6 m from animal. Used discrimanent analysis for classification
Results: Amplitude range, min freq, duration and mean freq were top contibutors. Able to classify with about 37{\%} error.},
author = {Yin, Sophia and McCowan, Brenda},
doi = {10.1016/j.anbehav.2003.07.016},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yin, McCowan - 2004 - Barking in domestic dogs Context specificity and individual identification.pdf:pdf},
isbn = {0003-3472},
issn = {00033472},
journal = {Animal Behaviour},
number = {2},
pages = {343--355},
title = {{Barking in domestic dogs: Context specificity and individual identification}},
volume = {68},
year = {2004}
}
@article{Schrader1997,
abstract = {The computer-aided analysis of acoustic signals of mammals is still a problem, as often (a) sound structures are complex, (b) vocal repertoires often comprise an enormous variety of vocalisations, (c) recordings are influenced by the acoustic conditions of the environment, and (d) the distance and spatial orientation of the sender to the microphone changes. In recent software packages for the analysis of acoustic signals, procedures are integrated which allow the calculation of a variety of signal features. However, these algorithms are often problematic under the conditions mentioned above. In this paper, we present a multi-parametric approach which reduces these problems and which allows a quantitative and reproducible analysis of complex animal vocalisations. Our approach comprises the following aspects: (1) reduction of influences of recording conditions, (2) determination of different sound features and (3) calculation of parameters to characterize these sound features. All calculations are done on the basis of the digitized spectrograms. Special attention is given to the use of smoothing algorithms and dynamic thresholds in order to estimate sound features and to reduce influences resulting from recording conditions. The suitability of our approach has been demonstrated successfully for vocalisations of different species.},
author = {Schrader, Lars and Hammerschmidt, Kurt},
doi = {10.1080/09524622.1997.9753338},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schrader, Hammerschmidt - 1997 - Computer-aided analysis of acoustic parameters in animal vocalisations A multi-parametric approach.pdf:pdf},
issn = {21650586},
journal = {Bioacoustics},
keywords = {Computer sound analysis,Mammals,Multiparametric approach,Primates,Vocalizations},
number = {4},
pages = {247--265},
title = {{Computer-aided analysis of acoustic parameters in animal vocalisations: A multi-parametric approach}},
volume = {7},
year = {1997}
}
@article{Lord2009,
abstract = {Barking is most often associated with the domestic dog Canis familiaris, but it is a common mammalian and avian vocalization. Like any vocalization, the acoustic character of the bark is likely to be a product of adaptation as well as an expression of the signaler's internal motivational state. While most authors recognize that the bark is a distinct signal type, no consistent description of its acoustic definition or function is apparent. The bark exhibits considerable variability in its acoustic form and occurs in a wide range of behavioral contexts, particularly in dogs. This has led some authors to suggest that dog barking might be a form of referential signaling, or an adaptation for heightened capability to communicate with humans. In this paper we propose a general ‘canonical' acoustic description of the bark. Surveying relevant literature on dogs, wild canids, other mammals and birds, we explore an alternative functional hypothesis, first suggested by [Morton, E.S., 1977. On the occurrence and significance of motivation-structural rules in some bird and mammal sounds. Am. Nat. 111, 855–869] and consistent with his motivational-structural rules theory: that barking in many animals, including the domestic dog, is associated with mobbing behavior and the motivational states that accompany mobbing.},
annote = {Hypothesis: Variation of bar is not referential but instead mobbing
Subjects: Data from previous study with 86 dogs
Methodology: Examine tone and noisiness
- Barking can be defined canonically as it happens in several mammals
- Goes into frequency background that was covered in other references
- Harmonic overtones
- anatomical/physiological factors
- noise often broadband or narrowband
- Average fun freq: 715 Hz over 25 random samples
- as bark rate increases, correlates with arousal
- Dogs bark at large set of stimuli, unusual for mammals to provide same signal for such large set of stimuli
- Mobbing: form of anit-predator behavior
- Low freq noise correlates with agressive behavior (arguable when considering play growl)
- Urban environments restrain dogs, increasing anxiety bc no escape vector
- Similar barking behavior observed when foxes domesticated
- Deaf dogs begin barking at same development point as others
- Discusses why body of work studying vocalizations do not imply referential communication
- Asserts results from such studies are consistent with Morton's rule},
author = {Lord, Kathryn and Feinstein, Mark and Coppinger, Raymond},
doi = {10.1016/J.BEPROC.2009.04.008},
file = {:C$\backslash$:/Users/logas/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lord, Feinstein, Coppinger - 2009 - Barking and mobbing.pdf:pdf},
issn = {0376-6357},
journal = {Behavioural Processes},
month = {jul},
number = {3},
pages = {358--368},
publisher = {Elsevier},
title = {{Barking and mobbing}},
url = {https://www.sciencedirect.com/science/article/pii/S0376635709001077},
volume = {81},
year = {2009}
}
